{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFMinerPDFasHTMLLoader\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='<html><head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html\">\\n</head><body>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:195px; top:106px; width:203px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:14px\">Adversarial Diffusion Distillation\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:99px; top:146px; width:53px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Axel Sauer\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:183px; top:146px; width:79px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Dominik Lorenz\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:294px; top:146px; width:92px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Andreas Blattmann\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:418px; top:146px; width:78px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Robin Rombach\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:100px; top:186px; width:393px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Code</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">: https://github.com/Stability-AI/generative-models </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Model weights</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">: https://huggingface.co/stabilityai/\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:269px; top:167px; width:56px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Stability AI\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:509px; width:495px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 1. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Generating high-ﬁdelity </span><span style=\"font-family: CMR9; font-size:8px\">512</span><span style=\"font-family: CMR6; font-size:5px\">2 </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">images in a single step. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">All samples are generated with a single U-Net evaluation trained with\\n<br>adversarial diffusion distillation (ADD).\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:145px; top:547px; width:44px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">Abstract\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:547px; width:76px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">1. Introduction\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:595px; width:238px; height:153px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">We introduce Adversarial Diffusion Distillation (ADD), a\\n<br>novel training approach that efﬁciently samples large-scale\\n<br>foundational image diffusion models in just 1–4 steps while\\n<br>maintaining high image quality. We use score distillation\\n<br>to leverage large-scale off-the-shelf image diffusion models\\n<br>as a teacher signal in combination with an adversarial loss\\n<br>to ensure high image ﬁdelity even in the low-step regime\\n<br>of one or two sampling steps. Our analyses show that our\\n<br>model clearly outperforms existing few-step methods (GANs,\\n<br>Latent Consistency Models) in a single step and reaches the\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">performance of state-of-the-art diffusion models (SDXL) in\\n<br>only four steps. ADD is the ﬁrst method to unlock single-step,\\n<br>real-time image synthesis with foundation models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:573px; width:237px; height:189px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Diffusion models (DMs) [20, 63, 65] have taken a central\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">role in the ﬁeld of generative modeling and have recently en-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">abled remarkable advances in high-quality image- [3, 53, 54]\\n<br>and video- [4, 12, 21] synthesis. One of the key strengths of\\n<br>DMs is their scalability and iterative nature, which allows\\n<br>them to handle complex tasks such as image synthesis from\\n<br>free-form text prompts. However, the iterative inference\\n<br>process in DMs requires a signiﬁcant number of sampling\\n<br>steps, which currently hinders their real-time application.\\n<br>Generative Adversarial Networks (GANs) [14, 26, 27], on\\n<br>the other hand, are characterized by their single-step for-\\n<br>mulation and inherent speed. But despite attempts to scale\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">to large datasets[25, 58], GANs often fall short of DMs in\\n<br>terms of sample quality. The aim of this work is to combine\\n<br>the superior sample quality of DMs with the inherent speed\\n<br>of GANs.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:783px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">1\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:203px; width:495px; height:297px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:892px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:892px;\"><a name=\"2\">Page 2</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:966px; width:237px; height:249px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our approach is conceptually simple: We propose </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">Ad-\\n<br>versarial Diffusion Distillation </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(ADD), a general approach\\n<br>that reduces the number of inference steps of a pre-trained\\n<br>diffusion model to 1–4 sampling steps while maintaining\\n<br>high sampling ﬁdelity and potentially further improving the\\n<br>overall performance of the model. To this end, we intro-\\n<br>duce a combination of two training objectives: (i) an </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">ad-\\n<br>versarial loss </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and (ii) a distillation loss that corresponds\\n<br>to </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">score distillation sampling </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(SDS) [51]. The adversar-\\n<br>ial loss forces the model to directly generate samples that\\n<br>lie on the manifold of real images at each forward pass,\\n<br>avoiding blurriness and other artifacts typically observed in\\n<br>other distillation methods [43]. The distillation loss uses\\n<br>another pretrained (and ﬁxed) DM as a teacher to effectively\\n<br>utilize the extensive knowledge of the pretrained DM and\\n<br>preserve the strong compositionality observed in large DMs.\\n<br>During inference, our approach does not use classiﬁer-free\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">guidance [</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">19], further reducing memory requirements. We\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">retain the model’s ability to improve results through iterative\\n<br>reﬁnement, which is an advantage over previous one-step\\n<br>GAN-based approaches [59].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:62px; top:1217px; width:195px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our contributions can be summarized as follows:\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1229px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">• We introduce ADD, a method for turning pretrained diffu-\\n<br>sion models into high-ﬁdelity, real-time image generators\\n<br>using only 1–4 sampling steps.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1265px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">• Our method uses a novel combination of adversarial train-\\n<br>ing and score distillation, for which we carefully ablate\\n<br>several design choices.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1301px; width:237px; height:70px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">• ADD signiﬁcantly outperforms strong baselines such as\\n<br>LCM, LCM-XL [38] and single-step GANs [59], and is\\n<br>able to handle complex image compositions while main-\\n<br>taining high image realism at only a single inference step.\\n<br>• Using four sampling steps, ADD-XL outperforms its\\n<br>teacher model SDXL-Base at a resolution of </span><span style=\"font-family: CMR10; font-size:9px\">512</span><span style=\"font-family: CMR7; font-size:6px\">2 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">px.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1383px; width:74px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">2. Background\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:1403px; width:238px; height:201px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">While diffusion models achieve remarkable performance in\\n<br>synthesizing and editing high-resolution images [3, 53, 54]\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and videos [4, 21], their iterative nature hinders real-time ap-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">plication. Latent diffusion models [54] attempt to solve this\\n<br>problem by representing images in a more computationally\\n<br>feasible latent space [11], but they still rely on the iterative\\n<br>application of large models with billions of parameters. In\\n<br>addition to utilizing faster samplers for diffusion models\\n<br>[8, 37, 64, 74], there is a growing body of research on model\\n<br>distillation such as progressive distillation [56] and guidance\\n<br>distillation [43]. These approaches reduce the number of\\n<br>iterative sampling steps to 4-8, but may signiﬁcantly lower\\n<br>the original performance. Furthermore, they require an it-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">erative training process. Consistency models [66] address\\n<br>the latter issue by enforcing a consistency regularization on\\n<br>the ODE trajectory and demonstrate strong performance for\\n<br>pixel-based models in the few-shot setting. LCMs [38] focus\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1192px; width:236px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 2. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Adversarial Diffusion Distillation. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">The ADD-student\\n<br>is trained as a denoiser that receives diffused input images </span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">and outputs samples </span><span style=\"font-family: CMR9; font-size:8px\">ˆ</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">θ</span><span style=\"font-family: CMR9; font-size:8px\">(</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">s</span><span style=\"font-family: CMMI9; font-size:8px\">, s</span><span style=\"font-family: CMR9; font-size:8px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">and optimizes two objectives: a)\\n<br>adversarial loss: the model aims to fool a discriminator which is\\n<br>trained to distinguish the generated samples </span><span style=\"font-family: CMR9; font-size:8px\">ˆ</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">from real images\\n<br></span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMR6; font-size:5px\">0</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">. b) distillation loss: the model is trained to match the denoised\\n<br>targets </span><span style=\"font-family: CMR9; font-size:8px\">ˆ</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">ψ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">of a frozen DM teacher.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1293px; width:237px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">on distilling latent diffusion models and achieve impressive\\n<br>performance at 4 sampling steps. Recently, LCM-LoRA [40]\\n<br>introduced a low-rank adaptation [22] training for efﬁciently\\n<br>learning LCM modules, which can be plugged into differ-\\n<br>ent checkpoints for SD and SDXL [50, 54]. InstaFlow [36]\\n<br>propose to use Rectiﬁed Flows [35] to facilitate a better\\n<br>distillation process.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1378px; width:238px; height:165px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">All of these methods share common ﬂaws: samples syn-\\n<br>thesized in four steps often look blurry and exhibit noticeable\\n<br>artifacts. At fewer sampling steps, this problem is further am-\\n<br>pliﬁed. GANs [14] can also be trained as standalone single-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">step models for text-to-image synthesis [25, 59]. Their sam-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">pling speed is impressive, yet the performance lags behind\\n<br>diffusion-based models. In part, this can be attributed to the\\n<br>ﬁnely balanced GAN-speciﬁc architectures necessary for sta-\\n<br>ble training of the adversarial objective. Scaling these mod-\\n<br>els and integrating advances in neural network architectures\\n<br>without disturbing the balance is notoriously challenging.\\n<br>Additionally, current state-of-the-art text-to-image GANs\\n<br>do not have a method like classiﬁer-free guidance available\\n<br>which is crucial for DMs at scale.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1547px; width:236px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Score Distillation Sampling [51] also known as Score\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Jacobian Chaining [68] is a recently proposed method that\\n<br>has been developed to distill the knowledge of foundational\\n<br>T2I Models into 3D synthesis models. While the majority of\\n<br>SDS-based works [45, 51, 68, 69] use SDS in the context of\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:1625px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">2\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:245px; top:963px; width:342px; height:443px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:245px; top:963px; width:342px; height:442px;\"></span>\\n<div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:434px; top:1040px; width:49px; height:146px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:435px; top:1009px; width:48px; height:147px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:436px; top:972px; width:48px; height:49px;\"></div><span style=\"position:absolute; border: black 1px solid; left:449px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:449px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:450px; top:1090px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:450px; top:1090px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1093px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1094px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1093px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1094px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:457px; top:1090px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:457px; top:1090px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:460px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:460px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:464px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:464px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:467px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:467px; top:1094px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:471px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:471px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:474px; top:1090px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:474px; top:1090px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:457px; top:1024px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:457px; top:1024px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:461px; top:1024px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:462px; top:1025px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:461px; top:1024px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:462px; top:1025px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:511px; top:1101px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:511px; top:1101px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:514px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:514px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:517px; top:1100px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:517px; top:1100px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:1099px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:1101px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:1099px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:1101px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:527px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:527px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:529px; top:1101px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:529px; top:1101px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:530px; top:1099px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:530px; top:1099px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1102px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1102px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1104px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1102px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1102px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1104px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:537px; top:1104px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:537px; top:1104px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:540px; top:1101px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:540px; top:1101px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:541px; top:1099px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:541px; top:1099px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:545px; top:1102px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:545px; top:1102px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:549px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:549px; top:1099px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:528px; top:1030px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:528px; top:1030px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1030px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1030px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1030px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1030px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:535px; top:1030px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:536px; top:1032px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:535px; top:1030px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:536px; top:1032px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:539px; top:1028px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:539px; top:1028px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:316px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:316px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:326px; top:1093px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:326px; top:1094px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:326px; top:1093px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:326px; top:1094px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:1092px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:1092px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:1092px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:1092px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:342px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:342px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1093px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:1093px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1093px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:1093px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1091px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1091px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:358px; top:1092px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:1093px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:358px; top:1092px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:1093px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1094px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:366px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:366px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:382px; top:1090px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1092px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:382px; top:1090px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1092px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:1091px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:1091px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:393px; top:1091px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:395px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:393px; top:1091px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:395px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1094px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1094px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:404px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:404px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:407px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:407px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:412px; top:1090px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:412px; top:1093px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:412px; top:1090px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:412px; top:1093px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:416px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:417px; top:1093px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:416px; top:1092px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:417px; top:1093px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:419px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:419px; top:1092px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:423px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:423px; top:1091px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:379px; top:1043px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:379px; top:1043px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1043px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1043px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:519px; top:1034px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:524px; top:1033px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:524px; top:1033px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1160px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:385px; top:1160px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1160px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:385px; top:1160px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1160px; width:6px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1160px; width:6px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:396px; top:1163px; width:2px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:396px; top:1163px; width:2px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1160px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1160px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:405px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:406px; top:1163px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:405px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:406px; top:1163px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:409px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:409px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:412px; top:1160px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:412px; top:1160px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:417px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:417px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:417px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:417px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:420px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:420px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:428px; top:1133px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1131px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1131px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:369px; top:1132px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1131px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1131px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:427px; top:1064px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1063px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1063px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:369px; top:1065px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:372px; top:1063px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:372px; top:1063px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:490px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1001px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:490px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1001px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:494px; top:998px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:495px; top:1000px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:494px; top:998px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:495px; top:1000px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:498px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:498px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:502px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1000px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:502px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1000px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:508px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:508px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:511px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:512px; top:1001px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:511px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:512px; top:1001px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:515px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:515px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:998px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:1000px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:998px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:1000px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:521px; top:1001px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:521px; top:1001px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:524px; top:998px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:524px; top:998px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:528px; top:998px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:528px; top:998px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:530px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1000px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:530px; top:1000px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1000px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:534px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:537px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:537px; top:1000px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1084px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1086px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1084px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1086px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:497px; top:1084px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:497px; top:1086px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:497px; top:1084px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:497px; top:1086px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:499px; top:1086px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:499px; top:1086px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:502px; top:1084px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:502px; top:1084px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1084px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1086px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1084px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1086px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:507px; top:1084px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:507px; top:1084px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:509px; top:1084px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:509px; top:1084px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:511px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:512px; top:1087px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:511px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:512px; top:1087px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:515px; top:1084px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:515px; top:1084px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:1084px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:1086px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:1084px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:518px; top:1086px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1086px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:520px; top:1086px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:530px; top:1084px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:530px; top:1084px; width:1px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1086px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1086px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1086px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:535px; top:1086px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:535px; top:1086px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:538px; top:1086px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:538px; top:1086px; width:2px; height:3px;\"></span>\\n<div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:320px; top:1039px; width:48px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:319px; top:1109px; width:49px; height:146px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:320px; top:582px; width:368px; height:574px;\"><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:219px; top:1108px; width:149px; height:48px;\"></div></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:320px; top:443px; width:368px; height:644px;\"><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:220px; top:1038px; width:148px; height:49px;\"></div></div><span style=\"position:absolute; border: black 1px solid; left:318px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:318px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:319px; top:1159px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:319px; top:1159px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:323px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:323px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:323px; top:1164px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:323px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:323px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:323px; top:1164px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:325px; top:1165px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:325px; top:1165px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:326px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:326px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:331px; top:1162px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:331px; top:1164px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:331px; top:1162px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:331px; top:1164px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:1162px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:340px; top:1162px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:1162px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:340px; top:1162px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:1159px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:1159px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1164px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1162px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1164px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:356px; top:1160px; width:4px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:356px; top:1160px; width:4px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1162px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1162px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1162px; width:4px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1162px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:370px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:370px; top:1162px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1159px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1159px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:459px; top:1099px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:459px; top:1101px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:457px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:454px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:452px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:449px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:447px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:444px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:442px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:440px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:437px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:435px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:432px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:430px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:428px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:425px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:423px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:420px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:418px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:416px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:413px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:411px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:408px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:406px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:396px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:391px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:387px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:382px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:379px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:375px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:372px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:370px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:365px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:362px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:360px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:358px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:355px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:353px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:350px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:348px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:343px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:1103px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:340px; top:1104px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:340px; top:1107px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:1106px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:1106px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:494px; top:1011px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:494px; top:1011px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:484px; top:1009px; width:7px; height:12px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1020px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1020px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:484px; top:1106px; width:19px; height:24px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1104px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1104px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:484px; top:1040px; width:7px; height:12px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1038px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1038px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:483px; top:1076px; width:19px; height:24px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1099px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1099px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:489px; top:1057px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1058px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:489px; top:1057px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1058px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:495px; top:1057px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:495px; top:1059px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:495px; top:1057px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:495px; top:1059px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:497px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:497px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:500px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:500px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:503px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1057px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1059px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1057px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1059px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:508px; top:1059px; width:5px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:508px; top:1059px; width:5px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:515px; top:1057px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:514px; top:1059px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:515px; top:1057px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:514px; top:1059px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:516px; top:1059px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:516px; top:1059px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:521px; top:1059px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:521px; top:1061px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:521px; top:1059px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:521px; top:1061px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:524px; top:1058px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:524px; top:1058px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:527px; top:1059px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:528px; top:1059px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:527px; top:1059px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:528px; top:1059px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1059px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1102px; width:8px; height:8px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:491px; top:1103px; width:8px; height:8px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:490px; top:1115px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:490px; top:1115px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1114px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:493px; top:1114px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:496px; top:1115px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:496px; top:1115px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:496px; top:1115px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:496px; top:1115px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:499px; top:1115px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:501px; top:1115px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:499px; top:1115px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:501px; top:1115px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1115px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1115px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1119px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1115px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1115px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:506px; top:1119px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:509px; top:1115px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:509px; top:1115px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:512px; top:1115px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:513px; top:1117px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:512px; top:1115px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:513px; top:1117px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:516px; top:1113px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:517px; top:1115px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:516px; top:1113px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:517px; top:1115px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:504px; top:1031px; width:3px; height:6px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:504px; top:1033px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1033px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:504px; top:1031px; width:3px; height:6px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:504px; top:1033px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:505px; top:1033px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1057px; width:7px; height:16px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1062px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1062px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1065px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1062px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1062px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1065px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:379px; top:1111px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:379px; top:1111px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1111px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1111px; width:24px; height:44px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1125px; width:7px; height:16px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1130px; width:4px; height:6px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1130px; width:4px; height:6px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:406px; top:1131px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:405px; top:1130px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:314px; top:996px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:314px; top:996px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:317px; top:998px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:317px; top:998px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:996px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:996px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:324px; top:993px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:324px; top:993px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:328px; top:997px; width:5px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:328px; top:997px; width:5px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:994px; width:7px; height:6px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:994px; width:7px; height:6px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:994px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:995px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:994px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:995px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:350px; top:998px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:350px; top:998px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:354px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:354px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:355px; top:994px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:355px; top:994px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:362px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:362px; top:994px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:315px; top:976px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:315px; top:976px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:975px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:975px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:327px; top:974px; width:5px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:327px; top:974px; width:5px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:332px; top:977px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:332px; top:977px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:977px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:977px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:336px; top:978px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:336px; top:978px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:976px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:978px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:976px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:978px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:342px; top:977px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:342px; top:978px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:342px; top:977px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:342px; top:978px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:978px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:978px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:977px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:977px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:352px; top:976px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:352px; top:977px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:352px; top:976px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:352px; top:977px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:360px; top:973px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:360px; top:973px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:976px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:976px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:976px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:976px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:371px; top:978px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:371px; top:978px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:374px; top:978px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:978px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:381px; top:978px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:374px; top:978px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:978px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:381px; top:978px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:976px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:976px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:387px; top:978px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:387px; top:978px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:391px; top:973px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:391px; top:973px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:459px; top:1027px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:459px; top:1030px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:457px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:455px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:452px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:450px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:448px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:445px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:443px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:440px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:438px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:435px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:433px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:428px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:426px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:423px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:421px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:419px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:416px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:414px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:411px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:409px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:407px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:404px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:402px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:399px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:397px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:392px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:390px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:387px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:385px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:382px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:380px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:378px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:375px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:370px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:368px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:365px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:361px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:358px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:356px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:353px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:349px; top:1032px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1033px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:345px; top:1034px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:1036px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:1036px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:525px; top:1036px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:525px; top:1036px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:529px; top:1036px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:529px; top:1036px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1038px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1040px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:531px; top:1038px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:532px; top:1040px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:535px; top:1036px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:535px; top:1036px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:539px; top:1038px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:539px; top:1038px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:539px; top:1038px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:539px; top:1038px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:446px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:446px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:447px; top:1160px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:447px; top:1160px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:451px; top:1163px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:451px; top:1163px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:455px; top:1160px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:455px; top:1160px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:458px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:458px; top:1162px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:459px; top:1160px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:459px; top:1160px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:462px; top:1163px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:463px; top:1163px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:463px; top:1165px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:462px; top:1163px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:463px; top:1163px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:463px; top:1165px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:465px; top:1166px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:465px; top:1166px; width:0px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:466px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:466px; top:1163px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:469px; top:1164px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:469px; top:1164px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:472px; top:1161px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:472px; top:1161px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:475px; top:1160px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:475px; top:1160px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:315px; top:985px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:315px; top:985px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:320px; top:986px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:320px; top:986px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:327px; top:985px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:327px; top:985px; width:5px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:331px; top:988px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:331px; top:988px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:989px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:989px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:336px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:336px; top:990px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:336px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:336px; top:990px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:987px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:987px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:989px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:989px; width:2px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:344px; top:989px; width:1px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:989px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:989px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:987px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:989px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:987px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:351px; top:989px; width:5px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:984px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:984px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:985px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:363px; top:985px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:989px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:989px; width:0px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:370px; top:989px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:374px; top:989px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:989px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:370px; top:989px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:374px; top:989px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:989px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:380px; top:985px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:380px; top:985px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:985px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:385px; top:985px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:985px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:385px; top:985px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:985px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:985px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:985px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:985px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:391px; top:985px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:392px; top:985px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:391px; top:985px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:392px; top:985px; width:1px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:395px; top:984px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:395px; top:984px; width:2px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:362px; top:1025px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:362px; top:1025px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:364px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:365px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:364px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:365px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:368px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:368px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:371px; top:1027px; width:5px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:371px; top:1027px; width:5px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:1029px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:377px; top:1029px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:380px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:380px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:383px; top:1025px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:383px; top:1025px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1025px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:390px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1025px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:390px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1025px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1027px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1025px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1027px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:396px; top:1025px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:396px; top:1025px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:398px; top:1025px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:398px; top:1025px; width:2px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:400px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:400px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:405px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:405px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:408px; top:1025px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:407px; top:1027px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:408px; top:1025px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:407px; top:1027px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:410px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:410px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:410px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:410px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:413px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:413px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:419px; top:1027px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:421px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:419px; top:1027px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:421px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:424px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:424px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:427px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:427px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:427px; top:1027px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:427px; top:1027px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:431px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:434px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:435px; top:1027px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:434px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:435px; top:1027px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:437px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:437px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:440px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:440px; top:1027px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:337px; top:1006px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:338px; top:1008px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:337px; top:1006px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:338px; top:1008px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:1006px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:1008px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:1006px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:341px; top:1008px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:343px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:343px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1006px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:346px; top:1006px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:349px; top:1008px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:350px; top:1009px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:349px; top:1008px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:350px; top:1009px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:353px; top:1008px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:353px; top:1008px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:357px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:357px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:360px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:361px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:360px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:361px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:366px; top:1008px; width:5px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:366px; top:1008px; width:5px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:372px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:372px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:373px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:375px; top:1006px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:375px; top:1006px; width:2px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:378px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:378px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:381px; top:1006px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:381px; top:1008px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:381px; top:1006px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:381px; top:1008px; width:1px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:383px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:383px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:388px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:389px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:392px; top:1010px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:392px; top:1010px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1008px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:395px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1011px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1008px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:395px; top:1008px; width:1px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:394px; top:1011px; width:2px; height:1px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:398px; top:1010px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:398px; top:1010px; width:0px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:401px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:403px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:404px; top:1006px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:404px; top:1006px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:411px; top:1007px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:411px; top:1007px; width:4px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:418px; top:1006px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:418px; top:1006px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:422px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:422px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:424px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:424px; top:1004px; width:0px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:426px; top:1003px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:426px; top:1003px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:426px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:426px; top:1008px; width:2px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:314px; top:1005px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:314px; top:1007px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:314px; top:1005px; width:3px; height:5px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:314px; top:1007px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:318px; top:1005px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:318px; top:1005px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:1007px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:321px; top:1007px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:325px; top:1009px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:325px; top:1009px; width:1px; height:2px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:328px; top:1007px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:328px; top:1007px; width:3px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:332px; top:1005px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:332px; top:1005px; width:1px; height:7px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:1734px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:1734px;\"><a name=\"3\">Page 3</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:95px; top:1805px; width:211px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A cinematic shot of a professor sloth wearing a tuxedo at a\\n<br>BBQ party.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:326px; top:1805px; width:222px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A high-quality photo of a confused bear in calculus class. The\\n<br>bear is wearing a party hat and steampunk armor.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1855px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1843px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br>D\\n<br>A\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:1846px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1910px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1898px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:1902px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1966px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1954px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:1956px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2022px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2010px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2055px; width:8px; height:56px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">+\\n<br>+\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">T\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">N\\n<br>A\\n<br>G\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">l\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">y\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2123px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">w\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">o\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">l\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">F\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">I\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2174px; width:8px; height:44px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">E\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">U\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">O\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2012px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2069px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2127px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2179px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">6\\n<br>1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2233px; width:495px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 3. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Qualitative comparison to state-of-the-art fast samplers. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Single step samples from our ADD-XL (top) and LCM-XL [40], our\\n<br>custom StyleGAN-T [59] baseline, InstaFlow [36] and MUSE. For MUSE, we use the </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">OpenMUSE </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">implementation and default inference\\n<br>settings with 16 sampling steps. For LCM-XL, we sample with 1, 2 and 4 steps. Our model outperforms all other few-step samplers in a\\n<br>single step.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2298px; width:236px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">per-scene optimization for 3D objects, the approach has also\\n<br>been applied to text-to-3D-video-synthesis [62] and in the\\n<br>context of image editing [16].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2338px; width:237px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Recently, the authors of [13] have shown a strong relation-\\n<br>ship between score-based models and GANs and propose\\n<br>Score GANs, which are trained using score-based diffusion\\n<br>ﬂows from a DM instead of a discriminator. Similarly, Diff-\\n<br>Instruct [42], a method which generalizes SDS, enables to\\n<br>distill a pretrained diffusion model into a generator without\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">discriminator.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2298px; width:237px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">faster sampling, Denoising Diffusion GANs [70] are intro-\\n<br>duced as a method to enable sampling with few steps. To\\n<br>improve quality, a discriminator loss is added to the score\\n<br>matching objective in Adversarial Score Matching [24] and\\n<br>the consistency objective of CTM [29].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2358px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our method combines adversarial training and score dis-\\n<br>tillation in a hybrid objective to address the issues in current\\n<br>top performing few-step generative models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2404px; width:51px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">3. Method\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2425px; width:237px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Conversely, there are also approaches which aim to im-\\n<br>prove the diffusion process using adversarial training. For\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2425px; width:237px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our goal is to generate high-ﬁdelity samples in as few sam-\\n<br>pling steps as possible, while matching the quality of state-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:2467px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">3\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1830px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1830px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1886px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1886px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1942px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1942px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1997px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1997px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:2053px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:2053px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:2111px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:2111px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:2167px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:2167px; width:222px; height:55px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:2576px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:2576px;\"><a name=\"4\">Page 4</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:84px; top:2647px; width:130px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A brain riding a rocketship heading\\n<br>towards the moon.”\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:239px; top:2647px; width:147px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A bald eagle made of chocolate powder,\\n<br>mango, and whipped cream”\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:434px; top:2658px; width:77px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A blue colored dog.”\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:55px; top:2688px; width:8px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:55px; top:2736px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:55px; top:2786px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2831px; width:495px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 4. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Qualitative effect of sampling steps. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We show qualitative examples when sampling ADD-XL with 1, 2, and 4 steps. Single-step\\n<br>samples are often already of high quality, but increasing the number of steps can further improve the consistency (e.g. second prompt, ﬁrst\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">column) and attention to detail (e.g. second prompt, second column). The seeds are constant within columns and we see that the general\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">layout is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:2888px; width:238px; height:213px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">of-the-art models [7, 50, 53, 55]. The adversarial objec-\\n<br>tive [14, 60] naturally lends itself to fast generation as it\\n<br>trains a model that outputs samples on the image manifold in\\n<br>a single forward step. However, attempts at scaling GANs to\\n<br>large datasets [58, 59] observed that is critical to not solely\\n<br>rely on the discriminator, but also employ a pretrained clas-\\n<br>siﬁer or CLIP network for improving text alignment. As\\n<br>remarked in [59], overly utilizing discriminative networks\\n<br>introduces artifacts and image quality suffers. Instead, we\\n<br>utilize the gradient of a pretrained diffusion model via a score\\n<br>distillation objective to improve text alignment and sample\\n<br>quality. Furthermore, instead of training from scratch, we\\n<br>initialize our model with pretrained diffusion model weights;\\n<br>pretraining the generator network is known to signiﬁcantly\\n<br>improve training with an adversarial loss [15]. Lastly, in-\\n<br>stead of utilizing a decoder-only architecture used for GAN\\n<br>training [26, 27], we adapt a standard diffusion model frame-\\n<br>work. This setup naturally enables iterative reﬁnement.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:3115px; width:110px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">3.1. Training Procedure\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:3135px; width:238px; height:153px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our training procedure is outlined in Fig. 2 and involves three\\n<br>networks: The ADD-student is initialized from a pretrained\\n<br>UNet-DM with weights </span><span style=\"font-family: CMMI10; font-size:9px\">θ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, a discriminator with trainable\\n<br>weights </span><span style=\"font-family: CMMI10; font-size:9px\">ϕ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, and a DM teacher with frozen weights </span><span style=\"font-family: CMMI10; font-size:9px\">ψ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. Dur-\\n<br>ing training, the ADD-student generates samples </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">from noisy data </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. The noised data points are produced\\n<br>from a dataset of real images </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">via a forward diffusion\\n<br>process </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0 </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. In our experiments, we use the\\n<br>same coefﬁcients </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">s </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">s </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">as the student DM and sam-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">ple </span><span style=\"font-family: CMMI10; font-size:9px\">s </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">uniformly from a set </span><span style=\"font-family: CMMI10; font-size:9px\">T</span><span style=\"font-family: CMR7; font-size:6px\">student </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMSY10; font-size:9px\">{</span><span style=\"font-family: CMMI10; font-size:9px\">τ</span><span style=\"font-family: CMR7; font-size:6px\">1</span><span style=\"font-family: CMMI10; font-size:9px\">, ..., τ</span><span style=\"font-family: CMMI7; font-size:6px\">n</span><span style=\"font-family: CMSY10; font-size:9px\">} </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">of </span><span style=\"font-family: CMMI10; font-size:9px\">N\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">chosen student timesteps. In practice, we choose </span><span style=\"font-family: CMMI10; font-size:9px\">N </span><span style=\"font-family: CMR10; font-size:9px\">= 4</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\\n<br>Importantly, we set </span><span style=\"font-family: CMMI10; font-size:9px\">τ</span><span style=\"font-family: CMMI7; font-size:6px\">n </span><span style=\"font-family: CMR10; font-size:9px\">= 1000 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and enforce zero-terminal\\n<br>SNR [33] during training, as the model needs to start from\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2888px; width:111px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">pure noise during inference.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2900px; width:237px; height:105px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For the adversarial objective, the generated samples </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and real images </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">are passed to the discriminator which\\n<br>aims to distinguish between them. The design of the dis-\\n<br>criminator and the adversarial loss are described in detail in\\n<br>Sec. 3.2. To distill knowledge from the DM teacher, we dif-\\n<br>fuse student samples </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">with the teacher’s forward process to\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, and use the teacher’s denoising prediction </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMMI10; font-size:9px\">, t</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">as a reconstruction target for the distillation loss </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">distill</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">,\\n<br>see Section 3.3. Thus, the overall objective is\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:323px; top:3015px; width:33px; height:12px;\"><span style=\"font-family: CMSY10; font-size:9px\">L </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">G\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:350px; top:3017px; width:169px; height:11px;\"><span style=\"font-family: CMR7; font-size:6px\">adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">) + </span><span style=\"font-family: CMMI10; font-size:9px\">λ</span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">distill</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ψ</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:3017px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(1)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3038px; width:238px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">While we formulate our method in pixel space, it is\\n<br>straightforward to adapt it to LDMs operating in latent space.\\n<br>When using LDMs with a shared latent space for teacher\\n<br>and student, the distillation loss can be computed in pixel or\\n<br>latent space. We compute the distillation loss in pixel space\\n<br>as this yields more stable gradients when distilling latent\\n<br>diffusion model [72].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3128px; width:98px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">3.2. Adversarial Loss\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3147px; width:238px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For the discriminator, we follow the proposed design and\\n<br>training procedure in [59] which we brieﬂy summarize; for\\n<br>details, we refer the reader to the original work. We use a\\n<br>frozen pretrained feature network </span><span style=\"font-family: CMMI10; font-size:9px\">F </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and a set of trainable\\n<br>lightweight discriminator heads </span><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. For the feature net-\\n<br>work </span><span style=\"font-family: CMMI10; font-size:9px\">F </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, Sauer et al. [59] ﬁnd vision transformers (ViTs) [9]\\n<br>to work well, and we ablate different choice for the ViTs\\n<br>objective and model size in Section 4. The trainable discrim-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">inator heads are applied on features </span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">at different layers of\\n<br>the feature network.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3267px; width:237px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">To improve performance, the discriminator can be condi-\\n<br>tioned on additional information via projection [46]. Com-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:3309px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">4\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:76px; top:2672px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:238px; top:2672px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:399px; top:2672px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:76px; top:2722px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:238px; top:2722px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:399px; top:2722px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:76px; top:2771px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:238px; top:2771px; width:148px; height:49px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:399px; top:2771px; width:148px; height:49px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:3418px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:3418px;\"><a name=\"5\">Page 5</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:3648px; width:495px; height:31px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 5. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">single step</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-XL (1-step) against established baselines. ADD-XL\\n<br>model outperforms all models, except SDXL in human preference for both image quality and prompt alignment. Using more sampling steps\\n<br>further improves our model (bottom row).\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:3702px; width:237px; height:106px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">monly, a text embedding </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">text </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">is used in the text-to-image\\n<br>setting. But, in contrast to standard GAN training, our train-\\n<br>ing conﬁguration also allows to condition on a given image.\\n<br>For </span><span style=\"font-family: CMMI10; font-size:9px\">τ &lt; </span><span style=\"font-family: CMR10; font-size:9px\">1000</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, the ADD-student receives some signal from\\n<br>the input image </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. Therefore, for a given generated sample\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, we can condition the discriminator on information\\n<br>from </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. This encourages the ADD-student to utilize the\\n<br>input effectively. In practice, we use an additional feature\\n<br>network to extract an image embedding </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">img</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:3810px; width:238px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Following [57, 59], we use the hinge loss [32] as the\\n<br>adversarial objective function. Thus the ADD-student’s ad-\\n<br>versarial objective </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">amounts to\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:76px; top:3853px; width:13px; height:12px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">G\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:83px; top:3855px; width:68px; height:11px;\"><span style=\"font-family: CMR7; font-size:6px\">adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:99px; top:3872px; width:66px; height:18px;\"><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMSY10; font-size:9px\">−</span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">s,ϵ,x</span><span style=\"font-family: CMR5; font-size:4px\">0 </span><span style=\"font-family: CMEX10; font-size:9px\">h X\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:156px; top:3888px; width:4px; height:6px;\"><span style=\"font-family: CMMI7; font-size:6px\">k\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:167px; top:3874px; width:92px; height:13px;\"><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)))</span><span style=\"font-family: CMEX10; font-size:9px\">i </span><span style=\"font-family: CMMI10; font-size:9px\">,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:275px; top:3869px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(2)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:3904px; width:192px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">whereas the discriminator is trained to minimize\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:3921px; width:75px; height:36px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">D\\n<br>adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br>= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">x</span><span style=\"font-family: CMR5; font-size:4px\">0 </span><span style=\"font-family: CMEX10; font-size:9px\">h X\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:106px; top:3956px; width:4px; height:6px;\"><span style=\"font-family: CMMI7; font-size:6px\">k\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:117px; top:3942px; width:158px; height:13px;\"><span style=\"font-family: CMR10; font-size:9px\">max(0</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">1 </span><span style=\"font-family: CMSY10; font-size:9px\">− D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0</span><span style=\"font-family: CMR10; font-size:9px\">))) + </span><span style=\"font-family: CMMI10; font-size:9px\">γR</span><span style=\"font-family: CMR10; font-size:9px\">1(</span><span style=\"font-family: CMMI10; font-size:9px\">ϕ</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMEX10; font-size:9px\">i\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:70px; top:3968px; width:45px; height:18px;\"><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMR7; font-size:6px\">ˆ</span><span style=\"font-family: CMMI7; font-size:6px\">x</span><span style=\"font-family: CMMI5; font-size:4px\">θ </span><span style=\"font-family: CMEX10; font-size:9px\">h X\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:107px; top:3984px; width:4px; height:6px;\"><span style=\"font-family: CMMI7; font-size:6px\">k\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:118px; top:3970px; width:118px; height:13px;\"><span style=\"font-family: CMR10; font-size:9px\">max(0</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">1 + </span><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">)))</span><span style=\"font-family: CMEX10; font-size:9px\">i </span><span style=\"font-family: CMMI10; font-size:9px\">,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3702px; width:238px; height:105px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where sg denotes the stop-gradient operation. Intuitively,\\n<br>the loss uses a distance metric </span><span style=\"font-family: CMMI10; font-size:9px\">d </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">to measure the mis-\\n<br>match between generated samples </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">by the ADD-student\\n<br>and the DM-teacher’s outputs </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMMI10; font-size:9px\">, t</span><span style=\"font-family: CMR10; font-size:9px\">) = (ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t </span><span style=\"font-family: CMSY10; font-size:9px\">−\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMMI10; font-size:9px\">, t</span><span style=\"font-family: CMR10; font-size:9px\">))</span><span style=\"font-family: CMMI10; font-size:9px\">/α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">averaged over timesteps </span><span style=\"font-family: CMMI10; font-size:9px\">t </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and noise </span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMSY7; font-size:6px\">′</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\\n<br>Notably, the teacher is not directly applied on generations\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">of the ADD-student but instead on diffused outputs\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMSY7; font-size:6px\">′</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, as non-diffused inputs would be out-of-\\n<br>distribution for the teacher model [68].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3811px; width:238px; height:165px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">In the following, we deﬁne the distance function\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x, y</span><span style=\"font-family: CMR10; font-size:9px\">) := </span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMMI10; font-size:9px\">x </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">y</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\\n<br>2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. Regarding the weighting function\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, we consider two options: exponential weighting, where\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(higher noise levels contribute less), and score dis-\\n<br>tillation sampling (SDS) weighting [51]. In the supplemen-\\n<br>tary material, we demonstrate that with </span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x, y</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMMI10; font-size:9px\">x </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">y</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\\n<br>2\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and a speciﬁc choice for </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, our distillation loss becomes\\n<br>equivalent to the SDS objective </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">SDS</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, as proposed in [51].\\n<br>The advantage of our formulation is its ability to enable\\n<br>direct visualization of the reconstruction targets and that\\n<br>it naturally facilitates the execution of several consecutive\\n<br>denoising steps. Lastly, we also evaluate noise-free score\\n<br>distillation (NFSD) objective, a recently proposed variant of\\n<br>SDS [28].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:275px; top:3992px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(3)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3991px; width:77px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">4. Experiments\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4012px; width:236px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR10; font-size:9px\">1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">denotes the R1 gradient penalty [44]. Rather\\n<br>than computing the gradient penalty with respect to the pixel\\n<br>values, we compute it on the input of each discriminator head\\n<br></span><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. We ﬁnd that the </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR10; font-size:9px\">1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">penalty is particularly beneﬁcial\\n<br>when training at output resolutions larger than </span><span style=\"font-family: CMR10; font-size:9px\">128</span><span style=\"font-family: CMR7; font-size:6px\">2 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">px.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4079px; width:123px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">3.3. Score Distillation Loss\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4098px; width:185px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">The distillation loss in Eq. (1) is formulated as\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4012px; width:238px; height:105px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For our experiments, we train two models of different ca-\\n<br>pacities, ADD-M (860M parameters) and ADD-XL (3.1B\\n<br>parameters). For ablating ADD-M, we use a Stable Dif-\\n<br>fusion (SD) 2.1 backbone [54], and for fair comparisons\\n<br>with other baselines, we use SD1.5. ADD-XL utilizes a\\n<br>SDXL [50] backbone. All experiments are conducted at\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">a standardized resolution of 512x512 pixels; outputs from\\n<br>models generating higher resolutions are down-sampled to\\n<br>this size.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:80px; top:4118px; width:83px; height:26px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">distill</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ψ</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:139px; top:4141px; width:4px; height:9px;\"><span style=\"font-family: CMEX10; font-size:9px\">(cid:2)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:143px; top:4134px; width:103px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(sg(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">); </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">))\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:252px; top:4134px; width:2px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:247px; top:4141px; width:4px; height:9px;\"><span style=\"font-family: CMEX10; font-size:9px\">(cid:3)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:275px; top:4126px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(4)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4121px; width:236px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">We employ a distillation weighting factor of </span><span style=\"font-family: CMMI10; font-size:9px\">λ </span><span style=\"font-family: CMR10; font-size:9px\">= 2</span><span style=\"font-family: CMMI10; font-size:9px\">.</span><span style=\"font-family: CMR10; font-size:9px\">5\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">across all experiments. Additionally, the R1 penalty strength\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:4151px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">5\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:3489px; width:242px; height:147px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:3489px; width:242px; height:147px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:4260px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:4260px;\"><a name=\"6\">Page 6</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:66px; top:4330px; width:19px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Arch\\n<br>ViT-S\\n<br>ViT-S\\n<br>ViT-L\\n<br>ViT-L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:98px; top:4330px; width:57px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Objective FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">21.5\\n<br>DINOv1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">DINOv2\\n<br>24.0\\n<br>DINOv2\\n<br>23.3\\n<br>CLIP\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:168px; top:4330px; width:17px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.312\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.319\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.302\\n<br>0.308\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:242px; top:4329px; width:16px; height:49px;\"><span style=\"font-family: CMMI8; font-size:7px\">c</span><span style=\"font-family: CMR6; font-size:5px\">text\\n<br></span><span style=\"font-family: Dingbats; font-size:7px\">✗\\n<br>✓\\n<br>✗\\n<br>✓\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:274px; top:4329px; width:15px; height:49px;\"><span style=\"font-family: CMMI8; font-size:7px\">c</span><span style=\"font-family: CMR6; font-size:5px\">img\\n<br></span><span style=\"font-family: Dingbats; font-size:7px\">✗\\n<br>✗\\n<br>✓\\n<br>✓\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:305px; top:4330px; width:19px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">21.2\\n<br>21.2\\n<br>21.1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:4330px; width:17px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.302\\n<br>0.307\\n<br>0.316\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.319\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:416px; top:4330px; width:40px; height:28px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Initialization\\n<br>Random\\n<br>Pretrained\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:476px; top:4330px; width:44px; height:28px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">293.6 0.065\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.319\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:480px; top:4351px; width:13px; height:7px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:52px; top:4383px; width:149px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(a) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Discriminator feature networks</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. Small,\\n<br>modern DINO networks perform best.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:223px; top:4383px; width:148px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(b) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Discriminator conditioning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. Combining\\n<br>image and text conditioning is most effective.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:394px; top:4383px; width:150px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(c) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Student pretraining</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. A randomly initial-\\n<br>ized student network collapses.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:62px; top:4407px; width:59px; height:59px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Loss\\n<br></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv\\n<br></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill\\n<br></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv </span><span style=\"font-family: CMR8; font-size:7px\">+ </span><span style=\"font-family: CMMI8; font-size:7px\">λ</span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill,exp\\n<br></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv </span><span style=\"font-family: CMR8; font-size:7px\">+ </span><span style=\"font-family: CMMI8; font-size:7px\">λ</span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill,sds\\n<br></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv </span><span style=\"font-family: CMR8; font-size:7px\">+</span><span style=\"font-family: CMMI8; font-size:7px\">λ</span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill,nfsd\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:136px; top:4407px; width:19px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">20.8\\n<br>315.6\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">22.3\\n<br>21.8\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:172px; top:4407px; width:17px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.315\\n<br>0.076\\n<br>0.319\\n<br>0.325\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.327\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:238px; top:4407px; width:24px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Student\\n<br>SD2.1\\n<br>SD2.1\\n<br>SDXL\\n<br>SDXL\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:273px; top:4407px; width:25px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Teacher\\n<br>SD2.1\\n<br>SDXL\\n<br>SD2.1\\n<br>SDXL\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:309px; top:4407px; width:19px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">21.3\\n<br>29.3\\n<br>28.41\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:341px; top:4407px; width:17px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.319\\n<br>0.321\\n<br>0.314\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.325\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:429px; top:4407px; width:17px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Steps\\n<br>1\\n<br>2\\n<br>4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:457px; top:4407px; width:19px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">20.8\\n<br>20.3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:489px; top:4407px; width:17px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.319\\n<br></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.321\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.317\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:52px; top:4470px; width:148px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(d) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Loss terms</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. Both losses are needed and\\n<br>exponential weighting of </span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">is beneﬁcial.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:223px; top:4470px; width:148px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(e) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Teacher type</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. The student adopts the\\n<br>teacher’s traits (SDXL has higher FID &amp; CS).\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:394px; top:4470px; width:150px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(f) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Teacher steps</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. A single teacher step is sufﬁ-\\n<br>cient.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4498px; width:496px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Table 1. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">ADD ablation study. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We report COCO zero-shot FID</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">5k </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">(FID) and CLIP score (CS). The results are calculated for a single student\\n<br>step. The default training settings are: DINOv2 ViT-S as the feature network, text and image conditioning for the discriminator, pretrained\\n<br>student weights, a small teacher and student model, and a single teacher step. The training length is 4000 iterations with a batch size of 128.\\n<br>Default settings are marked in gray .\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4559px; width:238px; height:238px;\"><span style=\"font-family: CMMI10; font-size:9px\">γ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">is set to </span><span style=\"font-family: CMR10; font-size:9px\">10</span><span style=\"font-family: CMSY7; font-size:6px\">−</span><span style=\"font-family: CMR7; font-size:6px\">5</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. For discriminator conditioning, we use\\n<br>a pretrained CLIP-ViT-g-14 text encoder [52] to compute\\n<br>text embeddings </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">text </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and the CLS embedding of a DINOv2\\n<br>ViT-L encoder [47] for image embeddings </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">img</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. For the\\n<br>baselines, we use the best publicly available models: La-\\n<br>tent diffusion models [50, 54] (SD1.5</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, SDXL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">) cascaded\\n<br>pixel diffusion models [55] (IF-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">3</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">), distilled diffusion mod-\\n<br>els [39, 41] (LCM-1.5, LCM-1.5-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">4</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">), and OpenMUSE\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">5 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">[48], a reimplementation of MUSE [6], a transformer\\n<br>model speciﬁcally developed for fast inference. Note that\\n<br>we compare to the SDXL-Base-1.0 model without its addi-\\n<br>tional reﬁner model; this is to ensure a fair comparison. As\\n<br>there are no public state-of-the-art GAN models, we retrain\\n<br>StyleGAN-T [59] with our improved discriminator. This\\n<br>baseline (StyleGAN-T++) signiﬁcantly outperforms the pre-\\n<br>vious best GANs in FID and CS, see supplementary. We\\n<br>quantify sample quality via FID [18] and text alignment via\\n<br>CLIP score [17]. For CLIP score, we use ViT-g-14 model\\n<br>trained on LAION-2B [61]. Both metrics are evaluated on\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">5k samples from COCO2017 [34].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4807px; width:90px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">4.1. Ablation Study\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4827px; width:237px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our training setup opens up a number of design spaces re-\\n<br>garding the adversarial loss, distillation loss, initialization,\\n<br>and loss interplay. We conduct an ablation study on several\\n<br>choices in Table 1; key insights are highlighted below each\\n<br>table. We will discuss each experiment in the following.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4892px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Discriminator feature networks.\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1a). Recent\\n<br>insights by Stein et al. [67] suggest that ViTs trained with the\\n<br>CLIP [52] or DINO [5, 47] objectives are particularly well-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:4936px; width:180px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">1</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/CompVis/stable-diffusion\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/Stability-AI/generative-models\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">3</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/deep-ﬂoyd/IF\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">4</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/latent-consistency/lcm-lora-sdxl\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">5</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/openMUSE\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:4993px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4560px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">suited for evaluating the performance of generative models.\\n<br>Similarly, these models also seem effective as discriminator\\n<br>feature networks, with DINOv2 emerging as the best choice.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4607px; width:237px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Discriminator conditioning. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1b). Similar to prior\\n<br>studies, we observe that text conditioning of the discrimi-\\n<br>nator enhances results. Notably, image conditioning outper-\\n<br>forms text conditioning, and the combination of both </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">text\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">img </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">yields the best results.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4677px; width:237px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Student pretraining. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1c). Our experiments demon-\\n<br>strate the importance of pretraining the ADD-student. Being\\n<br>able to use pretrained generators is a signiﬁcant advantage\\n<br>over pure GAN approaches. A problem of GANs is the lack\\n<br>of scalability; both Sauer et al. [59] and Kang et al. [25]\\n<br>observe a saturation of performance after a certain network\\n<br>capacity is reached. This observation contrasts the generally\\n<br>smooth scaling laws of DMs [49]. However, ADD can ef-\\n<br>fectively leverage larger pretrained DMs (see Table 1c) and\\n<br>beneﬁt from stable DM pretraining.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4807px; width:238px; height:165px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Loss terms. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1d). We ﬁnd that both losses are essen-\\n<br>tial. The distillation loss on its own is not effective, but when\\n<br>combined with the adversarial loss, there is a noticeable im-\\n<br>provement in results. Different weighting schedules lead\\n<br>to different behaviours, the exponential schedule tends to\\n<br>yield more diverse samples, as indicated by lower FID, SDS\\n<br>and NFSD schedules improve quality and text alignment.\\n<br>While we use the exponential schedule as the default setting\\n<br>in all other ablations, we opt for the NFSD weighting for\\n<br>training our ﬁnal model. Choosing an optimal weighting\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">function presents an opportunity for improvement. Alterna-\\n<br>tively, scheduling the distillation weights over training, as\\n<br>explored in the 3D generative modeling literature [23] could\\n<br>be considered.\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:62px; top:4340px; width:131px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:129px; top:4350px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:161px; top:4350px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:235px; top:4340px; width:127px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:298px; top:4370px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:330px; top:4370px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:415px; top:4340px; width:109px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:472px; top:4350px; width:25px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:498px; top:4350px; width:25px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:56px; top:4417px; width:143px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:127px; top:4437px; width:35px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:163px; top:4437px; width:35px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:231px; top:4417px; width:135px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:302px; top:4417px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:334px; top:4417px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:424px; top:4417px; width:89px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:450px; top:4417px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:482px; top:4417px; width:31px; height:9px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:160px; top:4531px; width:21px; height:11px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:50px; top:4934px; width:94px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:5102px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:5102px;\"><a name=\"7\">Page 7</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5331px; width:495px; height:31px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 6. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">multiple steps</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-XL (4-step) against established baselines. Our\\n<br>ADD-XL model outperforms all models, including its teacher SDXL 1.0 (base, no reﬁner) [50], in human preference for both image quality\\n<br>and prompt alignment.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5387px; width:21px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">Method\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:156px; top:5387px; width:18px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">#Steps\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:186px; top:5387px; width:23px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">Time (s)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:222px; top:5387px; width:17px; height:7px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">FID </span><span style=\"font-family: CMSY7; font-size:6px\">↓\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:251px; top:5387px; width:20px; height:7px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">CLIP </span><span style=\"font-family: CMSY7; font-size:6px\">↑\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5404px; width:48px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">DPM Solver [37]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5429px; width:78px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">Progressive Distillation [43]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5450px; width:80px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">CFG-Aware Distillation [31]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5463px; width:56px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">InstaFlow-0.9B [36]\\n<br>InstaFlow-1.7B [36]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5484px; width:38px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">UFOGen [71]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5497px; width:23px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">ADD-M\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:162px; top:5400px; width:6px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">25\\n<br>8\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5421px; width:3px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\\n<br>2\\n<br>4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5450px; width:3px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">8\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5463px; width:3px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\\n<br>1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5484px; width:3px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5497px; width:3px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5400px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.88\\n<br>0.34\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5421px; width:12px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\\n<br>0.13\\n<br>0.21\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5450px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.34\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5463px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\\n<br>0.12\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5484px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5497px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5400px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">20.1\\n<br>31.7\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5421px; width:12px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">37.2\\n<br>26.0\\n<br>26.4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5450px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">24.2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5463px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">23.4\\n<br>22.4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5484px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">22.5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5497px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:6px\">19.7\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5400px; width:15px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.318\\n<br>0.320\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5421px; width:15px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.275\\n<br>0.297\\n<br>0.300\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5450px; width:15px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.300\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5463px; width:15px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.304\\n<br>0.309\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5484px; width:15px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.311\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5497px; width:15px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:6px\">0.326\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:310px; top:5408px; width:8px; height:35px;\"><span style=\"font-family: CMSY10; font-size:4px\">↓\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">]\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">[\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">d\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br>e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:310px; top:5446px; width:8px; height:31px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br>c\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">r\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">f\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">I\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:324px; top:5393px; width:8px; height:17px;\"><span style=\"font-family: CMR10; font-size:8px\">12\\n<br>10\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5430px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5445px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5467px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5498px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">0\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5518px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Table 2. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Distillation Comparison </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare ADD to other\\n<br>distillation methods via COCO zero-shot FID</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">5k </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">(FID) and CLIP\\n<br>score (CS). All models are based on SD1.5.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5575px; width:238px; height:69px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Teacher type.\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1e). Interestingly, a bigger student\\n<br>and teacher does not necessarily result in better FID and\\n<br>CS. Rather, the student adopts the teachers characteristics.\\n<br>SDXL obtains generally higher FID, possibly because of its\\n<br>less diverse output, yet it exhibits higher image quality and\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">text alignment [50].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5654px; width:236px; height:45px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Teacher steps.\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1f). While our distillation loss\\n<br>formulation allows taking several consecutive steps with the\\n<br>teacher by construction, we ﬁnd that several steps do not\\n<br>conclusively result in better performance.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:5713px; width:228px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">4.2. Quantitative Comparison to State of the Art\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:5733px; width:237px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For our main comparison with other approaches, we refrain\\n<br>from using automated metrics, as user preference studies\\n<br>are more reliable [50]. In the study, we aim to assess both\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">prompt adherence and the overall image. As a performance\\n<br>measure, we compute win percentages for pairwise compar-\\n<br>isons and ELO scores when comparing several approaches.\\n<br>For the reported ELO scores we calculate the mean scores\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:5835px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">7\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:410px; top:5394px; width:36px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">IF-XL\\n<br>(150 steps)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:451px; top:5422px; width:32px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">SDXL\\n<br>(50 steps)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:351px; top:5451px; width:40px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">OpenMUSE\\n<br>(16 steps)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:357px; top:5503px; width:12px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">900\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:386px; top:5503px; width:12px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">950\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:412px; top:5460px; width:31px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">LCM-XL\\n<br>(4 steps)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:428px; top:5482px; width:31px; height:29px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ADD-XL\\n<br>(1 step)\\n<br></span><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">050\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:410px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">000\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:423px; top:5516px; width:22px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ELO </span><span style=\"font-family: CMSY10; font-size:8px\">↑\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:483px; top:5460px; width:31px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ADD-XL\\n<br>(4 steps)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:467px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">100\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:495px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">150\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:523px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">200\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5532px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 7. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Performance vs. speed. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We visualize the results reported\\n<br>in Fig. 6 in combination with the inference speeds of the respective\\n<br>models. The speeds are calculated for generating a single sample\\n<br>at resolution 512x512 on an A100 in mixed precision.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5598px; width:236px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">between both prompt following and image quality. Details\\n<br>on the ELO score computation and the study parameters are\\n<br>listed in the supplementary material.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5634px; width:238px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Fig. 5 and Fig. 6 present the study results. The most im-\\n<br>portant results are: First, ADD-XL outperforms LCM-XL (4\\n<br>steps) with a single step. Second, ADD-XL can beat SDXL\\n<br>(50 steps) with four steps in the majority of comparisons.\\n<br>This makes ADD-XL the state-of-the-art in both the single\\n<br>and the multiple steps setting. Fig. 7 visualizes ELO scores\\n<br>relative to inference speed. Lastly, Table 2 compares dif-\\n<br>ferent few-step sampling and distillation methods using the\\n<br>same base model. ADD outperforms all other approaches\\n<br>including the standard DPM solver with eight steps.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5762px; width:108px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">4.3. Qualitative Results\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5781px; width:238px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">To complement our quantitative studies above, we present\\n<br>qualitative results in this section. To paint a more complete\\n<br>picture, we provide additional samples and qualitative com-\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:5173px; width:242px; height:147px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:5173px; width:242px; height:147px;\"></div><span style=\"position:absolute; border: black 1px solid; left:58px; top:5384px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5397px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5418px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5447px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5460px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5481px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5494px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:58px; top:5507px; width:220px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:364px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:392px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:420px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:448px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:476px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:504px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:533px; top:5384px; width:0px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5501px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5471px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5449px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5433px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5405px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5396px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:335px; top:5384px; width:197px; height:117px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:406px; top:5401px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:347px; top:5472px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:408px; top:5480px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:447px; top:5442px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:423px; top:5490px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:478px; top:5480px; width:3px; height:3px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:5944px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:5944px;\"><a name=\"8\">Page 8</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:99px; top:6036px; width:205px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A cinematic shot of a little pig priest wearing sunglasses.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:6015px; width:219px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A photograph of the inside of a subway train. There are frogs\\n<br>sitting on the seats. One of them is reading a newspaper. The\\n<br>window shows the river in the background.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:89px; top:6172px; width:223px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A photo of an astronaut riding a horse in the forest. There is a\\n<br>river in front of them with water lilies.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:363px; top:6183px; width:151px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A photo of a cute mouse wearing a crown.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6076px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6064px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br>D\\n<br>A\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6066px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6115px; width:8px; height:43px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">B\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6119px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">0\\n<br>5\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6222px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6210px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br>D\\n<br>A\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6212px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6261px; width:8px; height:43px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">B\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6265px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">0\\n<br>5\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:6319px; width:495px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 8. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Qualitative comparison to the teacher model. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ADD-XL can outperform its teacher model SDXL in the multi-step setting. The\\n<br>adversarial loss boosts realism, particularly enhancing textures (fur, fabric, skin) while reducing oversmoothing, commonly observed in\\n<br>diffusion model samples. ADD-XL’s overall sample diversity tends to be lower.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:6374px; width:238px; height:141px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">parisons in the supplementary material. Fig. 3 compares\\n<br>ADD-XL (1 step) against the best current baselines in the\\n<br>few-steps regime. Fig. 4 illustrates the iterative sampling\\n<br>process of ADD-XL. These results showcase our model’s\\n<br>ability to improve upon an initial sample. Such iterative\\n<br>improvement represents another signiﬁcant beneﬁt over pure\\n<br>GAN approaches like StyleGAN-T++. Lastly, Fig. 8 com-\\n<br>pares ADD-XL directly with its teacher model SDXL-Base.\\n<br>As indicated by the user studies in Section 4.2, ADD-XL\\n<br>outperforms its teacher in both quality and prompt alignment.\\n<br>The enhanced realism comes at the cost of slightly decreased\\n<br>sample diversity.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:6530px; width:65px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">5. Discussion\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:6551px; width:238px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">This work introduces </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">Adversarial Diffusion Distillation</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, a\\n<br>general method for distilling a pretrained diffusion model\\n<br>into a fast, few-step image generation model. We combine\\n<br>an adversarial and a score distillation objective to distill the\\n<br>public Stable Diffusion [54] and SDXL [50] models, lever-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">aging both real data through the discriminator and structural\\n<br>understanding through the diffusion teacher. Our approach\\n<br>performs particularly well in the ultra-fast sampling regime\\n<br>of one or two steps, and our analyses demonstrate that it out-\\n<br>performs all concurrent methods in this regime. Furthermore,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:6677px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">8\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6374px; width:238px; height:45px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">we retain the ability to reﬁne samples using multiple steps.\\n<br>In fact, using four sampling steps, our model outperforms\\n<br>widely used multi-step generators such as SDXL, IF, and\\n<br>OpenMUSE.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6422px; width:236px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our model enables the generation of high quality images\\n<br>in a single-step, opening up new possibilities for real-time\\n<br>generation with foundation models.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6468px; width:98px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">Acknowledgements\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6488px; width:237px; height:93px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">We would like to thank Jonas M¨uller for feedback on the\\n<br>draft, the proof, and typesetting; Patrick Esser for feedback\\n<br>on the proof and building an early model demo; Frederic\\n<br>Boesel for generating data and helpful discussions; Minguk\\n<br>Kang and Taesung Park for providing GigaGAN samples;\\n<br>Richard Vencu, Harry Saini, and Sami Kama for maintaining\\n<br>the compute infrastructure; Yara Wald for creative sampling\\n<br>support; and Vanessa Sauer for her general support.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6594px; width:55px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">References\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:313px; top:6615px; width:233px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[1] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep\\n<br>Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben\\n<br>Mann, Nova DasSarma, Nelson Elhage, Zac Hatﬁeld-Dodds,\\n<br>Danny Hernandez, Jackson Kernion, Kamal Ndousse, Cather-\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6051px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6051px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6107px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6107px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6198px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6198px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6253px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6253px; width:222px; height:55px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:6786px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:6786px;\"><a name=\"9\">Page 9</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:6860px; width:233px; height:141px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam\\n<br>McCandlish, Chris Olah, and Jared Kaplan. A general lan-\\n<br>guage assistant as a laboratory for alignment, 2021. 13\\n<br>[2] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell,\\n<br>Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort,\\n<br>Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\\n<br>davath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nel-\\n<br>son Elhage, Zac Hatﬁeld-Dodds, Danny Hernandez, Tristan\\n<br>Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel\\n<br>Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack\\n<br>Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared\\n<br>Kaplan. Training a helpful and harmless assistant with rein-\\n<br>forcement learning from human feedback, 2022. 13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7006px; width:233px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[3] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat,\\n<br>Jiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala,\\n<br>Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, and\\n<br>Ming-Yu Liu. ediff-i: Text-to-image diffusion models with an\\n<br>ensemble of expert denoisers. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2211.01324, 2022.\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">1, 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7073px; width:233px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[4] A. Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn,\\n<br>Seung Wook Kim, Sanja Fidler, and Karsten Kreis. Align your\\n<br>latents: High-resolution video synthesis with latent diffusion\\n<br>models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2023 IEEE/CVF Conference on Computer Vision\\n<br>and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 22563–22575, 2023.\\n<br>1, 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7140px; width:233px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou,\\n<br>Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-\\n<br>ing properties in self-supervised vision transformers. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Pro-\\n<br>ceedings of the IEEE/CVF international conference on com-\\n<br>puter vision</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 9650–9660, 2021. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7196px; width:233px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[6] Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot,\\n<br>Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy,\\n<br>William T Freeman, Michael Rubinstein, et al. Muse: Text-to-\\n<br>image generation via masked generative transformers. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proc.\\n<br>ICML</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7252px; width:233px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[7] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang\\n<br>Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiao-\\n<br>fang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image\\n<br>generation models using photogenic needles in a haystack.\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2309.15807</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7309px; width:233px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[8] Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Genie:\\n<br>Higher-order denoising diffusion solvers. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in Neural\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Information Processing Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 35:30150–30166, 2022. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7343px; width:233px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\\n<br>Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\\n<br>Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\\n<br>vain Gelly, et al. An image is worth 16x16 words: Trans-\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">formers for image recognition at scale.\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv:2010.11929</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2020. 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7410px; width:237px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[10] Arpad E. Elo. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">The Rating of Chessplayers, Past and Present</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:69px; top:7421px; width:113px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Arco Pub., New York, 1978. 13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7433px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[11] Patrick Esser, Robin Rombach, and Bj¨orn Ommer. Tam-\\n<br>ing transformers for high-resolution image synthesis. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2021\\n<br>IEEE/CVF Conference on Computer Vision and Pattern\\n<br>Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 12868–12878, 2020. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7479px; width:237px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[12] Patrick Esser, Johnathan Chiu, Parmida Atighehchian,\\n<br>Jonathan Granskog, and Anastasis Germanidis. Structure\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:6860px; width:217px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">and content-guided video synthesis with diffusion models,\\n<br>2023. 1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6883px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[13] Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos,\\n<br>Thibaut Issenhuth, Emmanuel de B´ezenac, Micka¨el Chen,\\n<br>and Alain Rakotomamonjy. Unifying gans and score-based\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">diffusion as generative particle models.\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv:2305.16150</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6939px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[14] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing\\n<br>Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville,\\n<br>and Yoshua Bengio. Generative adversarial networks. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Com-\\n<br>munications of the ACM</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 63:139 – 144, 2014. 1, 2, 4\\n<br>[15] Timofey Grigoryev, Andrey Voynov, and Artem Babenko.\\n<br>When, why, and which pretrained gans are useful? </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ICLR</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br>2022. 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7018px; width:237px; height:109px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[16] Amir Hertz, Kﬁr Aberman, and Daniel Cohen-Or. Delta de-\\n<br>noising score. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of the IEEE/CVF International\\n<br>Conference on Computer Vision</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 2328–2337, 2023. 3\\n<br>[17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,\\n<br>and Yejin Choi. CLIPScore: A reference-free evaluation\\n<br>metric for image captioning. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proc. EMNLP</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2021. 6\\n<br>[18] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bern-\\n<br>hard Nessler, and Sepp Hochreiter. GANs trained by a two\\n<br>time-scale update rule converge to a local Nash equilibrium.\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">NeurIPS</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2017. 6, 12\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7131px; width:237px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[19] Jonathan Ho. Classiﬁer-free diffusion guidance. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:7142px; width:89px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">abs/2207.12598, 2022. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7154px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[20] Jonathan Ho, Ajay Jain, and P. Abbeel. Denoising diffusion\\n<br>probabilistic models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2006.11239, 2020. 1\\n<br>[21] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang,\\n<br>Ruiqi Gao, Alexey A. Gritsenko, Diederik P. Kingma, Ben\\n<br>Poole, Mohammad Norouzi, David J. Fleet, and Tim Salimans.\\n<br>Imagen video: High deﬁnition video generation with diffusion\\n<br>models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2210.02303, 2022. 1, 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7232px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[22] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\\n<br>Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank\\n<br>adaptation of large language models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2106.09685,\\n<br>2021. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7277px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[23] Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-\\n<br>Jun Zha, and Lei Zhang. Dreamtime: An improved optimiza-\\n<br>tion strategy for text-to-3d content creation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2306.12422</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7322px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[24] Alexia Jolicoeur-Martineau, R´emi Pich´e-Taillefer, R´emi Ta-\\n<br>chet des Combes, and Ioannis Mitliagkas. Adversarial score\\n<br>matching and improved sampling for image generation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\\n<br>preprint arXiv:2009.05475</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2020. 3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7367px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[25] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli\\n<br>Shechtman, Sylvain Paris, and Taesung Park. Scaling up gans\\n<br>for text-to-image synthesis. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of the IEEE/CVF\\n<br>Conference on Computer Vision and Pattern Recognition</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br>pages 10124–10134, 2023. 1, 2, 6, 14\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7423px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[26] Tero Karras, Samuli Laine, and Timo Aila. A style-based\\n<br>generator architecture for generative adversarial networks.\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2019 IEEE/CVF Conference on Computer Vision and Pattern\\n<br>Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 4396–4405, 2018. 1, 4, 14\\n<br>[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,\\n<br>Jaakko Lehtinen, and Timo Aila. Analyzing and improving\\n<br>the image quality of stylegan. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2020 IEEE/CVF Conference\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:7519px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">9\\n<br></span></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:7628px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:7628px;\"><a name=\"10\">Page 10</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:70px; top:7702px; width:216px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">on Computer Vision and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\\n<br>8107–8116, 2019. 1, 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:7702px; width:216px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">proach for transferring knowledge from pre-trained diffusion\\n<br>models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2305.18455</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7725px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[28] Oren Katzir, Or Patashnik, Daniel Cohen-Or, and Dani\\n<br>Lischinski. Noise-free score distillation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2310.17590</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7759px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[29] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Mu-\\n<br>rata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki\\n<br>Mitsufuji, and Stefano Ermon. Consistency trajectory models:\\n<br>Learning probability ﬂow ode trajectory of diffusion. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\\n<br>preprint arXiv:2310.02279</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7815px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[30] Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Ma-\\n<br>tiana, Joe Penna, and Omer Levy. Pick-a-pic: An open dataset\\n<br>of user preferences for text-to-image generation, 2023. 12\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7849px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[31] Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun\\n<br>Fu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren. Snapfusion:\\n<br>Text-to-image diffusion model on mobile devices within two\\n<br>seconds. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2306.00980</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 7\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7894px; width:236px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[32] Jae Hyun Lim and Jong Chul Ye. Geometric gan. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:70px; top:7905px; width:129px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">preprint arXiv:1705.02894</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2017. 5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7917px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[33] Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Com-\\n<br>mon diffusion noise schedules and sample steps are ﬂawed,\\n<br>2023. 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7951px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bour-\\n<br>dev, Ross Girshick, James Hays, Pietro Perona, Deva Ra-\\n<br>manan, C. Lawrence Zitnick, and Piotr Doll´ar. Microsoft\\n<br>coco: Common objects in context, 2015. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7996px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[35] Xingchao Liu, Chengyue Gong, et al. Flow straight and\\n<br>fast: Learning to generate and transfer data with rectiﬁed\\n<br>ﬂow. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">The Eleventh International Conference on Learning\\n<br>Representations</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8040px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[36] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, and\\n<br>Qiang Liu. Instaﬂow: One step is enough for high-quality\\n<br>diffusion-based text-to-image generation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2309.06380</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2, 3, 7, 15\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8085px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[37] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan\\n<br>Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion\\n<br>probabilistic model sampling in around 10 steps. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in\\n<br>Neural Information Processing Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 35:5775–5787, 2022.\\n<br>2, 7\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8141px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[38] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and\\n<br>Latent consistency models: Synthesizing\\n<br>Hang Zhao.\\n<br>high-resolution images with few-step inference. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">abs/2310.04378, 2023. 2, 13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8186px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[39] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang\\n<br>Zhao.\\n<br>Latent consistency models: Synthesizing high-\\n<br>resolution images with few-step inference. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2310.04378</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8231px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[40] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\\n<br>Platen, Apolin’ario Passos, Longbo Huang, Jian Li, and Hang\\n<br>Zhao. Lcm-lora: A universal stable-diffusion acceleration\\n<br>module. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2311.05556, 2023. 2, 3, 13, 15\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8276px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[41] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\\n<br>Platen, Apolin</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">´</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ario Passos, Longbo Huang, Jian Li, and Hang\\n<br>Zhao. Lcm-lora: A universal stable-diffusion acceleration\\n<br>module. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2311.05556</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8321px; width:237px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[42] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun,\\n<br>Zhenguo Li, and Zhihua Zhang. Diff-instruct: A universal ap-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7726px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[43] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik\\n<br>Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.\\n<br>On distillation of guided diffusion models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of\\n<br>the IEEE/CVF Conference on Computer Vision and Pattern\\n<br>Recognition</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 14297–14306, 2023. 2, 7\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7782px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[44] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.\\n<br>Which training methods for gans do actually converge? In\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International conference on machine learning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 3481–\\n<br>3490. PMLR, 2018. 5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7827px; width:236px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[45] Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and\\n<br>Daniel Cohen-Or. Latent-nerf for shape-guided generation\\n<br>of 3d shapes and textures. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2023 IEEE/CVF Conference on\\n<br>Computer Vision and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\\n<br>12663–12673, 2022. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7883px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[46] Takeru Miyato and Masanori Koyama. cgans with projection\\n<br>discriminator. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:1802.05637</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2018. 4\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[47] Maxime Oquab, Timoth</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">´</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ee Darcet, Th</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">´</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">eo Moutakanni, Huy Vo,\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel\\n<br>Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2:\\n<br>Learning robust visual features without supervision. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\\n<br>preprint arXiv:2304.07193</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7962px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[48] Suraj Patil, William Berman, and Patrick von Platen. Amused:\\n<br>An open muse model. https://github.com/huggingface/\\n<br>diffusers, 2023. 6, 15\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7996px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[49] William Peebles and Saining Xie. Scalable diffusion models\\n<br>with transformers. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of the IEEE/CVF Inter-\\n<br>national Conference on Computer Vision</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 4195–4205,\\n<br>2023. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8041px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[50] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann,\\n<br>Tim Dockhorn, Jonas M¨uller, Joe Penna, and Robin Rombach.\\n<br>Sdxl: Improving latent diffusion models for high-resolution\\n<br>image synthesis. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2307.01952</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2,\\n<br>4, 5, 6, 7, 8, 12, 13\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8097px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[51] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.\\n<br>Dreamfusion: Text-to-3d using 2d diffusion. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2209.14988</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 2, 5, 12\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8131px; width:237px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[52] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\\n<br>Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\\n<br>Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">transferable visual models from natural language supervi-\\n<br>sion. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International conference on machine learning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\\n<br>8748–8763. PMLR, 2021. 6, 12\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8198px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[53] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,\\n<br>and Mark Chen. Hierarchical text-conditional image gener-\\n<br>ation with clip latents. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2204.06125, 2022. 1, 2,\\n<br>4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8243px; width:236px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[54] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick\\n<br>Esser, and Bj¨orn Ommer. High-resolution image synthesis\\n<br>with latent diffusion models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2022 IEEE/CVF Conference\\n<br>on Computer Vision and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">10674–10685, 2021. 1, 2, 5, 6, 8\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8299px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[55] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,\\n<br>Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael\\n<br>Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Pho-\\n<br>torealistic text-to-image diffusion models with deep language\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:8361px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">10\\n<br></span></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:8470px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:8470px;\"><a name=\"11\">Page 11</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8544px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[70] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling\\n<br>the generative learning trilemma with denoising diffusion\\n<br>gans. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2112.07804</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2021. 3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8578px; width:237px; height:86px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[71] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufo-\\n<br>gen: You forward once large scale text-to-image generation\\n<br>via diffusion gans. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2311.09257</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 7\\n<br>[72] Chun-Han Yao, Amit Raj, Wei-Chih Hung, Yuanzhen Li,\\n<br>Michael Rubinstein, Ming-Hsuan Yang, and Varun Jampani.\\n<br>Artic3d: Learning robust articulated 3d shapes from noisy\\n<br>web image collections. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2306.04619</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br>2023. 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8668px; width:237px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[73] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan\\n<br>Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei\\n<br>Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana\\n<br>Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui\\n<br>Wu. Scaling autoregressive models for content-rich text-to-\\n<br>image generation, 2022. 12\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8735px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[74] Qinsheng Zhang and Yongxin Chen. Fast sampling of dif-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">fusion models with exponential integrator. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2204.13902</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:69px; top:8544px; width:216px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">understanding. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in Neural Information Processing\\n<br>Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 35:36479–36494, 2022. 4, 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8567px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[56] Tim Salimans and Jonathan Ho. Progressive distillation for\\n<br>fast sampling of diffusion models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">CoRR</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2202.00512,\\n<br>2022. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8601px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[57] Axel Sauer, Kashyap Chitta, Jens M¨uller, and Andreas Geiger.\\n<br>Projected gans converge faster. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in Neural Informa-\\n<br>tion Processing Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 34:17480–17492, 2021. 5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8635px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[58] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl:\\n<br>Scaling stylegan to large diverse datasets. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ACM SIGGRAPH\\n<br>2022 Conference Proceedings</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 1, 4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8669px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[59] Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and\\n<br>Timo Aila. Stylegan-t: Unlocking the power of gans for fast\\n<br>large-scale text-to-image synthesis. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proc. ICML</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2, 3,\\n<br>4, 5, 6, 14\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8714px; width:237px; height:86px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[60] Juergen Schmidhuber. Generative adversarial networks are\\n<br>special cases of artiﬁcial curiosity (1990) and also closely\\n<br>related to predictability minimization (1991), 2020. 4\\n<br>[61] Christoph Schuhmann, Romain Beaumont, Richard Vencu,\\n<br>Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes,\\n<br>Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al.\\n<br>LAION-5B: An open large-scale dataset for training next\\n<br>generation image-text models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">NeurIPS</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 6\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8804px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[62] Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual,\\n<br>Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea\\n<br>Vedaldi, Devi Parikh, Justin Johnson, et al. Text-to-4d dy-\\n<br>namic scene generation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2301.11280</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br>2023. 3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8860px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[63] Jascha Narain Sohl-Dickstein, Eric A. Weiss, Niru Ma-\\n<br>heswaranathan, and Surya Ganguli. Deep unsupervised\\n<br>learning using nonequilibrium thermodynamics. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\\n<br>abs/1503.03585, 2015. 1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8905px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[64] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising\\n<br>diffusion implicit models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International Conference on\\n<br>Learning Representations</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2021. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8939px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[65] Yang Song, Jascha Narain Sohl-Dickstein, Diederik P.\\n<br>Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.\\n<br>Score-based generative modeling through stochastic differen-\\n<br>tial equations. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2011.13456, 2020. 1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8984px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[66] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.\\n<br>Consistency models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International Conference on Machine\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Learning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9018px; width:237px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[67] George Stein, Jesse C Cresswell, Rasa Hosseinzadeh, Yi Sui,\\n<br>Brendan Leigh Ross, Valentin Villecroze, Zhaoyan Liu, An-\\n<br>thony L Caterini, J Eric T Taylor, and Gabriel Loaiza-Ganem.\\n<br>Exposing ﬂaws of generative model evaluation metrics and\\n<br>their unfair treatment of diffusion models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\\n<br>arXiv:2306.04675</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6, 14\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9085px; width:237px; height:97px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[68] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A Yeh,\\n<br>and Greg Shakhnarovich. Score jacobian chaining: Lifting\\n<br>pretrained 2d diffusion models for 3d generation. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceed-\\n<br>ings of the IEEE/CVF Conference on Computer Vision and\\n<br>Pattern Recognition</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 12619–12629, 2023. 2, 5\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[69] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan\\n<br>Li, Hang Su, and Jun Zhu. Proliﬁcdreamer: High-ﬁdelity and\\n<br>diverse text-to-3d generation with variational score distilla-\\n<br>tion. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2305.16213, 2023. 2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:9203px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">11\\n<br></span></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:9312px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:9312px;\"><a name=\"12\">Page 12</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9384px; width:49px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">Appendix\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9408px; width:246px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">A. SDS As a Special Case of the Distillation Loss\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9429px; width:177px; height:25px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">If we set the weighting function to </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMMI7; font-size:6px\">α</span><span style=\"font-family: CMMI5; font-size:4px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and choose </span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x, y</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMMI10; font-size:9px\">x </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">y</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:217px; top:9431px; width:327px; height:12px;\"><span style=\"font-family: CMR7; font-size:6px\">2</span><span style=\"font-family: CMMI7; font-size:6px\">σ</span><span style=\"font-family: CMMI5; font-size:4px\">t </span><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where </span><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">is the scaling factor from the weighted diffusion loss as in [51]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:172px; top:9445px; width:312px; height:11px;\"><span style=\"font-family: CMR7; font-size:6px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, the distillation loss in Eq. (4) is equivalent to the score distillation objective:\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:167px; top:9483px; width:9px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d\\n<br>dθ\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:178px; top:9488px; width:23px; height:13px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">MSE\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">distill\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:260px; top:9564px; width:131px; height:10px;\"><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">) + ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:393px; top:9557px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:9565px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(5)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:243px; top:9512px; width:102px; height:16px;\"><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">sg</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">); </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\\n<br>2</span><span style=\"font-family: CMEX10; font-size:9px\">i\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9508px; width:125px; height:69px;\"><span style=\"font-family: CMMI10; font-size:9px\">d\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h</span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">dθ\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h</span><span style=\"font-family: CMR10; font-size:9px\">2</span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)[ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)]\\n<br>= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:227px; top:9564px; width:21px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)[\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:249px; top:9557px; width:9px; height:23px;\"><span style=\"font-family: CMR10; font-size:9px\">1\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:307px; top:9532px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:216px; top:9557px; width:18px; height:76px;\"><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">1\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9587px; width:33px; height:16px;\"><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9614px; width:33px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">d\\n<br>dθ\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9642px; width:7px; height:9px;\"><span style=\"font-family: CMR10; font-size:9px\">=\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:204px; top:9642px; width:19px; height:10px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">SDS\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:226px; top:9590px; width:180px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)[(</span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">)]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:408px; top:9583px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:235px; top:9614px; width:90px; height:12px;\"><span style=\"font-family: CMR10; font-size:9px\">[</span><span style=\"font-family: CMSY10; font-size:9px\">−</span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMSY7; font-size:6px\">′ </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)]\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:327px; top:9609px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9716px; width:225px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">B. Details on Human Preference Assessment\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:9739px; width:495px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For the evaluation results presented in Figures 5 to 7, we employ human evaluation and do not rely on commonly used\\n<br>metrics for quality assessment of generative models such as FID [18] and CLIP-score [52], since these have been shown to\\n<br>capture more ﬁne grained aspects like aesthetics and scene composition only insufﬁciently [30, 50]. However these categories\\n<br>in particular have become more and more important when comparing current state-of-the-art text-to-image models. We\\n<br>evaluate all models based on 100 selected prompts from the PartiPrompts benchmark [73] with the most relevant categories\\n<br>(excluding prompts from the category </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">basic</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">). More details on how the study was conducted Appendix B.1 and the rankings\\n<br>computed Appendix B.2 are listed below.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:69px; top:9997px; width:455px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 9. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">single step</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-M (1-step) against established baselines.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:10045px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">12\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:217px; top:9436px; width:11px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:167px; top:9495px; width:10px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:231px; top:9520px; width:10px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:307px; top:9544px; width:15px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:216px; top:9569px; width:9px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:249px; top:9569px; width:9px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:393px; top:9569px; width:15px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:216px; top:9595px; width:9px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:408px; top:9595px; width:15px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:216px; top:9621px; width:18px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:327px; top:9621px; width:15px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:192px; top:9647px; width:10px; height:0px;\"></span>\\n<div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:9839px; width:242px; height:148px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:9839px; width:242px; height:148px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:10154px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:59px; top:10383px; width:476px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 10. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">multiple steps</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-XL (4-step) against established baselines.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:10416px; width:114px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">B.1. Experimental Setup\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10434px; width:496px; height:118px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Given all models for one particular study (e.g. ADD-XL, OpenMUSE</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">6</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, IF-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">7</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, SDXL [50] and LCM-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">8 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">[38, 40] in\\n<br>Figure 7) we compare each prompt for each pair of models (1v1). For every comparison, we collect an average of four votes\\n<br>per task from different annotators, for both visual quality and prompt following. Human evaluators, recruited from the platform\\n<br></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">Proliﬁc</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">9 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">with English as their ﬁrst language, are shown two images from different models based on the same text prompt. To\\n<br>prevent biases, evaluators are restricted from participating in more than one of our studies. For the prompt following task,\\n<br>we display the text prompt above the two images and ask, “Which image looks more representative of the text shown above\\n<br>and faithfully follows it?” For the visual quality assessment, we do not show the prompt and instead ask, “Which image is of\\n<br>higher quality and aesthetically more pleasing?”. Performing a complete assessment between all pair-wise comparisons gives\\n<br>us robust and reliable signals on model performance trends and the effect of varying thresholds. The order of prompts and the\\n<br>order between models are fully randomized. Frequent attention checks are in place to ensure data quality.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:10563px; width:129px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">B.2. ELO Score Calculation\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10582px; width:496px; height:69px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">To calculate rankings when comparing more than two models based on 1v1 comparisons we use ELO Scores (higher-is-\\n<br>better) [10] which were originally proposed as a scoring method for chess players but have more recently also been applied to\\n<br>compare instruction-tuned generative LLMs [1, 2]. For a set of competing players with initial ratings </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">init </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">participating in a\\n<br>series of zero-sum games the ELO rating system updates the ratings of the two players involved in a particular game based on\\n<br>the expected and and actual outcome of that game. Before the game with two players with ratings </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR7; font-size:6px\">1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR7; font-size:6px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, the expected\\n<br>outcome for the two players are calculated as\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:10669px; width:22px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">E</span><span style=\"font-family: CMR7; font-size:6px\">1 </span><span style=\"font-family: CMR10; font-size:9px\">=\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:10697px; width:22px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">E</span><span style=\"font-family: CMR7; font-size:6px\">2 </span><span style=\"font-family: CMR10; font-size:9px\">=\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:305px; top:10663px; width:27px; height:22px;\"><span style=\"font-family: CMR10; font-size:9px\">1\\n<br></span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">2</span><span style=\"font-family: CMSY5; font-size:4px\">−</span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">1\\n<br>400\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:281px; top:10679px; width:51px; height:34px;\"><span style=\"font-family: CMR10; font-size:9px\">1 + 10\\n<br></span><span style=\"font-family: CMR10; font-size:9px\">1\\n<br></span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">1</span><span style=\"font-family: CMSY5; font-size:4px\">−</span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">2\\n<br>400\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:281px; top:10706px; width:27px; height:9px;\"><span style=\"font-family: CMR10; font-size:9px\">1 + 10\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:10669px; width:2px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:10697px; width:2px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10725px; width:307px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">After observing the result of the game, the ratings </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">are updated via the rule\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:225px; top:10745px; width:2px; height:4px;\"><span style=\"font-family: CMSY5; font-size:4px\">′\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:225px; top:10750px; width:100px; height:11px;\"><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">K </span><span style=\"font-family: CMSY10; font-size:9px\">· </span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">i</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: CMMI10; font-size:9px\">,\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:217px; top:10750px; width:7px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">R\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:10750px; width:39px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">i </span><span style=\"font-family: CMSY10; font-size:9px\">∈ {</span><span style=\"font-family: CMR10; font-size:9px\">1</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">2</span><span style=\"font-family: CMSY10; font-size:9px\">}\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:10669px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(6)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:10697px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(7)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:10749px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(8)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10772px; width:495px; height:46px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where </span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">indicates the outcome of the match for player </span><span style=\"font-family: CMMI10; font-size:9px\">i</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. In our case we have </span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">= 1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">if player </span><span style=\"font-family: CMMI10; font-size:9px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">wins and </span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">= 0 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">if player\\n<br></span><span style=\"font-family: CMMI10; font-size:9px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">looses. The constant </span><span style=\"font-family: CMMI10; font-size:9px\">K </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">can be see as weight putting emphasis on more recent games. We choose </span><span style=\"font-family: CMMI10; font-size:9px\">K </span><span style=\"font-family: CMR10; font-size:9px\">= 1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and bootstrap\\n<br>the ﬁnal ELO ranking for a given series of comparisons based on 1000 individual ELO ranking calculations with randomly\\n<br>shufﬂed order. Before comparing the models we choose the start rating for every model as </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">init </span><span style=\"font-family: CMR10; font-size:9px\">= 1000</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:10828px; width:180px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">6</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/openMUSE\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">7</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/deep-ﬂoyd/IF\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">8</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/latent-consistency/lcm-lora-sdxl\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">9</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://app.proliﬁc.com\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:10887px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">13\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:10225px; width:242px; height:147px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:10225px; width:242px; height:147px;\"></div><span style=\"position:absolute; border: black 1px solid; left:281px; top:10674px; width:53px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:309px; top:10681px; width:23px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:281px; top:10702px; width:53px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:309px; top:10709px; width:23px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:50px; top:10826px; width:197px; height:0px;\"></span>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:10996px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:10996px;\"><a name=\"14\">Page 14</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11068px; width:157px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">C. GAN Baselines Comparison\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11089px; width:496px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For training our state-of-the-art GAN baseline StyleGAN-T++, we follow the training procedure outlined in [59]. The main\\n<br>differences are extended training (</span><span style=\"font-family: CMSY10; font-size:9px\">∼</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">2M iterations with a batch size of 2048, which is comparable to GigaGAN’s schedule [25]),\\n<br>the improved discriminator architecture proposed in Section 3.2, and R1 penalty applied at each discriminator head.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11124px; width:495px; height:45px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Fig. 11 shows that StyleGAN-T++ outperforms the previous best GANs by achieving a comparable zero-shot FID to\\n<br>GigaGAN at a signiﬁcantly higher CLIP score. Here, we do not compare to DMs, as comparisons between model classes via\\n<br>automatic metrics tend to be less informative [67]. As an example, GigaGAN achieves FID and CLIP scores comparable to\\n<br>SD1.5, but its sample quality is still inferior, as noted by the authors.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:11210px; width:12px; height:12px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">k\\n<br>5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:11222px; width:17px; height:100px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:12px\">D\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">I\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">F\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">o\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">h\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">-\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">o\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">r\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:10px\">Z\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:82px; top:11186px; width:17px; height:162px;\"><span style=\"font-family: CMR10; font-size:17px\">26\\n<br>24\\n<br>22\\n<br>20\\n<br></span><span style=\"font-family: CMR10; font-size:17px\">18\\n<br>16\\n<br>14\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:142px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">29\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:199px; top:11342px; width:22px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">3\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:449px; top:11202px; width:54px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">GigaGAN\\n<br>StyleGAN-T\\n<br>StyleGAN-T++\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:403px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">34\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:456px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">35\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:508px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">36\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:247px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">31\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:235px; top:11342px; width:158px; height:40px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">32\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:17px\">CLIP score (ViT-g-14)\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:351px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">33\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11394px; width:496px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 11. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Comparing text alignment tradeoffs at 256 </span><span style=\"font-family: CMSY9; font-size:8px\">× </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">256 pixels. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare FID–CLIP score curves of StyleGAN-T, StyleGAN-T++,\\n<br>and GigaGAN. For increasing CLIP score, all methods use via decreasing truncation [26] for values </span><span style=\"font-family: CMMI9; font-size:8px\">ψ </span><span style=\"font-family: CMR9; font-size:8px\">= </span><span style=\"font-family: CMSY9; font-size:8px\">{</span><span style=\"font-family: CMR9; font-size:8px\">1</span><span style=\"font-family: CMMI9; font-size:8px\">.</span><span style=\"font-family: CMR9; font-size:8px\">0</span><span style=\"font-family: CMMI9; font-size:8px\">, </span><span style=\"font-family: CMR9; font-size:8px\">0</span><span style=\"font-family: CMMI9; font-size:8px\">.</span><span style=\"font-family: CMR9; font-size:8px\">9</span><span style=\"font-family: CMMI9; font-size:8px\">, . . . , </span><span style=\"font-family: CMR9; font-size:8px\">0</span><span style=\"font-family: CMMI9; font-size:8px\">.</span><span style=\"font-family: CMR9; font-size:8px\">3</span><span style=\"font-family: CMSY9; font-size:8px\">}</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:11675px; width:495px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 12. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Additional single step </span><span style=\"font-family: CMR9; font-size:8px\">512</span><span style=\"font-family: CMR6; font-size:5px\">2 </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">images generated with ADD-XL. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">All samples are generated with a single U-Net evaluation trained\\n<br>with adversarial diffusion distillation (ADD).\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:11729px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">14\\n<br></span></div><span style=\"position:absolute; border: black 1px solid; left:158px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:210px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:262px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:315px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:367px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:419px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:471px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:523px; top:11193px; width:0px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11338px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11314px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11290px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11265px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11241px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11217px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11193px; width:417px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:106px; top:11193px; width:417px; height:144px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:320px; top:11243px; width:41px; height:78px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:173px; top:11214px; width:61px; height:58px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:441px; top:11299px; width:17px; height:10px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:318px; top:11319px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:339px; top:11295px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:349px; top:11266px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:359px; top:11240px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:233px; top:11212px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:227px; top:11225px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:219px; top:11236px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:217px; top:11240px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:202px; top:11252px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:199px; top:11256px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:193px; top:11262px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:180px; top:11266px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:171px; top:11271px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:439px; top:11308px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:442px; top:11306px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:449px; top:11301px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:456px; top:11297px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:409px; top:11198px; width:101px; height:39px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:415px; top:11207px; width:29px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:428px; top:11204px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:415px; top:11217px; width:29px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:428px; top:11215px; width:4px; height:4px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:415px; top:11228px; width:29px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:428px; top:11226px; width:4px; height:4px;\"></span>\\n<div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:11467px; width:495px; height:198px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:11838px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:11838px;\"><a name=\"15\">Page 15</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11910px; width:114px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">D. Additional Samples\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:11931px; width:495px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">We show additional one-step samples as in Figure 1 in Figure 12. An additional qualitative comparison as in Figure 4 which\\n<br>demonstrates that our model can further reﬁne quality by using more than one sampling step is provided in Figure 14, where\\n<br>we show that, while sampling quality with a single step is already high, more steps can give higher diversity and better spelling\\n<br>capabilities. Lastly, we provide an additional qualitative comparison of ADD-XL to other state-of-the-art one and few-step\\n<br>models in Figure 13.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:115px; top:12010px; width:171px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A cinematic shot of robot with colorful feathers.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:330px; top:11999px; width:215px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Teddy bears working on new AI research on the moon in the\\n<br>1980s.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12050px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12038px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br>D\\n<br>A\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12041px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12105px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12093px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12097px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12161px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12149px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br>D\\n<br>A\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12151px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12217px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12205px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12206px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12272px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12260px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br>D\\n<br>D\\n<br>A\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12262px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12328px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12316px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12318px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12371px; width:8px; height:13px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">w\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">o\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">l\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12384px; width:8px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">F\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">I\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12422px; width:8px; height:44px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">E\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">U\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">O\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12375px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12427px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">6\\n<br>1\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:12481px; width:496px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 13. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Additional qualitative comparisons to state of the art fast samplers. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Few step samples from our ADD-XL and LCM-XL [40],\\n<br>InstaFlow [36], and OpenMuse [48].\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:12571px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">15\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12025px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12025px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12081px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12081px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12136px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12136px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12192px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12192px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12248px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12248px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12303px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12303px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12359px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12359px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12415px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12415px; width:222px; height:55px;\"></div><span style=\"position:absolute; border: gray 1px solid; left:0px; top:12680px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:12680px;\"><a name=\"16\">Page 16</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:76px; top:12958px; width:223px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“a robot is playing the guitar at a rock concert in front of a large\\n<br>crowd.”\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:314px; top:12936px; width:222px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A portrait photo of a kangaroo wearing an orange hoodie and\\n<br>blue sunglasses standing on the grass in front of the Sydney\\n<br>Opera House holding a sign on the chest that says Welcome\\n<br>Friends!”\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:13003px; width:8px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:13057px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:13113px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\\n<br></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:13162px; width:495px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 14. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Additional results on the qualitative effect of sampling steps. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Similar to Figure 4, we show qualitative examples when\\n<br>sampling ADD-XL with 1, 2, and 4 steps. Single-step samples are often already of high quality, but increasing the number of steps can\\n<br>further improve the diversity (left) and spelling capabilities (right). The seeds are constant within columns and we see that the general layout\\n<br>is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:13413px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">16\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:77px; top:12984px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:314px; top:12984px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:77px; top:13040px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:314px; top:13040px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:77px; top:13095px; width:222px; height:55px;\"></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:314px; top:13095px; width:222px; height:55px;\"></div><div style=\"position:absolute; top:0px;\">Page: <a href=\"#1\">1</a>, <a href=\"#2\">2</a>, <a href=\"#3\">3</a>, <a href=\"#4\">4</a>, <a href=\"#5\">5</a>, <a href=\"#6\">6</a>, <a href=\"#7\">7</a>, <a href=\"#8\">8</a>, <a href=\"#9\">9</a>, <a href=\"#10\">10</a>, <a href=\"#11\">11</a>, <a href=\"#12\">12</a>, <a href=\"#13\">13</a>, <a href=\"#14\">14</a>, <a href=\"#15\">15</a>, <a href=\"#16\">16</a></div>\\n</body></html>\\n' metadata={'source': 'Input/adversarial_diffusion_distillation.pdf'}\n"
     ]
    }
   ],
   "source": [
    "loader = PDFMinerPDFasHTMLLoader(\"Input/adversarial_diffusion_distillation.pdf\")\n",
    "data = loader.load()[0]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:195px; top:106px; width:203px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:14px\">Adversarial Diffusion Distillation\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:99px; top:146px; width:53px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Axel Sauer\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:183px; top:146px; width:79px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Dominik Lorenz\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:294px; top:146px; width:92px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Andreas Blattmann\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:418px; top:146px; width:78px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Robin Rombach\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:100px; top:186px; width:393px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Code</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">: https://github.com/Stability-AI/generative-models </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Model weights</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">: https://huggingface.co/stabilityai/\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:269px; top:167px; width:56px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:11px\">Stability AI\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:509px; width:495px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 1. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Generating high-ﬁdelity </span><span style=\"font-family: CMR9; font-size:8px\">512</span><span style=\"font-family: CMR6; font-size:5px\">2 </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">images in a single step. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">All samples are generated with a single U-Net evaluation trained with\n",
      "<br/>adversarial diffusion distillation (ADD).\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:145px; top:547px; width:44px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">Abstract\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:547px; width:76px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">1. Introduction\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:595px; width:238px; height:153px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">We introduce Adversarial Diffusion Distillation (ADD), a\n",
      "<br/>novel training approach that efﬁciently samples large-scale\n",
      "<br/>foundational image diffusion models in just 1–4 steps while\n",
      "<br/>maintaining high image quality. We use score distillation\n",
      "<br/>to leverage large-scale off-the-shelf image diffusion models\n",
      "<br/>as a teacher signal in combination with an adversarial loss\n",
      "<br/>to ensure high image ﬁdelity even in the low-step regime\n",
      "<br/>of one or two sampling steps. Our analyses show that our\n",
      "<br/>model clearly outperforms existing few-step methods (GANs,\n",
      "<br/>Latent Consistency Models) in a single step and reaches the\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">performance of state-of-the-art diffusion models (SDXL) in\n",
      "<br/>only four steps. ADD is the ﬁrst method to unlock single-step,\n",
      "<br/>real-time image synthesis with foundation models.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:573px; width:237px; height:189px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Diffusion models (DMs) [20, 63, 65] have taken a central\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">role in the ﬁeld of generative modeling and have recently en-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">abled remarkable advances in high-quality image- [3, 53, 54]\n",
      "<br/>and video- [4, 12, 21] synthesis. One of the key strengths of\n",
      "<br/>DMs is their scalability and iterative nature, which allows\n",
      "<br/>them to handle complex tasks such as image synthesis from\n",
      "<br/>free-form text prompts. However, the iterative inference\n",
      "<br/>process in DMs requires a signiﬁcant number of sampling\n",
      "<br/>steps, which currently hinders their real-time application.\n",
      "<br/>Generative Adversarial Networks (GANs) [14, 26, 27], on\n",
      "<br/>the other hand, are characterized by their single-step for-\n",
      "<br/>mulation and inherent speed. But despite attempts to scale\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">to large datasets[25, 58], GANs often fall short of DMs in\n",
      "<br/>terms of sample quality. The aim of this work is to combine\n",
      "<br/>the superior sample quality of DMs with the inherent speed\n",
      "<br/>of GANs.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:783px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:203px; width:495px; height:297px;\"></div>, <div style=\"position:absolute; top:892px;\"><a name=\"2\">Page 2</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:966px; width:237px; height:249px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our approach is conceptually simple: We propose </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">Ad-\n",
      "<br/>versarial Diffusion Distillation </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(ADD), a general approach\n",
      "<br/>that reduces the number of inference steps of a pre-trained\n",
      "<br/>diffusion model to 1–4 sampling steps while maintaining\n",
      "<br/>high sampling ﬁdelity and potentially further improving the\n",
      "<br/>overall performance of the model. To this end, we intro-\n",
      "<br/>duce a combination of two training objectives: (i) an </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">ad-\n",
      "<br/>versarial loss </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and (ii) a distillation loss that corresponds\n",
      "<br/>to </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">score distillation sampling </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(SDS) [51]. The adversar-\n",
      "<br/>ial loss forces the model to directly generate samples that\n",
      "<br/>lie on the manifold of real images at each forward pass,\n",
      "<br/>avoiding blurriness and other artifacts typically observed in\n",
      "<br/>other distillation methods [43]. The distillation loss uses\n",
      "<br/>another pretrained (and ﬁxed) DM as a teacher to effectively\n",
      "<br/>utilize the extensive knowledge of the pretrained DM and\n",
      "<br/>preserve the strong compositionality observed in large DMs.\n",
      "<br/>During inference, our approach does not use classiﬁer-free\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">guidance [</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">19], further reducing memory requirements. We\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">retain the model’s ability to improve results through iterative\n",
      "<br/>reﬁnement, which is an advantage over previous one-step\n",
      "<br/>GAN-based approaches [59].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:62px; top:1217px; width:195px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our contributions can be summarized as follows:\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1229px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">• We introduce ADD, a method for turning pretrained diffu-\n",
      "<br/>sion models into high-ﬁdelity, real-time image generators\n",
      "<br/>using only 1–4 sampling steps.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1265px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">• Our method uses a novel combination of adversarial train-\n",
      "<br/>ing and score distillation, for which we carefully ablate\n",
      "<br/>several design choices.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1301px; width:237px; height:70px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">• ADD signiﬁcantly outperforms strong baselines such as\n",
      "<br/>LCM, LCM-XL [38] and single-step GANs [59], and is\n",
      "<br/>able to handle complex image compositions while main-\n",
      "<br/>taining high image realism at only a single inference step.\n",
      "<br/>• Using four sampling steps, ADD-XL outperforms its\n",
      "<br/>teacher model SDXL-Base at a resolution of </span><span style=\"font-family: CMR10; font-size:9px\">512</span><span style=\"font-family: CMR7; font-size:6px\">2 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">px.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:1383px; width:74px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">2. Background\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:1403px; width:238px; height:201px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">While diffusion models achieve remarkable performance in\n",
      "<br/>synthesizing and editing high-resolution images [3, 53, 54]\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and videos [4, 21], their iterative nature hinders real-time ap-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">plication. Latent diffusion models [54] attempt to solve this\n",
      "<br/>problem by representing images in a more computationally\n",
      "<br/>feasible latent space [11], but they still rely on the iterative\n",
      "<br/>application of large models with billions of parameters. In\n",
      "<br/>addition to utilizing faster samplers for diffusion models\n",
      "<br/>[8, 37, 64, 74], there is a growing body of research on model\n",
      "<br/>distillation such as progressive distillation [56] and guidance\n",
      "<br/>distillation [43]. These approaches reduce the number of\n",
      "<br/>iterative sampling steps to 4-8, but may signiﬁcantly lower\n",
      "<br/>the original performance. Furthermore, they require an it-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">erative training process. Consistency models [66] address\n",
      "<br/>the latter issue by enforcing a consistency regularization on\n",
      "<br/>the ODE trajectory and demonstrate strong performance for\n",
      "<br/>pixel-based models in the few-shot setting. LCMs [38] focus\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1192px; width:236px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 2. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Adversarial Diffusion Distillation. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">The ADD-student\n",
      "<br/>is trained as a denoiser that receives diffused input images </span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">and outputs samples </span><span style=\"font-family: CMR9; font-size:8px\">ˆ</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">θ</span><span style=\"font-family: CMR9; font-size:8px\">(</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">s</span><span style=\"font-family: CMMI9; font-size:8px\">, s</span><span style=\"font-family: CMR9; font-size:8px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">and optimizes two objectives: a)\n",
      "<br/>adversarial loss: the model aims to fool a discriminator which is\n",
      "<br/>trained to distinguish the generated samples </span><span style=\"font-family: CMR9; font-size:8px\">ˆ</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">from real images\n",
      "<br/></span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMR6; font-size:5px\">0</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">. b) distillation loss: the model is trained to match the denoised\n",
      "<br/>targets </span><span style=\"font-family: CMR9; font-size:8px\">ˆ</span><span style=\"font-family: CMMI9; font-size:8px\">x</span><span style=\"font-family: CMMI6; font-size:5px\">ψ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">of a frozen DM teacher.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1293px; width:237px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">on distilling latent diffusion models and achieve impressive\n",
      "<br/>performance at 4 sampling steps. Recently, LCM-LoRA [40]\n",
      "<br/>introduced a low-rank adaptation [22] training for efﬁciently\n",
      "<br/>learning LCM modules, which can be plugged into differ-\n",
      "<br/>ent checkpoints for SD and SDXL [50, 54]. InstaFlow [36]\n",
      "<br/>propose to use Rectiﬁed Flows [35] to facilitate a better\n",
      "<br/>distillation process.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1378px; width:238px; height:165px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">All of these methods share common ﬂaws: samples syn-\n",
      "<br/>thesized in four steps often look blurry and exhibit noticeable\n",
      "<br/>artifacts. At fewer sampling steps, this problem is further am-\n",
      "<br/>pliﬁed. GANs [14] can also be trained as standalone single-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">step models for text-to-image synthesis [25, 59]. Their sam-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">pling speed is impressive, yet the performance lags behind\n",
      "<br/>diffusion-based models. In part, this can be attributed to the\n",
      "<br/>ﬁnely balanced GAN-speciﬁc architectures necessary for sta-\n",
      "<br/>ble training of the adversarial objective. Scaling these mod-\n",
      "<br/>els and integrating advances in neural network architectures\n",
      "<br/>without disturbing the balance is notoriously challenging.\n",
      "<br/>Additionally, current state-of-the-art text-to-image GANs\n",
      "<br/>do not have a method like classiﬁer-free guidance available\n",
      "<br/>which is crucial for DMs at scale.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:1547px; width:236px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Score Distillation Sampling [51] also known as Score\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Jacobian Chaining [68] is a recently proposed method that\n",
      "<br/>has been developed to distill the knowledge of foundational\n",
      "<br/>T2I Models into 3D synthesis models. While the majority of\n",
      "<br/>SDS-based works [45, 51, 68, 69] use SDS in the context of\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:1625px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:434px; top:1040px; width:49px; height:146px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:435px; top:1009px; width:48px; height:147px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:436px; top:972px; width:48px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:320px; top:1039px; width:48px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:319px; top:1109px; width:49px; height:146px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:320px; top:582px; width:368px; height:574px;\"><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:219px; top:1108px; width:149px; height:48px;\"></div></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:219px; top:1108px; width:149px; height:48px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:320px; top:443px; width:368px; height:644px;\"><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:220px; top:1038px; width:148px; height:49px;\"></div></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:220px; top:1038px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; top:1734px;\"><a name=\"3\">Page 3</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:95px; top:1805px; width:211px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A cinematic shot of a professor sloth wearing a tuxedo at a\n",
      "<br/>BBQ party.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:326px; top:1805px; width:222px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A high-quality photo of a confused bear in calculus class. The\n",
      "<br/>bear is wearing a party hat and steampunk armor.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1855px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1843px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/>D\n",
      "<br/>A\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:1846px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1910px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1898px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:1902px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1966px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:1954px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:1956px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2022px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2010px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2055px; width:8px; height:56px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">+\n",
      "<br/>+\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">T\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">N\n",
      "<br/>A\n",
      "<br/>G\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">l\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">y\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2123px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">w\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">o\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">l\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">F\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">I\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:2174px; width:8px; height:44px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">E\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">U\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">O\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2012px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2069px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2127px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:2179px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">6\n",
      "<br/>1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2233px; width:495px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 3. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Qualitative comparison to state-of-the-art fast samplers. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Single step samples from our ADD-XL (top) and LCM-XL [40], our\n",
      "<br/>custom StyleGAN-T [59] baseline, InstaFlow [36] and MUSE. For MUSE, we use the </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">OpenMUSE </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">implementation and default inference\n",
      "<br/>settings with 16 sampling steps. For LCM-XL, we sample with 1, 2 and 4 steps. Our model outperforms all other few-step samplers in a\n",
      "<br/>single step.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2298px; width:236px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">per-scene optimization for 3D objects, the approach has also\n",
      "<br/>been applied to text-to-3D-video-synthesis [62] and in the\n",
      "<br/>context of image editing [16].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2338px; width:237px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Recently, the authors of [13] have shown a strong relation-\n",
      "<br/>ship between score-based models and GANs and propose\n",
      "<br/>Score GANs, which are trained using score-based diffusion\n",
      "<br/>ﬂows from a DM instead of a discriminator. Similarly, Diff-\n",
      "<br/>Instruct [42], a method which generalizes SDS, enables to\n",
      "<br/>distill a pretrained diffusion model into a generator without\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">discriminator.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2298px; width:237px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">faster sampling, Denoising Diffusion GANs [70] are intro-\n",
      "<br/>duced as a method to enable sampling with few steps. To\n",
      "<br/>improve quality, a discriminator loss is added to the score\n",
      "<br/>matching objective in Adversarial Score Matching [24] and\n",
      "<br/>the consistency objective of CTM [29].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2358px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our method combines adversarial training and score dis-\n",
      "<br/>tillation in a hybrid objective to address the issues in current\n",
      "<br/>top performing few-step generative models.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2404px; width:51px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">3. Method\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2425px; width:237px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Conversely, there are also approaches which aim to im-\n",
      "<br/>prove the diffusion process using adversarial training. For\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2425px; width:237px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our goal is to generate high-ﬁdelity samples in as few sam-\n",
      "<br/>pling steps as possible, while matching the quality of state-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:2467px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1830px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1830px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1886px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1886px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1942px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1942px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:1997px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:1997px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:2053px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:2053px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:2111px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:2111px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:2167px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:2167px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; top:2576px;\"><a name=\"4\">Page 4</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:84px; top:2647px; width:130px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A brain riding a rocketship heading\n",
      "<br/>towards the moon.”\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:239px; top:2647px; width:147px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A bald eagle made of chocolate powder,\n",
      "<br/>mango, and whipped cream”\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:434px; top:2658px; width:77px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A blue colored dog.”\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:55px; top:2688px; width:8px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:55px; top:2736px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:55px; top:2786px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:2831px; width:495px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 4. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Qualitative effect of sampling steps. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We show qualitative examples when sampling ADD-XL with 1, 2, and 4 steps. Single-step\n",
      "<br/>samples are often already of high quality, but increasing the number of steps can further improve the consistency (e.g. second prompt, ﬁrst\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">column) and attention to detail (e.g. second prompt, second column). The seeds are constant within columns and we see that the general\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">layout is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:2888px; width:238px; height:213px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">of-the-art models [7, 50, 53, 55]. The adversarial objec-\n",
      "<br/>tive [14, 60] naturally lends itself to fast generation as it\n",
      "<br/>trains a model that outputs samples on the image manifold in\n",
      "<br/>a single forward step. However, attempts at scaling GANs to\n",
      "<br/>large datasets [58, 59] observed that is critical to not solely\n",
      "<br/>rely on the discriminator, but also employ a pretrained clas-\n",
      "<br/>siﬁer or CLIP network for improving text alignment. As\n",
      "<br/>remarked in [59], overly utilizing discriminative networks\n",
      "<br/>introduces artifacts and image quality suffers. Instead, we\n",
      "<br/>utilize the gradient of a pretrained diffusion model via a score\n",
      "<br/>distillation objective to improve text alignment and sample\n",
      "<br/>quality. Furthermore, instead of training from scratch, we\n",
      "<br/>initialize our model with pretrained diffusion model weights;\n",
      "<br/>pretraining the generator network is known to signiﬁcantly\n",
      "<br/>improve training with an adversarial loss [15]. Lastly, in-\n",
      "<br/>stead of utilizing a decoder-only architecture used for GAN\n",
      "<br/>training [26, 27], we adapt a standard diffusion model frame-\n",
      "<br/>work. This setup naturally enables iterative reﬁnement.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:3115px; width:110px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">3.1. Training Procedure\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:3135px; width:238px; height:153px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our training procedure is outlined in Fig. 2 and involves three\n",
      "<br/>networks: The ADD-student is initialized from a pretrained\n",
      "<br/>UNet-DM with weights </span><span style=\"font-family: CMMI10; font-size:9px\">θ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, a discriminator with trainable\n",
      "<br/>weights </span><span style=\"font-family: CMMI10; font-size:9px\">ϕ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, and a DM teacher with frozen weights </span><span style=\"font-family: CMMI10; font-size:9px\">ψ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. Dur-\n",
      "<br/>ing training, the ADD-student generates samples </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">from noisy data </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. The noised data points are produced\n",
      "<br/>from a dataset of real images </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">via a forward diffusion\n",
      "<br/>process </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0 </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. In our experiments, we use the\n",
      "<br/>same coefﬁcients </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">s </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">s </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">as the student DM and sam-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">ple </span><span style=\"font-family: CMMI10; font-size:9px\">s </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">uniformly from a set </span><span style=\"font-family: CMMI10; font-size:9px\">T</span><span style=\"font-family: CMR7; font-size:6px\">student </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMSY10; font-size:9px\">{</span><span style=\"font-family: CMMI10; font-size:9px\">τ</span><span style=\"font-family: CMR7; font-size:6px\">1</span><span style=\"font-family: CMMI10; font-size:9px\">, ..., τ</span><span style=\"font-family: CMMI7; font-size:6px\">n</span><span style=\"font-family: CMSY10; font-size:9px\">} </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">of </span><span style=\"font-family: CMMI10; font-size:9px\">N\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">chosen student timesteps. In practice, we choose </span><span style=\"font-family: CMMI10; font-size:9px\">N </span><span style=\"font-family: CMR10; font-size:9px\">= 4</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\n",
      "<br/>Importantly, we set </span><span style=\"font-family: CMMI10; font-size:9px\">τ</span><span style=\"font-family: CMMI7; font-size:6px\">n </span><span style=\"font-family: CMR10; font-size:9px\">= 1000 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and enforce zero-terminal\n",
      "<br/>SNR [33] during training, as the model needs to start from\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2888px; width:111px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">pure noise during inference.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:2900px; width:237px; height:105px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For the adversarial objective, the generated samples </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and real images </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">are passed to the discriminator which\n",
      "<br/>aims to distinguish between them. The design of the dis-\n",
      "<br/>criminator and the adversarial loss are described in detail in\n",
      "<br/>Sec. 3.2. To distill knowledge from the DM teacher, we dif-\n",
      "<br/>fuse student samples </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">with the teacher’s forward process to\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, and use the teacher’s denoising prediction </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMMI10; font-size:9px\">, t</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">as a reconstruction target for the distillation loss </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">distill</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">,\n",
      "<br/>see Section 3.3. Thus, the overall objective is\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:323px; top:3015px; width:33px; height:12px;\"><span style=\"font-family: CMSY10; font-size:9px\">L </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">G\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:350px; top:3017px; width:169px; height:11px;\"><span style=\"font-family: CMR7; font-size:6px\">adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">) + </span><span style=\"font-family: CMMI10; font-size:9px\">λ</span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">distill</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ψ</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:3017px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(1)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3038px; width:238px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">While we formulate our method in pixel space, it is\n",
      "<br/>straightforward to adapt it to LDMs operating in latent space.\n",
      "<br/>When using LDMs with a shared latent space for teacher\n",
      "<br/>and student, the distillation loss can be computed in pixel or\n",
      "<br/>latent space. We compute the distillation loss in pixel space\n",
      "<br/>as this yields more stable gradients when distilling latent\n",
      "<br/>diffusion model [72].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3128px; width:98px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">3.2. Adversarial Loss\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3147px; width:238px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For the discriminator, we follow the proposed design and\n",
      "<br/>training procedure in [59] which we brieﬂy summarize; for\n",
      "<br/>details, we refer the reader to the original work. We use a\n",
      "<br/>frozen pretrained feature network </span><span style=\"font-family: CMMI10; font-size:9px\">F </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and a set of trainable\n",
      "<br/>lightweight discriminator heads </span><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. For the feature net-\n",
      "<br/>work </span><span style=\"font-family: CMMI10; font-size:9px\">F </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, Sauer et al. [59] ﬁnd vision transformers (ViTs) [9]\n",
      "<br/>to work well, and we ablate different choice for the ViTs\n",
      "<br/>objective and model size in Section 4. The trainable discrim-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">inator heads are applied on features </span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">at different layers of\n",
      "<br/>the feature network.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3267px; width:237px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">To improve performance, the discriminator can be condi-\n",
      "<br/>tioned on additional information via projection [46]. Com-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:3309px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:76px; top:2672px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:238px; top:2672px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:399px; top:2672px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:76px; top:2722px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:238px; top:2722px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:399px; top:2722px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:76px; top:2771px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:238px; top:2771px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:399px; top:2771px; width:148px; height:49px;\"></div>, <div style=\"position:absolute; top:3418px;\"><a name=\"5\">Page 5</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:3648px; width:495px; height:31px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 5. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">single step</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-XL (1-step) against established baselines. ADD-XL\n",
      "<br/>model outperforms all models, except SDXL in human preference for both image quality and prompt alignment. Using more sampling steps\n",
      "<br/>further improves our model (bottom row).\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:3702px; width:237px; height:106px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">monly, a text embedding </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">text </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">is used in the text-to-image\n",
      "<br/>setting. But, in contrast to standard GAN training, our train-\n",
      "<br/>ing conﬁguration also allows to condition on a given image.\n",
      "<br/>For </span><span style=\"font-family: CMMI10; font-size:9px\">τ &lt; </span><span style=\"font-family: CMR10; font-size:9px\">1000</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, the ADD-student receives some signal from\n",
      "<br/>the input image </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. Therefore, for a given generated sample\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, we can condition the discriminator on information\n",
      "<br/>from </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. This encourages the ADD-student to utilize the\n",
      "<br/>input effectively. In practice, we use an additional feature\n",
      "<br/>network to extract an image embedding </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">img</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:3810px; width:238px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Following [57, 59], we use the hinge loss [32] as the\n",
      "<br/>adversarial objective function. Thus the ADD-student’s ad-\n",
      "<br/>versarial objective </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">amounts to\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:76px; top:3853px; width:13px; height:12px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">G\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:83px; top:3855px; width:68px; height:11px;\"><span style=\"font-family: CMR7; font-size:6px\">adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:99px; top:3872px; width:66px; height:18px;\"><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMSY10; font-size:9px\">−</span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">s,ϵ,x</span><span style=\"font-family: CMR5; font-size:4px\">0 </span><span style=\"font-family: CMEX10; font-size:9px\">h X\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:156px; top:3888px; width:4px; height:6px;\"><span style=\"font-family: CMMI7; font-size:6px\">k\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:167px; top:3874px; width:92px; height:13px;\"><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)))</span><span style=\"font-family: CMEX10; font-size:9px\">i </span><span style=\"font-family: CMMI10; font-size:9px\">,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:275px; top:3869px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(2)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:3904px; width:192px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">whereas the discriminator is trained to minimize\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:3921px; width:75px; height:36px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">D\n",
      "<br/>adv</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ϕ</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/>= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">x</span><span style=\"font-family: CMR5; font-size:4px\">0 </span><span style=\"font-family: CMEX10; font-size:9px\">h X\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:106px; top:3956px; width:4px; height:6px;\"><span style=\"font-family: CMMI7; font-size:6px\">k\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:117px; top:3942px; width:158px; height:13px;\"><span style=\"font-family: CMR10; font-size:9px\">max(0</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">1 </span><span style=\"font-family: CMSY10; font-size:9px\">− D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMR7; font-size:6px\">0</span><span style=\"font-family: CMR10; font-size:9px\">))) + </span><span style=\"font-family: CMMI10; font-size:9px\">γR</span><span style=\"font-family: CMR10; font-size:9px\">1(</span><span style=\"font-family: CMMI10; font-size:9px\">ϕ</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMEX10; font-size:9px\">i\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:70px; top:3968px; width:45px; height:18px;\"><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMR7; font-size:6px\">ˆ</span><span style=\"font-family: CMMI7; font-size:6px\">x</span><span style=\"font-family: CMMI5; font-size:4px\">θ </span><span style=\"font-family: CMEX10; font-size:9px\">h X\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:107px; top:3984px; width:4px; height:6px;\"><span style=\"font-family: CMMI7; font-size:6px\">k\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:118px; top:3970px; width:118px; height:13px;\"><span style=\"font-family: CMR10; font-size:9px\">max(0</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">1 + </span><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">F</span><span style=\"font-family: CMMI7; font-size:6px\">k</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">)))</span><span style=\"font-family: CMEX10; font-size:9px\">i </span><span style=\"font-family: CMMI10; font-size:9px\">,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3702px; width:238px; height:105px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where sg denotes the stop-gradient operation. Intuitively,\n",
      "<br/>the loss uses a distance metric </span><span style=\"font-family: CMMI10; font-size:9px\">d </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">to measure the mis-\n",
      "<br/>match between generated samples </span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">by the ADD-student\n",
      "<br/>and the DM-teacher’s outputs </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMMI10; font-size:9px\">, t</span><span style=\"font-family: CMR10; font-size:9px\">) = (ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t </span><span style=\"font-family: CMSY10; font-size:9px\">−\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMMI10; font-size:9px\">, t</span><span style=\"font-family: CMR10; font-size:9px\">))</span><span style=\"font-family: CMMI10; font-size:9px\">/α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">averaged over timesteps </span><span style=\"font-family: CMMI10; font-size:9px\">t </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and noise </span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMSY7; font-size:6px\">′</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\n",
      "<br/>Notably, the teacher is not directly applied on generations\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">of the ADD-student but instead on diffused outputs\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMSY7; font-size:6px\">′</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, as non-diffused inputs would be out-of-\n",
      "<br/>distribution for the teacher model [68].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3811px; width:238px; height:165px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">In the following, we deﬁne the distance function\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x, y</span><span style=\"font-family: CMR10; font-size:9px\">) := </span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMMI10; font-size:9px\">x </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">y</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\n",
      "<br/>2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. Regarding the weighting function\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, we consider two options: exponential weighting, where\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(higher noise levels contribute less), and score dis-\n",
      "<br/>tillation sampling (SDS) weighting [51]. In the supplemen-\n",
      "<br/>tary material, we demonstrate that with </span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x, y</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMMI10; font-size:9px\">x </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">y</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\n",
      "<br/>2\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and a speciﬁc choice for </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, our distillation loss becomes\n",
      "<br/>equivalent to the SDS objective </span><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">SDS</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, as proposed in [51].\n",
      "<br/>The advantage of our formulation is its ability to enable\n",
      "<br/>direct visualization of the reconstruction targets and that\n",
      "<br/>it naturally facilitates the execution of several consecutive\n",
      "<br/>denoising steps. Lastly, we also evaluate noise-free score\n",
      "<br/>distillation (NFSD) objective, a recently proposed variant of\n",
      "<br/>SDS [28].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:275px; top:3992px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(3)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:3991px; width:77px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">4. Experiments\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4012px; width:236px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR10; font-size:9px\">1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">denotes the R1 gradient penalty [44]. Rather\n",
      "<br/>than computing the gradient penalty with respect to the pixel\n",
      "<br/>values, we compute it on the input of each discriminator head\n",
      "<br/></span><span style=\"font-family: CMSY10; font-size:9px\">D</span><span style=\"font-family: CMMI7; font-size:6px\">ϕ,k</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. We ﬁnd that the </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR10; font-size:9px\">1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">penalty is particularly beneﬁcial\n",
      "<br/>when training at output resolutions larger than </span><span style=\"font-family: CMR10; font-size:9px\">128</span><span style=\"font-family: CMR7; font-size:6px\">2 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">px.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4079px; width:123px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">3.3. Score Distillation Loss\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4098px; width:185px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">The distillation loss in Eq. (1) is formulated as\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4012px; width:238px; height:105px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For our experiments, we train two models of different ca-\n",
      "<br/>pacities, ADD-M (860M parameters) and ADD-XL (3.1B\n",
      "<br/>parameters). For ablating ADD-M, we use a Stable Dif-\n",
      "<br/>fusion (SD) 2.1 backbone [54], and for fair comparisons\n",
      "<br/>with other baselines, we use SD1.5. ADD-XL utilizes a\n",
      "<br/>SDXL [50] backbone. All experiments are conducted at\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">a standardized resolution of 512x512 pixels; outputs from\n",
      "<br/>models generating higher resolutions are down-sampled to\n",
      "<br/>this size.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:80px; top:4118px; width:83px; height:26px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">distill</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">s</span><span style=\"font-family: CMMI10; font-size:9px\">, s</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">, ψ</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:139px; top:4141px; width:4px; height:9px;\"><span style=\"font-family: CMEX10; font-size:9px\">(cid:2)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:143px; top:4134px; width:103px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(sg(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">); </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">))\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:252px; top:4134px; width:2px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:247px; top:4141px; width:4px; height:9px;\"><span style=\"font-family: CMEX10; font-size:9px\">(cid:3)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:275px; top:4126px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(4)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4121px; width:236px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">We employ a distillation weighting factor of </span><span style=\"font-family: CMMI10; font-size:9px\">λ </span><span style=\"font-family: CMR10; font-size:9px\">= 2</span><span style=\"font-family: CMMI10; font-size:9px\">.</span><span style=\"font-family: CMR10; font-size:9px\">5\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">across all experiments. Additionally, the R1 penalty strength\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:4151px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:3489px; width:242px; height:147px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:3489px; width:242px; height:147px;\"></div>, <div style=\"position:absolute; top:4260px;\"><a name=\"6\">Page 6</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:66px; top:4330px; width:19px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Arch\n",
      "<br/>ViT-S\n",
      "<br/>ViT-S\n",
      "<br/>ViT-L\n",
      "<br/>ViT-L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:98px; top:4330px; width:57px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Objective FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">21.5\n",
      "<br/>DINOv1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">DINOv2\n",
      "<br/>24.0\n",
      "<br/>DINOv2\n",
      "<br/>23.3\n",
      "<br/>CLIP\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:168px; top:4330px; width:17px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.312\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.319\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.302\n",
      "<br/>0.308\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:242px; top:4329px; width:16px; height:49px;\"><span style=\"font-family: CMMI8; font-size:7px\">c</span><span style=\"font-family: CMR6; font-size:5px\">text\n",
      "<br/></span><span style=\"font-family: Dingbats; font-size:7px\">✗\n",
      "<br/>✓\n",
      "<br/>✗\n",
      "<br/>✓\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:274px; top:4329px; width:15px; height:49px;\"><span style=\"font-family: CMMI8; font-size:7px\">c</span><span style=\"font-family: CMR6; font-size:5px\">img\n",
      "<br/></span><span style=\"font-family: Dingbats; font-size:7px\">✗\n",
      "<br/>✗\n",
      "<br/>✓\n",
      "<br/>✓\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:305px; top:4330px; width:19px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">21.2\n",
      "<br/>21.2\n",
      "<br/>21.1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:4330px; width:17px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.302\n",
      "<br/>0.307\n",
      "<br/>0.316\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.319\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:416px; top:4330px; width:40px; height:28px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Initialization\n",
      "<br/>Random\n",
      "<br/>Pretrained\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:476px; top:4330px; width:44px; height:28px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">293.6 0.065\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.319\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:480px; top:4351px; width:13px; height:7px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:52px; top:4383px; width:149px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(a) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Discriminator feature networks</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. Small,\n",
      "<br/>modern DINO networks perform best.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:223px; top:4383px; width:148px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(b) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Discriminator conditioning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. Combining\n",
      "<br/>image and text conditioning is most effective.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:394px; top:4383px; width:150px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(c) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Student pretraining</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. A randomly initial-\n",
      "<br/>ized student network collapses.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:62px; top:4407px; width:59px; height:59px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Loss\n",
      "<br/></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv\n",
      "<br/></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill\n",
      "<br/></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv </span><span style=\"font-family: CMR8; font-size:7px\">+ </span><span style=\"font-family: CMMI8; font-size:7px\">λ</span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill,exp\n",
      "<br/></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv </span><span style=\"font-family: CMR8; font-size:7px\">+ </span><span style=\"font-family: CMMI8; font-size:7px\">λ</span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill,sds\n",
      "<br/></span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">adv </span><span style=\"font-family: CMR8; font-size:7px\">+</span><span style=\"font-family: CMMI8; font-size:7px\">λ</span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill,nfsd\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:136px; top:4407px; width:19px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">20.8\n",
      "<br/>315.6\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">22.3\n",
      "<br/>21.8\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:172px; top:4407px; width:17px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.315\n",
      "<br/>0.076\n",
      "<br/>0.319\n",
      "<br/>0.325\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.327\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:238px; top:4407px; width:24px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Student\n",
      "<br/>SD2.1\n",
      "<br/>SD2.1\n",
      "<br/>SDXL\n",
      "<br/>SDXL\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:273px; top:4407px; width:25px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Teacher\n",
      "<br/>SD2.1\n",
      "<br/>SDXL\n",
      "<br/>SD2.1\n",
      "<br/>SDXL\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:309px; top:4407px; width:19px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">21.3\n",
      "<br/>29.3\n",
      "<br/>28.41\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:341px; top:4407px; width:17px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.319\n",
      "<br/>0.321\n",
      "<br/>0.314\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.325\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:429px; top:4407px; width:17px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">Steps\n",
      "<br/>1\n",
      "<br/>2\n",
      "<br/>4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:457px; top:4407px; width:19px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">FID </span><span style=\"font-family: CMSY8; font-size:7px\">↓\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">20.6\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">20.8\n",
      "<br/>20.3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:489px; top:4407px; width:17px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">CS </span><span style=\"font-family: CMSY8; font-size:7px\">↑\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.319\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">0.321\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">0.317\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:52px; top:4470px; width:148px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(d) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Loss terms</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. Both losses are needed and\n",
      "<br/>exponential weighting of </span><span style=\"font-family: CMSY8; font-size:7px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">distill </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">is beneﬁcial.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:223px; top:4470px; width:148px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(e) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Teacher type</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. The student adopts the\n",
      "<br/>teacher’s traits (SDXL has higher FID &amp; CS).\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:394px; top:4470px; width:150px; height:17px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">(f) </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:7px\">Teacher steps</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">. A single teacher step is sufﬁ-\n",
      "<br/>cient.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4498px; width:496px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Table 1. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">ADD ablation study. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We report COCO zero-shot FID</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">5k </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">(FID) and CLIP score (CS). The results are calculated for a single student\n",
      "<br/>step. The default training settings are: DINOv2 ViT-S as the feature network, text and image conditioning for the discriminator, pretrained\n",
      "<br/>student weights, a small teacher and student model, and a single teacher step. The training length is 4000 iterations with a batch size of 128.\n",
      "<br/>Default settings are marked in gray .\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:4559px; width:238px; height:238px;\"><span style=\"font-family: CMMI10; font-size:9px\">γ </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">is set to </span><span style=\"font-family: CMR10; font-size:9px\">10</span><span style=\"font-family: CMSY7; font-size:6px\">−</span><span style=\"font-family: CMR7; font-size:6px\">5</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. For discriminator conditioning, we use\n",
      "<br/>a pretrained CLIP-ViT-g-14 text encoder [52] to compute\n",
      "<br/>text embeddings </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">text </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and the CLS embedding of a DINOv2\n",
      "<br/>ViT-L encoder [47] for image embeddings </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">img</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. For the\n",
      "<br/>baselines, we use the best publicly available models: La-\n",
      "<br/>tent diffusion models [50, 54] (SD1.5</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, SDXL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">) cascaded\n",
      "<br/>pixel diffusion models [55] (IF-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">3</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">), distilled diffusion mod-\n",
      "<br/>els [39, 41] (LCM-1.5, LCM-1.5-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">4</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">), and OpenMUSE\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">5 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">[48], a reimplementation of MUSE [6], a transformer\n",
      "<br/>model speciﬁcally developed for fast inference. Note that\n",
      "<br/>we compare to the SDXL-Base-1.0 model without its addi-\n",
      "<br/>tional reﬁner model; this is to ensure a fair comparison. As\n",
      "<br/>there are no public state-of-the-art GAN models, we retrain\n",
      "<br/>StyleGAN-T [59] with our improved discriminator. This\n",
      "<br/>baseline (StyleGAN-T++) signiﬁcantly outperforms the pre-\n",
      "<br/>vious best GANs in FID and CS, see supplementary. We\n",
      "<br/>quantify sample quality via FID [18] and text alignment via\n",
      "<br/>CLIP score [17]. For CLIP score, we use ViT-g-14 model\n",
      "<br/>trained on LAION-2B [61]. Both metrics are evaluated on\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">5k samples from COCO2017 [34].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4807px; width:90px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">4.1. Ablation Study\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4827px; width:237px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our training setup opens up a number of design spaces re-\n",
      "<br/>garding the adversarial loss, distillation loss, initialization,\n",
      "<br/>and loss interplay. We conduct an ablation study on several\n",
      "<br/>choices in Table 1; key insights are highlighted below each\n",
      "<br/>table. We will discuss each experiment in the following.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:4892px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Discriminator feature networks.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1a). Recent\n",
      "<br/>insights by Stein et al. [67] suggest that ViTs trained with the\n",
      "<br/>CLIP [52] or DINO [5, 47] objectives are particularly well-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:4936px; width:180px; height:48px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">1</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/CompVis/stable-diffusion\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/Stability-AI/generative-models\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">3</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/deep-ﬂoyd/IF\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">4</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/latent-consistency/lcm-lora-sdxl\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">5</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/openMUSE\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:4993px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4560px; width:237px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">suited for evaluating the performance of generative models.\n",
      "<br/>Similarly, these models also seem effective as discriminator\n",
      "<br/>feature networks, with DINOv2 emerging as the best choice.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4607px; width:237px; height:58px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Discriminator conditioning. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1b). Similar to prior\n",
      "<br/>studies, we observe that text conditioning of the discrimi-\n",
      "<br/>nator enhances results. Notably, image conditioning outper-\n",
      "<br/>forms text conditioning, and the combination of both </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">text\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR7; font-size:6px\">img </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">yields the best results.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4677px; width:237px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Student pretraining. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1c). Our experiments demon-\n",
      "<br/>strate the importance of pretraining the ADD-student. Being\n",
      "<br/>able to use pretrained generators is a signiﬁcant advantage\n",
      "<br/>over pure GAN approaches. A problem of GANs is the lack\n",
      "<br/>of scalability; both Sauer et al. [59] and Kang et al. [25]\n",
      "<br/>observe a saturation of performance after a certain network\n",
      "<br/>capacity is reached. This observation contrasts the generally\n",
      "<br/>smooth scaling laws of DMs [49]. However, ADD can ef-\n",
      "<br/>fectively leverage larger pretrained DMs (see Table 1c) and\n",
      "<br/>beneﬁt from stable DM pretraining.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:4807px; width:238px; height:165px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Loss terms. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1d). We ﬁnd that both losses are essen-\n",
      "<br/>tial. The distillation loss on its own is not effective, but when\n",
      "<br/>combined with the adversarial loss, there is a noticeable im-\n",
      "<br/>provement in results. Different weighting schedules lead\n",
      "<br/>to different behaviours, the exponential schedule tends to\n",
      "<br/>yield more diverse samples, as indicated by lower FID, SDS\n",
      "<br/>and NFSD schedules improve quality and text alignment.\n",
      "<br/>While we use the exponential schedule as the default setting\n",
      "<br/>in all other ablations, we opt for the NFSD weighting for\n",
      "<br/>training our ﬁnal model. Choosing an optimal weighting\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">function presents an opportunity for improvement. Alterna-\n",
      "<br/>tively, scheduling the distillation weights over training, as\n",
      "<br/>explored in the 3D generative modeling literature [23] could\n",
      "<br/>be considered.\n",
      "<br/></span></div>, <div style=\"position:absolute; top:5102px;\"><a name=\"7\">Page 7</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5331px; width:495px; height:31px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 6. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">multiple steps</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-XL (4-step) against established baselines. Our\n",
      "<br/>ADD-XL model outperforms all models, including its teacher SDXL 1.0 (base, no reﬁner) [50], in human preference for both image quality\n",
      "<br/>and prompt alignment.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5387px; width:21px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">Method\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:156px; top:5387px; width:18px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">#Steps\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:186px; top:5387px; width:23px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">Time (s)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:222px; top:5387px; width:17px; height:7px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">FID </span><span style=\"font-family: CMSY7; font-size:6px\">↓\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:251px; top:5387px; width:20px; height:7px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">CLIP </span><span style=\"font-family: CMSY7; font-size:6px\">↑\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5404px; width:48px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">DPM Solver [37]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5429px; width:78px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">Progressive Distillation [43]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5450px; width:80px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">CFG-Aware Distillation [31]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5463px; width:56px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">InstaFlow-0.9B [36]\n",
      "<br/>InstaFlow-1.7B [36]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5484px; width:38px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">UFOGen [71]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:64px; top:5497px; width:23px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">ADD-M\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:162px; top:5400px; width:6px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">25\n",
      "<br/>8\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5421px; width:3px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\n",
      "<br/>2\n",
      "<br/>4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5450px; width:3px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">8\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5463px; width:3px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\n",
      "<br/>1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5484px; width:3px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:163px; top:5497px; width:3px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5400px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.88\n",
      "<br/>0.34\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5421px; width:12px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\n",
      "<br/>0.13\n",
      "<br/>0.21\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5450px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.34\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5463px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\n",
      "<br/>0.12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5484px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:192px; top:5497px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.09\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5400px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">20.1\n",
      "<br/>31.7\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5421px; width:12px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">37.2\n",
      "<br/>26.0\n",
      "<br/>26.4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5450px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">24.2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5463px; width:12px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">23.4\n",
      "<br/>22.4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5484px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">22.5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:224px; top:5497px; width:12px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:6px\">19.7\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5400px; width:15px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.318\n",
      "<br/>0.320\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5421px; width:15px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.275\n",
      "<br/>0.297\n",
      "<br/>0.300\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5450px; width:15px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.300\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5463px; width:15px; height:14px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.304\n",
      "<br/>0.309\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5484px; width:15px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">0.311\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:5497px; width:15px; height:6px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:6px\">0.326\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:310px; top:5408px; width:8px; height:35px;\"><span style=\"font-family: CMSY10; font-size:4px\">↓\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">]\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">[\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">d\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/>e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:310px; top:5446px; width:8px; height:31px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/>c\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">r\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">f\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">I\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:324px; top:5393px; width:8px; height:17px;\"><span style=\"font-family: CMR10; font-size:8px\">12\n",
      "<br/>10\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5430px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5445px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5467px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:5498px; width:4px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">0\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5518px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Table 2. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Distillation Comparison </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare ADD to other\n",
      "<br/>distillation methods via COCO zero-shot FID</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">5k </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">(FID) and CLIP\n",
      "<br/>score (CS). All models are based on SD1.5.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5575px; width:238px; height:69px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Teacher type.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1e). Interestingly, a bigger student\n",
      "<br/>and teacher does not necessarily result in better FID and\n",
      "<br/>CS. Rather, the student adopts the teachers characteristics.\n",
      "<br/>SDXL obtains generally higher FID, possibly because of its\n",
      "<br/>less diverse output, yet it exhibits higher image quality and\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">text alignment [50].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:5654px; width:236px; height:45px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:9px\">Teacher steps.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(Table 1f). While our distillation loss\n",
      "<br/>formulation allows taking several consecutive steps with the\n",
      "<br/>teacher by construction, we ﬁnd that several steps do not\n",
      "<br/>conclusively result in better performance.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:5713px; width:228px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">4.2. Quantitative Comparison to State of the Art\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:5733px; width:237px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For our main comparison with other approaches, we refrain\n",
      "<br/>from using automated metrics, as user preference studies\n",
      "<br/>are more reliable [50]. In the study, we aim to assess both\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">prompt adherence and the overall image. As a performance\n",
      "<br/>measure, we compute win percentages for pairwise compar-\n",
      "<br/>isons and ELO scores when comparing several approaches.\n",
      "<br/>For the reported ELO scores we calculate the mean scores\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:5835px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">7\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:410px; top:5394px; width:36px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">IF-XL\n",
      "<br/>(150 steps)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:451px; top:5422px; width:32px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">SDXL\n",
      "<br/>(50 steps)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:351px; top:5451px; width:40px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">OpenMUSE\n",
      "<br/>(16 steps)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:357px; top:5503px; width:12px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">900\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:386px; top:5503px; width:12px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">950\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:412px; top:5460px; width:31px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">LCM-XL\n",
      "<br/>(4 steps)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:428px; top:5482px; width:31px; height:29px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ADD-XL\n",
      "<br/>(1 step)\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">050\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:410px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">000\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:423px; top:5516px; width:22px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ELO </span><span style=\"font-family: CMSY10; font-size:8px\">↑\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:483px; top:5460px; width:31px; height:18px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ADD-XL\n",
      "<br/>(4 steps)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:467px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">100\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:495px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">150\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:523px; top:5503px; width:18px; height:8px;\"><span style=\"font-family: CMR10; font-size:8px\">1</span><span style=\"font-family: CMMI10; font-size:8px\">,</span><span style=\"font-family: CMR10; font-size:8px\">200\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5532px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 7. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Performance vs. speed. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We visualize the results reported\n",
      "<br/>in Fig. 6 in combination with the inference speeds of the respective\n",
      "<br/>models. The speeds are calculated for generating a single sample\n",
      "<br/>at resolution 512x512 on an A100 in mixed precision.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5598px; width:236px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">between both prompt following and image quality. Details\n",
      "<br/>on the ELO score computation and the study parameters are\n",
      "<br/>listed in the supplementary material.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5634px; width:238px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Fig. 5 and Fig. 6 present the study results. The most im-\n",
      "<br/>portant results are: First, ADD-XL outperforms LCM-XL (4\n",
      "<br/>steps) with a single step. Second, ADD-XL can beat SDXL\n",
      "<br/>(50 steps) with four steps in the majority of comparisons.\n",
      "<br/>This makes ADD-XL the state-of-the-art in both the single\n",
      "<br/>and the multiple steps setting. Fig. 7 visualizes ELO scores\n",
      "<br/>relative to inference speed. Lastly, Table 2 compares dif-\n",
      "<br/>ferent few-step sampling and distillation methods using the\n",
      "<br/>same base model. ADD outperforms all other approaches\n",
      "<br/>including the standard DPM solver with eight steps.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5762px; width:108px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">4.3. Qualitative Results\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:5781px; width:238px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">To complement our quantitative studies above, we present\n",
      "<br/>qualitative results in this section. To paint a more complete\n",
      "<br/>picture, we provide additional samples and qualitative com-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:5173px; width:242px; height:147px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:5173px; width:242px; height:147px;\"></div>, <div style=\"position:absolute; top:5944px;\"><a name=\"8\">Page 8</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:99px; top:6036px; width:205px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A cinematic shot of a little pig priest wearing sunglasses.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:6015px; width:219px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A photograph of the inside of a subway train. There are frogs\n",
      "<br/>sitting on the seats. One of them is reading a newspaper. The\n",
      "<br/>window shows the river in the background.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:89px; top:6172px; width:223px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A photo of an astronaut riding a horse in the forest. There is a\n",
      "<br/>river in front of them with water lilies.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:363px; top:6183px; width:151px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A photo of a cute mouse wearing a crown.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6076px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6064px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/>D\n",
      "<br/>A\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6066px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6115px; width:8px; height:43px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">B\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6119px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">0\n",
      "<br/>5\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6222px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6210px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/>D\n",
      "<br/>A\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6212px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:6261px; width:8px; height:43px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">B\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:6265px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">0\n",
      "<br/>5\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:6319px; width:495px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 8. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Qualitative comparison to the teacher model. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ADD-XL can outperform its teacher model SDXL in the multi-step setting. The\n",
      "<br/>adversarial loss boosts realism, particularly enhancing textures (fur, fabric, skin) while reducing oversmoothing, commonly observed in\n",
      "<br/>diffusion model samples. ADD-XL’s overall sample diversity tends to be lower.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:6374px; width:238px; height:141px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">parisons in the supplementary material. Fig. 3 compares\n",
      "<br/>ADD-XL (1 step) against the best current baselines in the\n",
      "<br/>few-steps regime. Fig. 4 illustrates the iterative sampling\n",
      "<br/>process of ADD-XL. These results showcase our model’s\n",
      "<br/>ability to improve upon an initial sample. Such iterative\n",
      "<br/>improvement represents another signiﬁcant beneﬁt over pure\n",
      "<br/>GAN approaches like StyleGAN-T++. Lastly, Fig. 8 com-\n",
      "<br/>pares ADD-XL directly with its teacher model SDXL-Base.\n",
      "<br/>As indicated by the user studies in Section 4.2, ADD-XL\n",
      "<br/>outperforms its teacher in both quality and prompt alignment.\n",
      "<br/>The enhanced realism comes at the cost of slightly decreased\n",
      "<br/>sample diversity.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:6530px; width:65px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">5. Discussion\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:6551px; width:238px; height:117px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">This work introduces </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">Adversarial Diffusion Distillation</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, a\n",
      "<br/>general method for distilling a pretrained diffusion model\n",
      "<br/>into a fast, few-step image generation model. We combine\n",
      "<br/>an adversarial and a score distillation objective to distill the\n",
      "<br/>public Stable Diffusion [54] and SDXL [50] models, lever-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">aging both real data through the discriminator and structural\n",
      "<br/>understanding through the diffusion teacher. Our approach\n",
      "<br/>performs particularly well in the ultra-fast sampling regime\n",
      "<br/>of one or two steps, and our analyses demonstrate that it out-\n",
      "<br/>performs all concurrent methods in this regime. Furthermore,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:6677px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">8\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6374px; width:238px; height:45px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">we retain the ability to reﬁne samples using multiple steps.\n",
      "<br/>In fact, using four sampling steps, our model outperforms\n",
      "<br/>widely used multi-step generators such as SDXL, IF, and\n",
      "<br/>OpenMUSE.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6422px; width:236px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Our model enables the generation of high quality images\n",
      "<br/>in a single-step, opening up new possibilities for real-time\n",
      "<br/>generation with foundation models.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6468px; width:98px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">Acknowledgements\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6488px; width:237px; height:93px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">We would like to thank Jonas M¨uller for feedback on the\n",
      "<br/>draft, the proof, and typesetting; Patrick Esser for feedback\n",
      "<br/>on the proof and building an early model demo; Frederic\n",
      "<br/>Boesel for generating data and helpful discussions; Minguk\n",
      "<br/>Kang and Taesung Park for providing GigaGAN samples;\n",
      "<br/>Richard Vencu, Harry Saini, and Sami Kama for maintaining\n",
      "<br/>the compute infrastructure; Yara Wald for creative sampling\n",
      "<br/>support; and Vanessa Sauer for her general support.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6594px; width:55px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">References\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:313px; top:6615px; width:233px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[1] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep\n",
      "<br/>Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben\n",
      "<br/>Mann, Nova DasSarma, Nelson Elhage, Zac Hatﬁeld-Dodds,\n",
      "<br/>Danny Hernandez, Jackson Kernion, Kamal Ndousse, Cather-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6051px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6051px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6107px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6107px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6198px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6198px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:6253px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:6253px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; top:6786px;\"><a name=\"9\">Page 9</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:6860px; width:233px; height:141px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam\n",
      "<br/>McCandlish, Chris Olah, and Jared Kaplan. A general lan-\n",
      "<br/>guage assistant as a laboratory for alignment, 2021. 13\n",
      "<br/>[2] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell,\n",
      "<br/>Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort,\n",
      "<br/>Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\n",
      "<br/>davath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nel-\n",
      "<br/>son Elhage, Zac Hatﬁeld-Dodds, Danny Hernandez, Tristan\n",
      "<br/>Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel\n",
      "<br/>Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack\n",
      "<br/>Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared\n",
      "<br/>Kaplan. Training a helpful and harmless assistant with rein-\n",
      "<br/>forcement learning from human feedback, 2022. 13\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7006px; width:233px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[3] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat,\n",
      "<br/>Jiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala,\n",
      "<br/>Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, and\n",
      "<br/>Ming-Yu Liu. ediff-i: Text-to-image diffusion models with an\n",
      "<br/>ensemble of expert denoisers. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2211.01324, 2022.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">1, 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7073px; width:233px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[4] A. Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn,\n",
      "<br/>Seung Wook Kim, Sanja Fidler, and Karsten Kreis. Align your\n",
      "<br/>latents: High-resolution video synthesis with latent diffusion\n",
      "<br/>models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2023 IEEE/CVF Conference on Computer Vision\n",
      "<br/>and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 22563–22575, 2023.\n",
      "<br/>1, 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7140px; width:233px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou,\n",
      "<br/>Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-\n",
      "<br/>ing properties in self-supervised vision transformers. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Pro-\n",
      "<br/>ceedings of the IEEE/CVF international conference on com-\n",
      "<br/>puter vision</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 9650–9660, 2021. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7196px; width:233px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[6] Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot,\n",
      "<br/>Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy,\n",
      "<br/>William T Freeman, Michael Rubinstein, et al. Muse: Text-to-\n",
      "<br/>image generation via masked generative transformers. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proc.\n",
      "<br/>ICML</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7252px; width:233px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[7] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang\n",
      "<br/>Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiao-\n",
      "<br/>fang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image\n",
      "<br/>generation models using photogenic needles in a haystack.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2309.15807</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7309px; width:233px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[8] Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Genie:\n",
      "<br/>Higher-order denoising diffusion solvers. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in Neural\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Information Processing Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 35:30150–30166, 2022. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:7343px; width:233px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\n",
      "<br/>Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\n",
      "<br/>Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\n",
      "<br/>vain Gelly, et al. An image is worth 16x16 words: Trans-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">formers for image recognition at scale.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv:2010.11929</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2020. 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7410px; width:237px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[10] Arpad E. Elo. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">The Rating of Chessplayers, Past and Present</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:69px; top:7421px; width:113px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Arco Pub., New York, 1978. 13\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7433px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[11] Patrick Esser, Robin Rombach, and Bj¨orn Ommer. Tam-\n",
      "<br/>ing transformers for high-resolution image synthesis. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2021\n",
      "<br/>IEEE/CVF Conference on Computer Vision and Pattern\n",
      "<br/>Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 12868–12878, 2020. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7479px; width:237px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[12] Patrick Esser, Johnathan Chiu, Parmida Atighehchian,\n",
      "<br/>Jonathan Granskog, and Anastasis Germanidis. Structure\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:6860px; width:217px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">and content-guided video synthesis with diffusion models,\n",
      "<br/>2023. 1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6883px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[13] Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos,\n",
      "<br/>Thibaut Issenhuth, Emmanuel de B´ezenac, Micka¨el Chen,\n",
      "<br/>and Alain Rakotomamonjy. Unifying gans and score-based\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">diffusion as generative particle models.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv:2305.16150</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:6939px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[14] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing\n",
      "<br/>Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville,\n",
      "<br/>and Yoshua Bengio. Generative adversarial networks. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Com-\n",
      "<br/>munications of the ACM</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 63:139 – 144, 2014. 1, 2, 4\n",
      "<br/>[15] Timofey Grigoryev, Andrey Voynov, and Artem Babenko.\n",
      "<br/>When, why, and which pretrained gans are useful? </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ICLR</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/>2022. 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7018px; width:237px; height:109px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[16] Amir Hertz, Kﬁr Aberman, and Daniel Cohen-Or. Delta de-\n",
      "<br/>noising score. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of the IEEE/CVF International\n",
      "<br/>Conference on Computer Vision</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 2328–2337, 2023. 3\n",
      "<br/>[17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,\n",
      "<br/>and Yejin Choi. CLIPScore: A reference-free evaluation\n",
      "<br/>metric for image captioning. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proc. EMNLP</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2021. 6\n",
      "<br/>[18] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bern-\n",
      "<br/>hard Nessler, and Sepp Hochreiter. GANs trained by a two\n",
      "<br/>time-scale update rule converge to a local Nash equilibrium.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">NeurIPS</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2017. 6, 12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7131px; width:237px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[19] Jonathan Ho. Classiﬁer-free diffusion guidance. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:7142px; width:89px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">abs/2207.12598, 2022. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7154px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[20] Jonathan Ho, Ajay Jain, and P. Abbeel. Denoising diffusion\n",
      "<br/>probabilistic models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2006.11239, 2020. 1\n",
      "<br/>[21] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang,\n",
      "<br/>Ruiqi Gao, Alexey A. Gritsenko, Diederik P. Kingma, Ben\n",
      "<br/>Poole, Mohammad Norouzi, David J. Fleet, and Tim Salimans.\n",
      "<br/>Imagen video: High deﬁnition video generation with diffusion\n",
      "<br/>models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2210.02303, 2022. 1, 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7232px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[22] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\n",
      "<br/>Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank\n",
      "<br/>adaptation of large language models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2106.09685,\n",
      "<br/>2021. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7277px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[23] Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-\n",
      "<br/>Jun Zha, and Lei Zhang. Dreamtime: An improved optimiza-\n",
      "<br/>tion strategy for text-to-3d content creation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2306.12422</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7322px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[24] Alexia Jolicoeur-Martineau, R´emi Pich´e-Taillefer, R´emi Ta-\n",
      "<br/>chet des Combes, and Ioannis Mitliagkas. Adversarial score\n",
      "<br/>matching and improved sampling for image generation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\n",
      "<br/>preprint arXiv:2009.05475</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2020. 3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7367px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[25] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli\n",
      "<br/>Shechtman, Sylvain Paris, and Taesung Park. Scaling up gans\n",
      "<br/>for text-to-image synthesis. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of the IEEE/CVF\n",
      "<br/>Conference on Computer Vision and Pattern Recognition</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/>pages 10124–10134, 2023. 1, 2, 6, 14\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7423px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[26] Tero Karras, Samuli Laine, and Timo Aila. A style-based\n",
      "<br/>generator architecture for generative adversarial networks.\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2019 IEEE/CVF Conference on Computer Vision and Pattern\n",
      "<br/>Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 4396–4405, 2018. 1, 4, 14\n",
      "<br/>[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,\n",
      "<br/>Jaakko Lehtinen, and Timo Aila. Analyzing and improving\n",
      "<br/>the image quality of stylegan. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2020 IEEE/CVF Conference\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:295px; top:7519px; width:4px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">9\n",
      "<br/></span></div>, <div style=\"position:absolute; top:7628px;\"><a name=\"10\">Page 10</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:70px; top:7702px; width:216px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">on Computer Vision and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\n",
      "<br/>8107–8116, 2019. 1, 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:328px; top:7702px; width:216px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">proach for transferring knowledge from pre-trained diffusion\n",
      "<br/>models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2305.18455</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7725px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[28] Oren Katzir, Or Patashnik, Daniel Cohen-Or, and Dani\n",
      "<br/>Lischinski. Noise-free score distillation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2310.17590</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7759px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[29] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Mu-\n",
      "<br/>rata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki\n",
      "<br/>Mitsufuji, and Stefano Ermon. Consistency trajectory models:\n",
      "<br/>Learning probability ﬂow ode trajectory of diffusion. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\n",
      "<br/>preprint arXiv:2310.02279</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7815px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[30] Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Ma-\n",
      "<br/>tiana, Joe Penna, and Omer Levy. Pick-a-pic: An open dataset\n",
      "<br/>of user preferences for text-to-image generation, 2023. 12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7849px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[31] Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun\n",
      "<br/>Fu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren. Snapfusion:\n",
      "<br/>Text-to-image diffusion model on mobile devices within two\n",
      "<br/>seconds. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2306.00980</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 7\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7894px; width:236px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[32] Jae Hyun Lim and Jong Chul Ye. Geometric gan. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:70px; top:7905px; width:129px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">preprint arXiv:1705.02894</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2017. 5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7917px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[33] Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Com-\n",
      "<br/>mon diffusion noise schedules and sample steps are ﬂawed,\n",
      "<br/>2023. 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7951px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bour-\n",
      "<br/>dev, Ross Girshick, James Hays, Pietro Perona, Deva Ra-\n",
      "<br/>manan, C. Lawrence Zitnick, and Piotr Doll´ar. Microsoft\n",
      "<br/>coco: Common objects in context, 2015. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:7996px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[35] Xingchao Liu, Chengyue Gong, et al. Flow straight and\n",
      "<br/>fast: Learning to generate and transfer data with rectiﬁed\n",
      "<br/>ﬂow. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">The Eleventh International Conference on Learning\n",
      "<br/>Representations</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8040px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[36] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, and\n",
      "<br/>Qiang Liu. Instaﬂow: One step is enough for high-quality\n",
      "<br/>diffusion-based text-to-image generation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2309.06380</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2, 3, 7, 15\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8085px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[37] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan\n",
      "<br/>Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion\n",
      "<br/>probabilistic model sampling in around 10 steps. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in\n",
      "<br/>Neural Information Processing Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 35:5775–5787, 2022.\n",
      "<br/>2, 7\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8141px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[38] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and\n",
      "<br/>Latent consistency models: Synthesizing\n",
      "<br/>Hang Zhao.\n",
      "<br/>high-resolution images with few-step inference. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">abs/2310.04378, 2023. 2, 13\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8186px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[39] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang\n",
      "<br/>Zhao.\n",
      "<br/>Latent consistency models: Synthesizing high-\n",
      "<br/>resolution images with few-step inference. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2310.04378</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8231px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[40] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\n",
      "<br/>Platen, Apolin’ario Passos, Longbo Huang, Jian Li, and Hang\n",
      "<br/>Zhao. Lcm-lora: A universal stable-diffusion acceleration\n",
      "<br/>module. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2311.05556, 2023. 2, 3, 13, 15\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8276px; width:236px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[41] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\n",
      "<br/>Platen, Apolin</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">´</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ario Passos, Longbo Huang, Jian Li, and Hang\n",
      "<br/>Zhao. Lcm-lora: A universal stable-diffusion acceleration\n",
      "<br/>module. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2311.05556</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8321px; width:237px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[42] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun,\n",
      "<br/>Zhenguo Li, and Zhihua Zhang. Diff-instruct: A universal ap-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7726px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[43] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik\n",
      "<br/>Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.\n",
      "<br/>On distillation of guided diffusion models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of\n",
      "<br/>the IEEE/CVF Conference on Computer Vision and Pattern\n",
      "<br/>Recognition</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 14297–14306, 2023. 2, 7\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7782px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[44] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.\n",
      "<br/>Which training methods for gans do actually converge? In\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International conference on machine learning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 3481–\n",
      "<br/>3490. PMLR, 2018. 5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7827px; width:236px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[45] Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and\n",
      "<br/>Daniel Cohen-Or. Latent-nerf for shape-guided generation\n",
      "<br/>of 3d shapes and textures. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2023 IEEE/CVF Conference on\n",
      "<br/>Computer Vision and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\n",
      "<br/>12663–12673, 2022. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7883px; width:237px; height:75px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[46] Takeru Miyato and Masanori Koyama. cgans with projection\n",
      "<br/>discriminator. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:1802.05637</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2018. 4\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[47] Maxime Oquab, Timoth</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">´</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">ee Darcet, Th</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">´</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">eo Moutakanni, Huy Vo,\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel\n",
      "<br/>Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2:\n",
      "<br/>Learning robust visual features without supervision. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv\n",
      "<br/>preprint arXiv:2304.07193</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7962px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[48] Suraj Patil, William Berman, and Patrick von Platen. Amused:\n",
      "<br/>An open muse model. https://github.com/huggingface/\n",
      "<br/>diffusers, 2023. 6, 15\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:7996px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[49] William Peebles and Saining Xie. Scalable diffusion models\n",
      "<br/>with transformers. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceedings of the IEEE/CVF Inter-\n",
      "<br/>national Conference on Computer Vision</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 4195–4205,\n",
      "<br/>2023. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8041px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[50] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann,\n",
      "<br/>Tim Dockhorn, Jonas M¨uller, Joe Penna, and Robin Rombach.\n",
      "<br/>Sdxl: Improving latent diffusion models for high-resolution\n",
      "<br/>image synthesis. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2307.01952</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2,\n",
      "<br/>4, 5, 6, 7, 8, 12, 13\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8097px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[51] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.\n",
      "<br/>Dreamfusion: Text-to-3d using 2d diffusion. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2209.14988</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 2, 5, 12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8131px; width:237px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[52] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\n",
      "<br/>Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\n",
      "<br/>Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">transferable visual models from natural language supervi-\n",
      "<br/>sion. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International conference on machine learning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\n",
      "<br/>8748–8763. PMLR, 2021. 6, 12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8198px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[53] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,\n",
      "<br/>and Mark Chen. Hierarchical text-conditional image gener-\n",
      "<br/>ation with clip latents. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2204.06125, 2022. 1, 2,\n",
      "<br/>4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8243px; width:236px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[54] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick\n",
      "<br/>Esser, and Bj¨orn Ommer. High-resolution image synthesis\n",
      "<br/>with latent diffusion models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">2022 IEEE/CVF Conference\n",
      "<br/>on Computer Vision and Pattern Recognition (CVPR)</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">10674–10685, 2021. 1, 2, 5, 6, 8\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8299px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[55] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,\n",
      "<br/>Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael\n",
      "<br/>Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Pho-\n",
      "<br/>torealistic text-to-image diffusion models with deep language\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:8361px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">10\n",
      "<br/></span></div>, <div style=\"position:absolute; top:8470px;\"><a name=\"11\">Page 11</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8544px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[70] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling\n",
      "<br/>the generative learning trilemma with denoising diffusion\n",
      "<br/>gans. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2112.07804</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2021. 3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8578px; width:237px; height:86px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[71] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufo-\n",
      "<br/>gen: You forward once large scale text-to-image generation\n",
      "<br/>via diffusion gans. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2311.09257</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 7\n",
      "<br/>[72] Chun-Han Yao, Amit Raj, Wei-Chih Hung, Yuanzhen Li,\n",
      "<br/>Michael Rubinstein, Ming-Hsuan Yang, and Varun Jampani.\n",
      "<br/>Artic3d: Learning robust articulated 3d shapes from noisy\n",
      "<br/>web image collections. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2306.04619</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/>2023. 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8668px; width:237px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[73] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan\n",
      "<br/>Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei\n",
      "<br/>Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana\n",
      "<br/>Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui\n",
      "<br/>Wu. Scaling autoregressive models for content-rich text-to-\n",
      "<br/>image generation, 2022. 12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:308px; top:8735px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[74] Qinsheng Zhang and Yongxin Chen. Fast sampling of dif-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">fusion models with exponential integrator. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2204.13902</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:69px; top:8544px; width:216px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">understanding. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in Neural Information Processing\n",
      "<br/>Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 35:36479–36494, 2022. 4, 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8567px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[56] Tim Salimans and Jonathan Ho. Progressive distillation for\n",
      "<br/>fast sampling of diffusion models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">CoRR</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2202.00512,\n",
      "<br/>2022. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8601px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[57] Axel Sauer, Kashyap Chitta, Jens M¨uller, and Andreas Geiger.\n",
      "<br/>Projected gans converge faster. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Advances in Neural Informa-\n",
      "<br/>tion Processing Systems</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 34:17480–17492, 2021. 5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8635px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[58] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl:\n",
      "<br/>Scaling stylegan to large diverse datasets. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ACM SIGGRAPH\n",
      "<br/>2022 Conference Proceedings</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 1, 4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8669px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[59] Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and\n",
      "<br/>Timo Aila. Stylegan-t: Unlocking the power of gans for fast\n",
      "<br/>large-scale text-to-image synthesis. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proc. ICML</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2, 3,\n",
      "<br/>4, 5, 6, 14\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8714px; width:237px; height:86px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[60] Juergen Schmidhuber. Generative adversarial networks are\n",
      "<br/>special cases of artiﬁcial curiosity (1990) and also closely\n",
      "<br/>related to predictability minimization (1991), 2020. 4\n",
      "<br/>[61] Christoph Schuhmann, Romain Beaumont, Richard Vencu,\n",
      "<br/>Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes,\n",
      "<br/>Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al.\n",
      "<br/>LAION-5B: An open large-scale dataset for training next\n",
      "<br/>generation image-text models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">NeurIPS</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2022. 6\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8804px; width:237px; height:52px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[62] Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual,\n",
      "<br/>Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea\n",
      "<br/>Vedaldi, Devi Parikh, Justin Johnson, et al. Text-to-4d dy-\n",
      "<br/>namic scene generation. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint arXiv:2301.11280</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/>2023. 3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8860px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[63] Jascha Narain Sohl-Dickstein, Eric A. Weiss, Niru Ma-\n",
      "<br/>heswaranathan, and Surya Ganguli. Deep unsupervised\n",
      "<br/>learning using nonequilibrium thermodynamics. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">,\n",
      "<br/>abs/1503.03585, 2015. 1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8905px; width:236px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[64] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising\n",
      "<br/>diffusion implicit models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International Conference on\n",
      "<br/>Learning Representations</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2021. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8939px; width:237px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[65] Yang Song, Jascha Narain Sohl-Dickstein, Diederik P.\n",
      "<br/>Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.\n",
      "<br/>Score-based generative modeling through stochastic differen-\n",
      "<br/>tial equations. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2011.13456, 2020. 1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:8984px; width:237px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[66] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.\n",
      "<br/>Consistency models. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">International Conference on Machine\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Learning</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9018px; width:237px; height:63px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[67] George Stein, Jesse C Cresswell, Rasa Hosseinzadeh, Yi Sui,\n",
      "<br/>Brendan Leigh Ross, Valentin Villecroze, Zhaoyan Liu, An-\n",
      "<br/>thony L Caterini, J Eric T Taylor, and Gabriel Loaiza-Ganem.\n",
      "<br/>Exposing ﬂaws of generative model evaluation metrics and\n",
      "<br/>their unfair treatment of diffusion models. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">arXiv preprint\n",
      "<br/>arXiv:2306.04675</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, 2023. 6, 14\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9085px; width:237px; height:97px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[68] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A Yeh,\n",
      "<br/>and Greg Shakhnarovich. Score jacobian chaining: Lifting\n",
      "<br/>pretrained 2d diffusion models for 3d generation. In </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Proceed-\n",
      "<br/>ings of the IEEE/CVF Conference on Computer Vision and\n",
      "<br/>Pattern Recognition</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, pages 12619–12629, 2023. 2, 5\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">[69] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan\n",
      "<br/>Li, Hang Su, and Jun Zhu. Proliﬁcdreamer: High-ﬁdelity and\n",
      "<br/>diverse text-to-3d generation with variational score distilla-\n",
      "<br/>tion. </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">ArXiv</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">, abs/2305.16213, 2023. 2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:9203px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">11\n",
      "<br/></span></div>, <div style=\"position:absolute; top:9312px;\"><a name=\"12\">Page 12</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9384px; width:49px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">Appendix\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9408px; width:246px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">A. SDS As a Special Case of the Distillation Loss\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9429px; width:177px; height:25px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">If we set the weighting function to </span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMMI7; font-size:6px\">α</span><span style=\"font-family: CMMI5; font-size:4px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and choose </span><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">x, y</span><span style=\"font-family: CMR10; font-size:9px\">) = </span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMMI10; font-size:9px\">x </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">y</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:217px; top:9431px; width:327px; height:12px;\"><span style=\"font-family: CMR7; font-size:6px\">2</span><span style=\"font-family: CMMI7; font-size:6px\">σ</span><span style=\"font-family: CMMI5; font-size:4px\">t </span><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where </span><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">is the scaling factor from the weighted diffusion loss as in [51]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:172px; top:9445px; width:312px; height:11px;\"><span style=\"font-family: CMR7; font-size:6px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, the distillation loss in Eq. (4) is equivalent to the score distillation objective:\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:167px; top:9483px; width:9px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d\n",
      "<br/>dθ\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:178px; top:9488px; width:23px; height:13px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: CMR7; font-size:6px\">MSE\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">distill\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:260px; top:9564px; width:131px; height:10px;\"><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">) + ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:393px; top:9557px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:9565px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(5)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:243px; top:9512px; width:102px; height:16px;\"><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">sg</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">); </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)</span><span style=\"font-family: CMSY10; font-size:9px\">||</span><span style=\"font-family: CMR7; font-size:6px\">2\n",
      "<br/>2</span><span style=\"font-family: CMEX10; font-size:9px\">i\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9508px; width:125px; height:69px;\"><span style=\"font-family: CMMI10; font-size:9px\">d\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h</span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">dθ\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h</span><span style=\"font-family: CMR10; font-size:9px\">2</span><span style=\"font-family: CMMI10; font-size:9px\">c</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)[ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)]\n",
      "<br/>= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:227px; top:9564px; width:21px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)[\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:249px; top:9557px; width:9px; height:23px;\"><span style=\"font-family: CMR10; font-size:9px\">1\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:307px; top:9532px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:216px; top:9557px; width:18px; height:76px;\"><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">1\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9587px; width:33px; height:16px;\"><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9614px; width:33px; height:45px;\"><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: MSBM10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">t,ϵ</span><span style=\"font-family: CMSY5; font-size:4px\">′ </span><span style=\"font-family: CMEX10; font-size:9px\">h\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">d\n",
      "<br/>dθ\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:181px; top:9642px; width:7px; height:9px;\"><span style=\"font-family: CMR10; font-size:9px\">=\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:204px; top:9642px; width:19px; height:10px;\"><span style=\"font-family: CMSY10; font-size:9px\">L</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">SDS\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:226px; top:9590px; width:180px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">w</span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)[(</span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">α</span><span style=\"font-family: CMMI7; font-size:6px\">t </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">ψ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">)]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:408px; top:9583px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:235px; top:9614px; width:90px; height:12px;\"><span style=\"font-family: CMR10; font-size:9px\">[</span><span style=\"font-family: CMSY10; font-size:9px\">−</span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMSY7; font-size:6px\">′ </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">σ</span><span style=\"font-family: CMMI7; font-size:6px\">t</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">ϵ</span><span style=\"font-family: CMMI7; font-size:6px\">θ</span><span style=\"font-family: CMR10; font-size:9px\">(ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ,t</span><span style=\"font-family: CMR10; font-size:9px\">; </span><span style=\"font-family: CMMI10; font-size:9px\">t</span><span style=\"font-family: CMR10; font-size:9px\">)]\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:327px; top:9609px; width:21px; height:23px;\"><span style=\"font-family: CMMI10; font-size:9px\">d</span><span style=\"font-family: CMR10; font-size:9px\">ˆ</span><span style=\"font-family: CMMI10; font-size:9px\">x</span><span style=\"font-family: CMMI7; font-size:6px\">θ\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">dθ </span><span style=\"font-family: CMEX10; font-size:9px\">i\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:9716px; width:225px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">B. Details on Human Preference Assessment\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:9739px; width:495px; height:81px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For the evaluation results presented in Figures 5 to 7, we employ human evaluation and do not rely on commonly used\n",
      "<br/>metrics for quality assessment of generative models such as FID [18] and CLIP-score [52], since these have been shown to\n",
      "<br/>capture more ﬁne grained aspects like aesthetics and scene composition only insufﬁciently [30, 50]. However these categories\n",
      "<br/>in particular have become more and more important when comparing current state-of-the-art text-to-image models. We\n",
      "<br/>evaluate all models based on 100 selected prompts from the PartiPrompts benchmark [73] with the most relevant categories\n",
      "<br/>(excluding prompts from the category </span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">basic</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">). More details on how the study was conducted Appendix B.1 and the rankings\n",
      "<br/>computed Appendix B.2 are listed below.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:69px; top:9997px; width:455px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 9. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">single step</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-M (1-step) against established baselines.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:10045px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">12\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:9839px; width:242px; height:148px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:9839px; width:242px; height:148px;\"></div>, <div style=\"position:absolute; top:10154px;\"><a name=\"13\">Page 13</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:59px; top:10383px; width:476px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 10. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">User preference study (</span><span style=\"font-family: NimbusRomNo9L-MediItal; font-size:8px\">multiple steps</span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">). </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare the performance of ADD-XL (4-step) against established baselines.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:10416px; width:114px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">B.1. Experimental Setup\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10434px; width:496px; height:118px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Given all models for one particular study (e.g. ADD-XL, OpenMUSE</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">6</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, IF-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">7</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, SDXL [50] and LCM-XL</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">8 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">[38, 40] in\n",
      "<br/>Figure 7) we compare each prompt for each pair of models (1v1). For every comparison, we collect an average of four votes\n",
      "<br/>per task from different annotators, for both visual quality and prompt following. Human evaluators, recruited from the platform\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:9px\">Proliﬁc</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">9 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">with English as their ﬁrst language, are shown two images from different models based on the same text prompt. To\n",
      "<br/>prevent biases, evaluators are restricted from participating in more than one of our studies. For the prompt following task,\n",
      "<br/>we display the text prompt above the two images and ask, “Which image looks more representative of the text shown above\n",
      "<br/>and faithfully follows it?” For the visual quality assessment, we do not show the prompt and instead ask, “Which image is of\n",
      "<br/>higher quality and aesthetically more pleasing?”. Performing a complete assessment between all pair-wise comparisons gives\n",
      "<br/>us robust and reliable signals on model performance trends and the effect of varying thresholds. The order of prompts and the\n",
      "<br/>order between models are fully randomized. Frequent attention checks are in place to ensure data quality.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:10563px; width:129px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:10px\">B.2. ELO Score Calculation\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10582px; width:496px; height:69px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">To calculate rankings when comparing more than two models based on 1v1 comparisons we use ELO Scores (higher-is-\n",
      "<br/>better) [10] which were originally proposed as a scoring method for chess players but have more recently also been applied to\n",
      "<br/>compare instruction-tuned generative LLMs [1, 2]. For a set of competing players with initial ratings </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">init </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">participating in a\n",
      "<br/>series of zero-sum games the ELO rating system updates the ratings of the two players involved in a particular game based on\n",
      "<br/>the expected and and actual outcome of that game. Before the game with two players with ratings </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR7; font-size:6px\">1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMR7; font-size:6px\">2</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">, the expected\n",
      "<br/>outcome for the two players are calculated as\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:10669px; width:22px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">E</span><span style=\"font-family: CMR7; font-size:6px\">1 </span><span style=\"font-family: CMR10; font-size:9px\">=\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:254px; top:10697px; width:22px; height:10px;\"><span style=\"font-family: CMMI10; font-size:9px\">E</span><span style=\"font-family: CMR7; font-size:6px\">2 </span><span style=\"font-family: CMR10; font-size:9px\">=\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:305px; top:10663px; width:27px; height:22px;\"><span style=\"font-family: CMR10; font-size:9px\">1\n",
      "<br/></span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">2</span><span style=\"font-family: CMSY5; font-size:4px\">−</span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">1\n",
      "<br/>400\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:281px; top:10679px; width:51px; height:34px;\"><span style=\"font-family: CMR10; font-size:9px\">1 + 10\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:9px\">1\n",
      "<br/></span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">1</span><span style=\"font-family: CMSY5; font-size:4px\">−</span><span style=\"font-family: CMMI5; font-size:4px\">R</span><span style=\"font-family: CMR5; font-size:4px\">2\n",
      "<br/>400\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:281px; top:10706px; width:27px; height:9px;\"><span style=\"font-family: CMR10; font-size:9px\">1 + 10\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:10669px; width:2px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:10697px; width:2px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10725px; width:307px; height:10px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">After observing the result of the game, the ratings </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">are updated via the rule\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:225px; top:10745px; width:2px; height:4px;\"><span style=\"font-family: CMSY5; font-size:4px\">′\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:225px; top:10750px; width:100px; height:11px;\"><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">= </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">+ </span><span style=\"font-family: CMMI10; font-size:9px\">K </span><span style=\"font-family: CMSY10; font-size:9px\">· </span><span style=\"font-family: CMR10; font-size:9px\">(</span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMSY10; font-size:9px\">− </span><span style=\"font-family: CMMI10; font-size:9px\">E</span><span style=\"font-family: CMMI7; font-size:6px\">i</span><span style=\"font-family: CMR10; font-size:9px\">) </span><span style=\"font-family: CMMI10; font-size:9px\">,\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:217px; top:10750px; width:7px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">R\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:337px; top:10750px; width:39px; height:9px;\"><span style=\"font-family: CMMI10; font-size:9px\">i </span><span style=\"font-family: CMSY10; font-size:9px\">∈ {</span><span style=\"font-family: CMR10; font-size:9px\">1</span><span style=\"font-family: CMMI10; font-size:9px\">, </span><span style=\"font-family: CMR10; font-size:9px\">2</span><span style=\"font-family: CMSY10; font-size:9px\">}\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:10669px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(6)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:10697px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(7)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:534px; top:10749px; width:11px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">(8)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:10772px; width:495px; height:46px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">where </span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">indicates the outcome of the match for player </span><span style=\"font-family: CMMI10; font-size:9px\">i</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">. In our case we have </span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">= 1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">if player </span><span style=\"font-family: CMMI10; font-size:9px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">wins and </span><span style=\"font-family: CMMI10; font-size:9px\">S</span><span style=\"font-family: CMMI7; font-size:6px\">i </span><span style=\"font-family: CMR10; font-size:9px\">= 0 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">if player\n",
      "<br/></span><span style=\"font-family: CMMI10; font-size:9px\">i </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">looses. The constant </span><span style=\"font-family: CMMI10; font-size:9px\">K </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">can be see as weight putting emphasis on more recent games. We choose </span><span style=\"font-family: CMMI10; font-size:9px\">K </span><span style=\"font-family: CMR10; font-size:9px\">= 1 </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">and bootstrap\n",
      "<br/>the ﬁnal ELO ranking for a given series of comparisons based on 1000 individual ELO ranking calculations with randomly\n",
      "<br/>shufﬂed order. Before comparing the models we choose the start rating for every model as </span><span style=\"font-family: CMMI10; font-size:9px\">R</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">init </span><span style=\"font-family: CMR10; font-size:9px\">= 1000</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:10828px; width:180px; height:38px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">6</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/openMUSE\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">7</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://github.com/deep-ﬂoyd/IF\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">8</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://huggingface.co/latent-consistency/lcm-lora-sdxl\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">9</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">https://app.proliﬁc.com\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:10887px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">13\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:10225px; width:242px; height:147px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:300px; top:10225px; width:242px; height:147px;\"></div>, <div style=\"position:absolute; top:10996px;\"><a name=\"14\">Page 14</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11068px; width:157px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">C. GAN Baselines Comparison\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11089px; width:496px; height:33px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">For training our state-of-the-art GAN baseline StyleGAN-T++, we follow the training procedure outlined in [59]. The main\n",
      "<br/>differences are extended training (</span><span style=\"font-family: CMSY10; font-size:9px\">∼</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">2M iterations with a batch size of 2048, which is comparable to GigaGAN’s schedule [25]),\n",
      "<br/>the improved discriminator architecture proposed in Section 3.2, and R1 penalty applied at each discriminator head.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11124px; width:495px; height:45px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">Fig. 11 shows that StyleGAN-T++ outperforms the previous best GANs by achieving a comparable zero-shot FID to\n",
      "<br/>GigaGAN at a signiﬁcantly higher CLIP score. Here, we do not compare to DMs, as comparisons between model classes via\n",
      "<br/>automatic metrics tend to be less informative [67]. As an example, GigaGAN achieves FID and CLIP scores comparable to\n",
      "<br/>SD1.5, but its sample quality is still inferior, as noted by the authors.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:60px; top:11210px; width:12px; height:12px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">k\n",
      "<br/>5\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:11222px; width:17px; height:100px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:12px\">D\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">I\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">F\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">o\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">h\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">-\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">o\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">r\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:10px\">Z\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:82px; top:11186px; width:17px; height:162px;\"><span style=\"font-family: CMR10; font-size:17px\">26\n",
      "<br/>24\n",
      "<br/>22\n",
      "<br/>20\n",
      "<br/></span><span style=\"font-family: CMR10; font-size:17px\">18\n",
      "<br/>16\n",
      "<br/>14\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:142px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">29\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:199px; top:11342px; width:22px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">3\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:449px; top:11202px; width:54px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">GigaGAN\n",
      "<br/>StyleGAN-T\n",
      "<br/>StyleGAN-T++\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:403px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">34\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:456px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">35\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:508px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">36\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:247px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">31\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:235px; top:11342px; width:158px; height:40px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">32\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:17px\">CLIP score (ViT-g-14)\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:351px; top:11342px; width:30px; height:17px;\"><span style=\"font-family: CMR10; font-size:17px\">0</span><span style=\"font-family: CMMI10; font-size:17px\">.</span><span style=\"font-family: CMR10; font-size:17px\">33\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11394px; width:496px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 11. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Comparing text alignment tradeoffs at 256 </span><span style=\"font-family: CMSY9; font-size:8px\">× </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">256 pixels. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">We compare FID–CLIP score curves of StyleGAN-T, StyleGAN-T++,\n",
      "<br/>and GigaGAN. For increasing CLIP score, all methods use via decreasing truncation [26] for values </span><span style=\"font-family: CMMI9; font-size:8px\">ψ </span><span style=\"font-family: CMR9; font-size:8px\">= </span><span style=\"font-family: CMSY9; font-size:8px\">{</span><span style=\"font-family: CMR9; font-size:8px\">1</span><span style=\"font-family: CMMI9; font-size:8px\">.</span><span style=\"font-family: CMR9; font-size:8px\">0</span><span style=\"font-family: CMMI9; font-size:8px\">, </span><span style=\"font-family: CMR9; font-size:8px\">0</span><span style=\"font-family: CMMI9; font-size:8px\">.</span><span style=\"font-family: CMR9; font-size:8px\">9</span><span style=\"font-family: CMMI9; font-size:8px\">, . . . , </span><span style=\"font-family: CMR9; font-size:8px\">0</span><span style=\"font-family: CMMI9; font-size:8px\">.</span><span style=\"font-family: CMR9; font-size:8px\">3</span><span style=\"font-family: CMSY9; font-size:8px\">}</span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:11675px; width:495px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 12. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Additional single step </span><span style=\"font-family: CMR9; font-size:8px\">512</span><span style=\"font-family: CMR6; font-size:5px\">2 </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">images generated with ADD-XL. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">All samples are generated with a single U-Net evaluation trained\n",
      "<br/>with adversarial diffusion distillation (ADD).\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:11729px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">14\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:50px; top:11467px; width:495px; height:198px;\"></div>, <div style=\"position:absolute; top:11838px;\"><a name=\"15\">Page 15</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:11910px; width:114px; height:11px;\"><span style=\"font-family: NimbusRomNo9L-Medi; font-size:11px\">D. Additional Samples\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:49px; top:11931px; width:495px; height:57px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">We show additional one-step samples as in Figure 1 in Figure 12. An additional qualitative comparison as in Figure 4 which\n",
      "<br/>demonstrates that our model can further reﬁne quality by using more than one sampling step is provided in Figure 14, where\n",
      "<br/>we show that, while sampling quality with a single step is already high, more steps can give higher diversity and better spelling\n",
      "<br/>capabilities. Lastly, we provide an additional qualitative comparison of ADD-XL to other state-of-the-art one and few-step\n",
      "<br/>models in Figure 13.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:115px; top:12010px; width:171px; height:8px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">A cinematic shot of robot with colorful feathers.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:330px; top:11999px; width:215px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-ReguItal; font-size:8px\">Teddy bears working on new AI research on the moon in the\n",
      "<br/>1980s.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12050px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12038px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/>D\n",
      "<br/>A\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12041px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12105px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12093px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12097px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12161px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12149px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/>D\n",
      "<br/>A\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12151px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12217px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12205px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12206px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12272px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12260px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/>D\n",
      "<br/>D\n",
      "<br/>A\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12262px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12328px; width:8px; height:2px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">-\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12316px; width:8px; height:34px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">X\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">C\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">L\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12318px; width:8px; height:30px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12371px; width:8px; height:13px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">w\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">o\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">l\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12384px; width:8px; height:22px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">F\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">a\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">I\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:12422px; width:8px; height:44px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:5px\">E\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">S\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">U\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:7px\">M\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">n\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:6px\">O\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12375px; width:8px; height:27px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:67px; top:12427px; width:8px; height:35px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">)\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">6\n",
      "<br/>1\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">(\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:12481px; width:496px; height:20px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 13. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Additional qualitative comparisons to state of the art fast samplers. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Few step samples from our ADD-XL and LCM-XL [40],\n",
      "<br/>InstaFlow [36], and OpenMuse [48].\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:12571px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">15\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12025px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12025px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12081px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12081px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12136px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12136px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12192px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12192px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12248px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12248px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12303px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12303px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12359px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12359px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:89px; top:12415px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:326px; top:12415px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; top:12680px;\"><a name=\"16\">Page 16</a></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:76px; top:12958px; width:223px; height:19px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“a robot is playing the guitar at a rock concert in front of a large\n",
      "<br/>crowd.”\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:314px; top:12936px; width:222px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">“A portrait photo of a kangaroo wearing an orange hoodie and\n",
      "<br/>blue sunglasses standing on the grass in front of the Sydney\n",
      "<br/>Opera House holding a sign on the chest that says Welcome\n",
      "<br/>Friends!”\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:13003px; width:8px; height:21px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">1\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:13057px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">2\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:56px; top:13113px; width:8px; height:24px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">p\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">e\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:2px\">t\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:3px\">s\n",
      "<br/></span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:4px\">4\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:50px; top:13162px; width:495px; height:41px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Figure 14. </span><span style=\"font-family: NimbusRomNo9L-Medi; font-size:8px\">Additional results on the qualitative effect of sampling steps. </span><span style=\"font-family: NimbusRomNo9L-Regu; font-size:8px\">Similar to Figure 4, we show qualitative examples when\n",
      "<br/>sampling ADD-XL with 1, 2, and 4 steps. Single-step samples are often already of high quality, but increasing the number of steps can\n",
      "<br/>further improve the diversity (left) and spelling capabilities (right). The seeds are constant within columns and we see that the general layout\n",
      "<br/>is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\n",
      "<br/></span></div>, <div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:292px; top:13413px; width:9px; height:9px;\"><span style=\"font-family: NimbusRomNo9L-Regu; font-size:9px\">16\n",
      "<br/></span></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:77px; top:12984px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:314px; top:12984px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:77px; top:13040px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:314px; top:13040px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:77px; top:13095px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:314px; top:13095px; width:222px; height:55px;\"></div>, <div style=\"position:absolute; top:0px;\">Page: <a href=\"#1\">1</a>, <a href=\"#2\">2</a>, <a href=\"#3\">3</a>, <a href=\"#4\">4</a>, <a href=\"#5\">5</a>, <a href=\"#6\">6</a>, <a href=\"#7\">7</a>, <a href=\"#8\">8</a>, <a href=\"#9\">9</a>, <a href=\"#10\">10</a>, <a href=\"#11\">11</a>, <a href=\"#12\">12</a>, <a href=\"#13\">13</a>, <a href=\"#14\">14</a>, <a href=\"#15\">15</a>, <a href=\"#16\">16</a></div>]\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(data.page_content,'html.parser')\n",
    "content = soup.find_all('div')\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "-----------------------\n",
      "Adversarial Diffusion Distillation\n",
      "\n",
      "-----------------------\n",
      "Axel Sauer\n",
      "\n",
      "-----------------------\n",
      "Dominik Lorenz\n",
      "\n",
      "-----------------------\n",
      "Andreas Blattmann\n",
      "\n",
      "-----------------------\n",
      "Robin Rombach\n",
      "\n",
      "-----------------------\n",
      "Code: https://github.com/Stability-AI/generative-models Model weights: https://huggingface.co/stabilityai/\n",
      "\n",
      "-----------------------\n",
      "Stability AI\n",
      "\n",
      "-----------------------\n",
      "Figure 1. Generating high-ﬁdelity 5122 images in a single step. All samples are generated with a single U-Net evaluation trained with\n",
      "adversarial diffusion distillation (ADD).\n",
      "\n",
      "-----------------------\n",
      "Abstract\n",
      "\n",
      "-----------------------\n",
      "1. Introduction\n",
      "\n",
      "-----------------------\n",
      "We introduce Adversarial Diffusion Distillation (ADD), a\n",
      "novel training approach that efﬁciently samples large-scale\n",
      "foundational image diffusion models in just 1–4 steps while\n",
      "maintaining high image quality. We use score distillation\n",
      "to leverage large-scale off-the-shelf image diffusion models\n",
      "as a teacher signal in combination with an adversarial loss\n",
      "to ensure high image ﬁdelity even in the low-step regime\n",
      "of one or two sampling steps. Our analyses show that our\n",
      "model clearly outperforms existing few-step methods (GANs,\n",
      "Latent Consistency Models) in a single step and reaches the\n",
      "performance of state-of-the-art diffusion models (SDXL) in\n",
      "only four steps. ADD is the ﬁrst method to unlock single-step,\n",
      "real-time image synthesis with foundation models.\n",
      "\n",
      "-----------------------\n",
      "Diffusion models (DMs) [20, 63, 65] have taken a central\n",
      "role in the ﬁeld of generative modeling and have recently en-\n",
      "abled remarkable advances in high-quality image- [3, 53, 54]\n",
      "and video- [4, 12, 21] synthesis. One of the key strengths of\n",
      "DMs is their scalability and iterative nature, which allows\n",
      "them to handle complex tasks such as image synthesis from\n",
      "free-form text prompts. However, the iterative inference\n",
      "process in DMs requires a signiﬁcant number of sampling\n",
      "steps, which currently hinders their real-time application.\n",
      "Generative Adversarial Networks (GANs) [14, 26, 27], on\n",
      "the other hand, are characterized by their single-step for-\n",
      "mulation and inherent speed. But despite attempts to scale\n",
      "to large datasets[25, 58], GANs often fall short of DMs in\n",
      "terms of sample quality. The aim of this work is to combine\n",
      "the superior sample quality of DMs with the inherent speed\n",
      "of GANs.\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 2\n",
      "-----------------------\n",
      "Our approach is conceptually simple: We propose Ad-\n",
      "versarial Diffusion Distillation (ADD), a general approach\n",
      "that reduces the number of inference steps of a pre-trained\n",
      "diffusion model to 1–4 sampling steps while maintaining\n",
      "high sampling ﬁdelity and potentially further improving the\n",
      "overall performance of the model. To this end, we intro-\n",
      "duce a combination of two training objectives: (i) an ad-\n",
      "versarial loss and (ii) a distillation loss that corresponds\n",
      "to score distillation sampling (SDS) [51]. The adversar-\n",
      "ial loss forces the model to directly generate samples that\n",
      "lie on the manifold of real images at each forward pass,\n",
      "avoiding blurriness and other artifacts typically observed in\n",
      "other distillation methods [43]. The distillation loss uses\n",
      "another pretrained (and ﬁxed) DM as a teacher to effectively\n",
      "utilize the extensive knowledge of the pretrained DM and\n",
      "preserve the strong compositionality observed in large DMs.\n",
      "During inference, our approach does not use classiﬁer-free\n",
      "guidance [19], further reducing memory requirements. We\n",
      "retain the model’s ability to improve results through iterative\n",
      "reﬁnement, which is an advantage over previous one-step\n",
      "GAN-based approaches [59].\n",
      "\n",
      "-----------------------\n",
      "Our contributions can be summarized as follows:\n",
      "\n",
      "-----------------------\n",
      "• We introduce ADD, a method for turning pretrained diffu-\n",
      "sion models into high-ﬁdelity, real-time image generators\n",
      "using only 1–4 sampling steps.\n",
      "\n",
      "-----------------------\n",
      "• Our method uses a novel combination of adversarial train-\n",
      "ing and score distillation, for which we carefully ablate\n",
      "several design choices.\n",
      "\n",
      "-----------------------\n",
      "• ADD signiﬁcantly outperforms strong baselines such as\n",
      "LCM, LCM-XL [38] and single-step GANs [59], and is\n",
      "able to handle complex image compositions while main-\n",
      "taining high image realism at only a single inference step.\n",
      "• Using four sampling steps, ADD-XL outperforms its\n",
      "teacher model SDXL-Base at a resolution of 5122 px.\n",
      "\n",
      "-----------------------\n",
      "2. Background\n",
      "\n",
      "-----------------------\n",
      "While diffusion models achieve remarkable performance in\n",
      "synthesizing and editing high-resolution images [3, 53, 54]\n",
      "and videos [4, 21], their iterative nature hinders real-time ap-\n",
      "plication. Latent diffusion models [54] attempt to solve this\n",
      "problem by representing images in a more computationally\n",
      "feasible latent space [11], but they still rely on the iterative\n",
      "application of large models with billions of parameters. In\n",
      "addition to utilizing faster samplers for diffusion models\n",
      "[8, 37, 64, 74], there is a growing body of research on model\n",
      "distillation such as progressive distillation [56] and guidance\n",
      "distillation [43]. These approaches reduce the number of\n",
      "iterative sampling steps to 4-8, but may signiﬁcantly lower\n",
      "the original performance. Furthermore, they require an it-\n",
      "erative training process. Consistency models [66] address\n",
      "the latter issue by enforcing a consistency regularization on\n",
      "the ODE trajectory and demonstrate strong performance for\n",
      "pixel-based models in the few-shot setting. LCMs [38] focus\n",
      "\n",
      "-----------------------\n",
      "Figure 2. Adversarial Diffusion Distillation. The ADD-student\n",
      "is trained as a denoiser that receives diffused input images xs\n",
      "and outputs samples ˆxθ(xs, s) and optimizes two objectives: a)\n",
      "adversarial loss: the model aims to fool a discriminator which is\n",
      "trained to distinguish the generated samples ˆxθ from real images\n",
      "x0. b) distillation loss: the model is trained to match the denoised\n",
      "targets ˆxψ of a frozen DM teacher.\n",
      "\n",
      "-----------------------\n",
      "on distilling latent diffusion models and achieve impressive\n",
      "performance at 4 sampling steps. Recently, LCM-LoRA [40]\n",
      "introduced a low-rank adaptation [22] training for efﬁciently\n",
      "learning LCM modules, which can be plugged into differ-\n",
      "ent checkpoints for SD and SDXL [50, 54]. InstaFlow [36]\n",
      "propose to use Rectiﬁed Flows [35] to facilitate a better\n",
      "distillation process.\n",
      "\n",
      "-----------------------\n",
      "All of these methods share common ﬂaws: samples syn-\n",
      "thesized in four steps often look blurry and exhibit noticeable\n",
      "artifacts. At fewer sampling steps, this problem is further am-\n",
      "pliﬁed. GANs [14] can also be trained as standalone single-\n",
      "step models for text-to-image synthesis [25, 59]. Their sam-\n",
      "pling speed is impressive, yet the performance lags behind\n",
      "diffusion-based models. In part, this can be attributed to the\n",
      "ﬁnely balanced GAN-speciﬁc architectures necessary for sta-\n",
      "ble training of the adversarial objective. Scaling these mod-\n",
      "els and integrating advances in neural network architectures\n",
      "without disturbing the balance is notoriously challenging.\n",
      "Additionally, current state-of-the-art text-to-image GANs\n",
      "do not have a method like classiﬁer-free guidance available\n",
      "which is crucial for DMs at scale.\n",
      "\n",
      "-----------------------\n",
      "Score Distillation Sampling [51] also known as Score\n",
      "Jacobian Chaining [68] is a recently proposed method that\n",
      "has been developed to distill the knowledge of foundational\n",
      "T2I Models into 3D synthesis models. While the majority of\n",
      "SDS-based works [45, 51, 68, 69] use SDS in the context of\n",
      "\n",
      "-----------------------\n",
      "2\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 3\n",
      "-----------------------\n",
      "A cinematic shot of a professor sloth wearing a tuxedo at a\n",
      "BBQ party.\n",
      "\n",
      "-----------------------\n",
      "A high-quality photo of a confused bear in calculus class. The\n",
      "bear is wearing a party hat and steampunk armor.\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "D\n",
      "D\n",
      "A\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "M\n",
      "C\n",
      "L\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "M\n",
      "C\n",
      "L\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "2\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "M\n",
      "C\n",
      "L\n",
      "\n",
      "-----------------------\n",
      "+\n",
      "+\n",
      "T\n",
      "-\n",
      "N\n",
      "A\n",
      "G\n",
      "e\n",
      "l\n",
      "y\n",
      "t\n",
      "S\n",
      "\n",
      "-----------------------\n",
      "w\n",
      "o\n",
      "l\n",
      "F\n",
      "a\n",
      "t\n",
      "s\n",
      "n\n",
      "I\n",
      "\n",
      "-----------------------\n",
      "E\n",
      "S\n",
      "U\n",
      "M\n",
      "n\n",
      "e\n",
      "p\n",
      "O\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "(\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "6\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "Figure 3. Qualitative comparison to state-of-the-art fast samplers. Single step samples from our ADD-XL (top) and LCM-XL [40], our\n",
      "custom StyleGAN-T [59] baseline, InstaFlow [36] and MUSE. For MUSE, we use the OpenMUSE implementation and default inference\n",
      "settings with 16 sampling steps. For LCM-XL, we sample with 1, 2 and 4 steps. Our model outperforms all other few-step samplers in a\n",
      "single step.\n",
      "\n",
      "-----------------------\n",
      "per-scene optimization for 3D objects, the approach has also\n",
      "been applied to text-to-3D-video-synthesis [62] and in the\n",
      "context of image editing [16].\n",
      "\n",
      "-----------------------\n",
      "Recently, the authors of [13] have shown a strong relation-\n",
      "ship between score-based models and GANs and propose\n",
      "Score GANs, which are trained using score-based diffusion\n",
      "ﬂows from a DM instead of a discriminator. Similarly, Diff-\n",
      "Instruct [42], a method which generalizes SDS, enables to\n",
      "distill a pretrained diffusion model into a generator without\n",
      "discriminator.\n",
      "\n",
      "-----------------------\n",
      "faster sampling, Denoising Diffusion GANs [70] are intro-\n",
      "duced as a method to enable sampling with few steps. To\n",
      "improve quality, a discriminator loss is added to the score\n",
      "matching objective in Adversarial Score Matching [24] and\n",
      "the consistency objective of CTM [29].\n",
      "\n",
      "-----------------------\n",
      "Our method combines adversarial training and score dis-\n",
      "tillation in a hybrid objective to address the issues in current\n",
      "top performing few-step generative models.\n",
      "\n",
      "-----------------------\n",
      "3. Method\n",
      "\n",
      "-----------------------\n",
      "Conversely, there are also approaches which aim to im-\n",
      "prove the diffusion process using adversarial training. For\n",
      "\n",
      "-----------------------\n",
      "Our goal is to generate high-ﬁdelity samples in as few sam-\n",
      "pling steps as possible, while matching the quality of state-\n",
      "\n",
      "-----------------------\n",
      "3\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 4\n",
      "-----------------------\n",
      "“A brain riding a rocketship heading\n",
      "towards the moon.”\n",
      "\n",
      "-----------------------\n",
      "“A bald eagle made of chocolate powder,\n",
      "mango, and whipped cream”\n",
      "\n",
      "-----------------------\n",
      "“A blue colored dog.”\n",
      "\n",
      "-----------------------\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "2\n",
      "\n",
      "-----------------------\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "\n",
      "-----------------------\n",
      "Figure 4. Qualitative effect of sampling steps. We show qualitative examples when sampling ADD-XL with 1, 2, and 4 steps. Single-step\n",
      "samples are often already of high quality, but increasing the number of steps can further improve the consistency (e.g. second prompt, ﬁrst\n",
      "column) and attention to detail (e.g. second prompt, second column). The seeds are constant within columns and we see that the general\n",
      "layout is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\n",
      "\n",
      "-----------------------\n",
      "of-the-art models [7, 50, 53, 55]. The adversarial objec-\n",
      "tive [14, 60] naturally lends itself to fast generation as it\n",
      "trains a model that outputs samples on the image manifold in\n",
      "a single forward step. However, attempts at scaling GANs to\n",
      "large datasets [58, 59] observed that is critical to not solely\n",
      "rely on the discriminator, but also employ a pretrained clas-\n",
      "siﬁer or CLIP network for improving text alignment. As\n",
      "remarked in [59], overly utilizing discriminative networks\n",
      "introduces artifacts and image quality suffers. Instead, we\n",
      "utilize the gradient of a pretrained diffusion model via a score\n",
      "distillation objective to improve text alignment and sample\n",
      "quality. Furthermore, instead of training from scratch, we\n",
      "initialize our model with pretrained diffusion model weights;\n",
      "pretraining the generator network is known to signiﬁcantly\n",
      "improve training with an adversarial loss [15]. Lastly, in-\n",
      "stead of utilizing a decoder-only architecture used for GAN\n",
      "training [26, 27], we adapt a standard diffusion model frame-\n",
      "work. This setup naturally enables iterative reﬁnement.\n",
      "\n",
      "-----------------------\n",
      "3.1. Training Procedure\n",
      "\n",
      "-----------------------\n",
      "Our training procedure is outlined in Fig. 2 and involves three\n",
      "networks: The ADD-student is initialized from a pretrained\n",
      "UNet-DM with weights θ, a discriminator with trainable\n",
      "weights ϕ, and a DM teacher with frozen weights ψ. Dur-\n",
      "ing training, the ADD-student generates samples ˆxθ(xs, s)\n",
      "from noisy data xs. The noised data points are produced\n",
      "from a dataset of real images x0 via a forward diffusion\n",
      "process xs = αsx0 + σsϵ. In our experiments, we use the\n",
      "same coefﬁcients αs and σs as the student DM and sam-\n",
      "ple s uniformly from a set Tstudent = {τ1, ..., τn} of N\n",
      "chosen student timesteps. In practice, we choose N = 4.\n",
      "Importantly, we set τn = 1000 and enforce zero-terminal\n",
      "SNR [33] during training, as the model needs to start from\n",
      "\n",
      "-----------------------\n",
      "pure noise during inference.\n",
      "\n",
      "-----------------------\n",
      "For the adversarial objective, the generated samples ˆxθ\n",
      "and real images x0 are passed to the discriminator which\n",
      "aims to distinguish between them. The design of the dis-\n",
      "criminator and the adversarial loss are described in detail in\n",
      "Sec. 3.2. To distill knowledge from the DM teacher, we dif-\n",
      "fuse student samples ˆxθ with the teacher’s forward process to\n",
      "ˆxθ,t, and use the teacher’s denoising prediction ˆxψ(ˆxθ,t, t)\n",
      "as a reconstruction target for the distillation loss Ldistill,\n",
      "see Section 3.3. Thus, the overall objective is\n",
      "\n",
      "-----------------------\n",
      "L = LG\n",
      "\n",
      "-----------------------\n",
      "adv(ˆxθ(xs, s), ϕ) + λLdistill(ˆxθ(xs, s), ψ)\n",
      "\n",
      "-----------------------\n",
      "(1)\n",
      "\n",
      "-----------------------\n",
      "While we formulate our method in pixel space, it is\n",
      "straightforward to adapt it to LDMs operating in latent space.\n",
      "When using LDMs with a shared latent space for teacher\n",
      "and student, the distillation loss can be computed in pixel or\n",
      "latent space. We compute the distillation loss in pixel space\n",
      "as this yields more stable gradients when distilling latent\n",
      "diffusion model [72].\n",
      "\n",
      "-----------------------\n",
      "3.2. Adversarial Loss\n",
      "\n",
      "-----------------------\n",
      "For the discriminator, we follow the proposed design and\n",
      "training procedure in [59] which we brieﬂy summarize; for\n",
      "details, we refer the reader to the original work. We use a\n",
      "frozen pretrained feature network F and a set of trainable\n",
      "lightweight discriminator heads Dϕ,k. For the feature net-\n",
      "work F , Sauer et al. [59] ﬁnd vision transformers (ViTs) [9]\n",
      "to work well, and we ablate different choice for the ViTs\n",
      "objective and model size in Section 4. The trainable discrim-\n",
      "inator heads are applied on features Fk at different layers of\n",
      "the feature network.\n",
      "\n",
      "-----------------------\n",
      "To improve performance, the discriminator can be condi-\n",
      "tioned on additional information via projection [46]. Com-\n",
      "\n",
      "-----------------------\n",
      "4\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 5\n",
      "-----------------------\n",
      "Figure 5. User preference study (single step). We compare the performance of ADD-XL (1-step) against established baselines. ADD-XL\n",
      "model outperforms all models, except SDXL in human preference for both image quality and prompt alignment. Using more sampling steps\n",
      "further improves our model (bottom row).\n",
      "\n",
      "-----------------------\n",
      "monly, a text embedding ctext is used in the text-to-image\n",
      "setting. But, in contrast to standard GAN training, our train-\n",
      "ing conﬁguration also allows to condition on a given image.\n",
      "For τ < 1000, the ADD-student receives some signal from\n",
      "the input image x0. Therefore, for a given generated sample\n",
      "ˆxθ(xs, s), we can condition the discriminator on information\n",
      "from x0. This encourages the ADD-student to utilize the\n",
      "input effectively. In practice, we use an additional feature\n",
      "network to extract an image embedding cimg.\n",
      "\n",
      "-----------------------\n",
      "Following [57, 59], we use the hinge loss [32] as the\n",
      "adversarial objective function. Thus the ADD-student’s ad-\n",
      "versarial objective Ladv(ˆxθ(xs, s), ϕ) amounts to\n",
      "\n",
      "-----------------------\n",
      "LG\n",
      "\n",
      "-----------------------\n",
      "adv(ˆxθ(xs, s), ϕ)\n",
      "\n",
      "-----------------------\n",
      "= −Es,ϵ,x0 h X\n",
      "\n",
      "-----------------------\n",
      "k\n",
      "\n",
      "-----------------------\n",
      "Dϕ,k(Fk(ˆxθ(xs, s)))i ,\n",
      "\n",
      "-----------------------\n",
      "(2)\n",
      "\n",
      "-----------------------\n",
      "whereas the discriminator is trained to minimize\n",
      "\n",
      "-----------------------\n",
      "LD\n",
      "adv(ˆxθ(xs, s), ϕ)\n",
      "= Ex0 h X\n",
      "\n",
      "-----------------------\n",
      "k\n",
      "\n",
      "-----------------------\n",
      "max(0, 1 − Dϕ,k(Fk(x0))) + γR1(ϕ)i\n",
      "\n",
      "-----------------------\n",
      "+ Eˆxθ h X\n",
      "\n",
      "-----------------------\n",
      "k\n",
      "\n",
      "-----------------------\n",
      "max(0, 1 + Dϕ,k(Fk(ˆxθ)))i ,\n",
      "\n",
      "-----------------------\n",
      "where sg denotes the stop-gradient operation. Intuitively,\n",
      "the loss uses a distance metric d to measure the mis-\n",
      "match between generated samples xθ by the ADD-student\n",
      "and the DM-teacher’s outputs ˆxψ(ˆxθ,t, t) = (ˆxθ,t −\n",
      "σtˆϵψ(ˆxθ,t, t))/αt averaged over timesteps t and noise ϵ′.\n",
      "Notably, the teacher is not directly applied on generations\n",
      "ˆxθ of the ADD-student but instead on diffused outputs\n",
      "ˆxθ,t = αt ˆxθ + σtϵ′, as non-diffused inputs would be out-of-\n",
      "distribution for the teacher model [68].\n",
      "\n",
      "-----------------------\n",
      "In the following, we deﬁne the distance function\n",
      "d(x, y) := ||x − y||2\n",
      "2. Regarding the weighting function\n",
      "c(t), we consider two options: exponential weighting, where\n",
      "c(t) = αt (higher noise levels contribute less), and score dis-\n",
      "tillation sampling (SDS) weighting [51]. In the supplemen-\n",
      "tary material, we demonstrate that with d(x, y) = ||x − y||2\n",
      "2\n",
      "and a speciﬁc choice for c(t), our distillation loss becomes\n",
      "equivalent to the SDS objective LSDS, as proposed in [51].\n",
      "The advantage of our formulation is its ability to enable\n",
      "direct visualization of the reconstruction targets and that\n",
      "it naturally facilitates the execution of several consecutive\n",
      "denoising steps. Lastly, we also evaluate noise-free score\n",
      "distillation (NFSD) objective, a recently proposed variant of\n",
      "SDS [28].\n",
      "\n",
      "-----------------------\n",
      "(3)\n",
      "\n",
      "-----------------------\n",
      "4. Experiments\n",
      "\n",
      "-----------------------\n",
      "where R1 denotes the R1 gradient penalty [44]. Rather\n",
      "than computing the gradient penalty with respect to the pixel\n",
      "values, we compute it on the input of each discriminator head\n",
      "Dϕ,k. We ﬁnd that the R1 penalty is particularly beneﬁcial\n",
      "when training at output resolutions larger than 1282 px.\n",
      "\n",
      "-----------------------\n",
      "3.3. Score Distillation Loss\n",
      "\n",
      "-----------------------\n",
      "The distillation loss in Eq. (1) is formulated as\n",
      "\n",
      "-----------------------\n",
      "For our experiments, we train two models of different ca-\n",
      "pacities, ADD-M (860M parameters) and ADD-XL (3.1B\n",
      "parameters). For ablating ADD-M, we use a Stable Dif-\n",
      "fusion (SD) 2.1 backbone [54], and for fair comparisons\n",
      "with other baselines, we use SD1.5. ADD-XL utilizes a\n",
      "SDXL [50] backbone. All experiments are conducted at\n",
      "a standardized resolution of 512x512 pixels; outputs from\n",
      "models generating higher resolutions are down-sampled to\n",
      "this size.\n",
      "\n",
      "-----------------------\n",
      "Ldistill(ˆxθ(xs, s), ψ)\n",
      "= Et,ϵ′\n",
      "\n",
      "-----------------------\n",
      "(cid:2)\n",
      "\n",
      "-----------------------\n",
      "c(t)d(ˆxθ, ˆxψ(sg(ˆxθ,t); t))\n",
      "\n",
      "-----------------------\n",
      ",\n",
      "\n",
      "-----------------------\n",
      "(cid:3)\n",
      "\n",
      "-----------------------\n",
      "(4)\n",
      "\n",
      "-----------------------\n",
      "We employ a distillation weighting factor of λ = 2.5\n",
      "across all experiments. Additionally, the R1 penalty strength\n",
      "\n",
      "-----------------------\n",
      "5\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 6\n",
      "-----------------------\n",
      "Arch\n",
      "ViT-S\n",
      "ViT-S\n",
      "ViT-L\n",
      "ViT-L\n",
      "\n",
      "-----------------------\n",
      "Objective FID ↓\n",
      "21.5\n",
      "DINOv1\n",
      "20.6\n",
      "DINOv2\n",
      "24.0\n",
      "DINOv2\n",
      "23.3\n",
      "CLIP\n",
      "\n",
      "-----------------------\n",
      "CS ↑\n",
      "0.312\n",
      "0.319\n",
      "0.302\n",
      "0.308\n",
      "\n",
      "-----------------------\n",
      "ctext\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✓\n",
      "\n",
      "-----------------------\n",
      "cimg\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✓\n",
      "\n",
      "-----------------------\n",
      "FID ↓\n",
      "21.2\n",
      "21.2\n",
      "21.1\n",
      "20.6\n",
      "\n",
      "-----------------------\n",
      "CS ↑\n",
      "0.302\n",
      "0.307\n",
      "0.316\n",
      "0.319\n",
      "\n",
      "-----------------------\n",
      "Initialization\n",
      "Random\n",
      "Pretrained\n",
      "\n",
      "-----------------------\n",
      "FID ↓ CS ↑\n",
      "293.6 0.065\n",
      "0.319\n",
      "\n",
      "-----------------------\n",
      "20.6\n",
      "\n",
      "-----------------------\n",
      "(a) Discriminator feature networks. Small,\n",
      "modern DINO networks perform best.\n",
      "\n",
      "-----------------------\n",
      "(b) Discriminator conditioning. Combining\n",
      "image and text conditioning is most effective.\n",
      "\n",
      "-----------------------\n",
      "(c) Student pretraining. A randomly initial-\n",
      "ized student network collapses.\n",
      "\n",
      "-----------------------\n",
      "Loss\n",
      "Ladv\n",
      "Ldistill\n",
      "Ladv + λLdistill,exp\n",
      "Ladv + λLdistill,sds\n",
      "Ladv +λLdistill,nfsd\n",
      "\n",
      "-----------------------\n",
      "FID ↓\n",
      "20.8\n",
      "315.6\n",
      "20.6\n",
      "22.3\n",
      "21.8\n",
      "\n",
      "-----------------------\n",
      "CS ↑\n",
      "0.315\n",
      "0.076\n",
      "0.319\n",
      "0.325\n",
      "0.327\n",
      "\n",
      "-----------------------\n",
      "Student\n",
      "SD2.1\n",
      "SD2.1\n",
      "SDXL\n",
      "SDXL\n",
      "\n",
      "-----------------------\n",
      "Teacher\n",
      "SD2.1\n",
      "SDXL\n",
      "SD2.1\n",
      "SDXL\n",
      "\n",
      "-----------------------\n",
      "FID ↓\n",
      "20.6\n",
      "21.3\n",
      "29.3\n",
      "28.41\n",
      "\n",
      "-----------------------\n",
      "CS ↑\n",
      "0.319\n",
      "0.321\n",
      "0.314\n",
      "0.325\n",
      "\n",
      "-----------------------\n",
      "Steps\n",
      "1\n",
      "2\n",
      "4\n",
      "\n",
      "-----------------------\n",
      "FID ↓\n",
      "20.6\n",
      "20.8\n",
      "20.3\n",
      "\n",
      "-----------------------\n",
      "CS ↑\n",
      "0.319\n",
      "0.321\n",
      "0.317\n",
      "\n",
      "-----------------------\n",
      "(d) Loss terms. Both losses are needed and\n",
      "exponential weighting of Ldistill is beneﬁcial.\n",
      "\n",
      "-----------------------\n",
      "(e) Teacher type. The student adopts the\n",
      "teacher’s traits (SDXL has higher FID & CS).\n",
      "\n",
      "-----------------------\n",
      "(f) Teacher steps. A single teacher step is sufﬁ-\n",
      "cient.\n",
      "\n",
      "-----------------------\n",
      "Table 1. ADD ablation study. We report COCO zero-shot FID5k (FID) and CLIP score (CS). The results are calculated for a single student\n",
      "step. The default training settings are: DINOv2 ViT-S as the feature network, text and image conditioning for the discriminator, pretrained\n",
      "student weights, a small teacher and student model, and a single teacher step. The training length is 4000 iterations with a batch size of 128.\n",
      "Default settings are marked in gray .\n",
      "\n",
      "-----------------------\n",
      "γ is set to 10−5. For discriminator conditioning, we use\n",
      "a pretrained CLIP-ViT-g-14 text encoder [52] to compute\n",
      "text embeddings ctext and the CLS embedding of a DINOv2\n",
      "ViT-L encoder [47] for image embeddings cimg. For the\n",
      "baselines, we use the best publicly available models: La-\n",
      "tent diffusion models [50, 54] (SD1.51, SDXL2) cascaded\n",
      "pixel diffusion models [55] (IF-XL3), distilled diffusion mod-\n",
      "els [39, 41] (LCM-1.5, LCM-1.5-XL4), and OpenMUSE\n",
      "5 [48], a reimplementation of MUSE [6], a transformer\n",
      "model speciﬁcally developed for fast inference. Note that\n",
      "we compare to the SDXL-Base-1.0 model without its addi-\n",
      "tional reﬁner model; this is to ensure a fair comparison. As\n",
      "there are no public state-of-the-art GAN models, we retrain\n",
      "StyleGAN-T [59] with our improved discriminator. This\n",
      "baseline (StyleGAN-T++) signiﬁcantly outperforms the pre-\n",
      "vious best GANs in FID and CS, see supplementary. We\n",
      "quantify sample quality via FID [18] and text alignment via\n",
      "CLIP score [17]. For CLIP score, we use ViT-g-14 model\n",
      "trained on LAION-2B [61]. Both metrics are evaluated on\n",
      "5k samples from COCO2017 [34].\n",
      "\n",
      "-----------------------\n",
      "4.1. Ablation Study\n",
      "\n",
      "-----------------------\n",
      "Our training setup opens up a number of design spaces re-\n",
      "garding the adversarial loss, distillation loss, initialization,\n",
      "and loss interplay. We conduct an ablation study on several\n",
      "choices in Table 1; key insights are highlighted below each\n",
      "table. We will discuss each experiment in the following.\n",
      "\n",
      "-----------------------\n",
      "Discriminator feature networks.\n",
      "(Table 1a). Recent\n",
      "insights by Stein et al. [67] suggest that ViTs trained with the\n",
      "CLIP [52] or DINO [5, 47] objectives are particularly well-\n",
      "\n",
      "-----------------------\n",
      "1https://github.com/CompVis/stable-diffusion\n",
      "2https://github.com/Stability-AI/generative-models\n",
      "3https://github.com/deep-ﬂoyd/IF\n",
      "4https://huggingface.co/latent-consistency/lcm-lora-sdxl\n",
      "5https://huggingface.co/openMUSE\n",
      "\n",
      "-----------------------\n",
      "6\n",
      "\n",
      "-----------------------\n",
      "suited for evaluating the performance of generative models.\n",
      "Similarly, these models also seem effective as discriminator\n",
      "feature networks, with DINOv2 emerging as the best choice.\n",
      "\n",
      "-----------------------\n",
      "Discriminator conditioning. (Table 1b). Similar to prior\n",
      "studies, we observe that text conditioning of the discrimi-\n",
      "nator enhances results. Notably, image conditioning outper-\n",
      "forms text conditioning, and the combination of both ctext\n",
      "and cimg yields the best results.\n",
      "\n",
      "-----------------------\n",
      "Student pretraining. (Table 1c). Our experiments demon-\n",
      "strate the importance of pretraining the ADD-student. Being\n",
      "able to use pretrained generators is a signiﬁcant advantage\n",
      "over pure GAN approaches. A problem of GANs is the lack\n",
      "of scalability; both Sauer et al. [59] and Kang et al. [25]\n",
      "observe a saturation of performance after a certain network\n",
      "capacity is reached. This observation contrasts the generally\n",
      "smooth scaling laws of DMs [49]. However, ADD can ef-\n",
      "fectively leverage larger pretrained DMs (see Table 1c) and\n",
      "beneﬁt from stable DM pretraining.\n",
      "\n",
      "-----------------------\n",
      "Loss terms. (Table 1d). We ﬁnd that both losses are essen-\n",
      "tial. The distillation loss on its own is not effective, but when\n",
      "combined with the adversarial loss, there is a noticeable im-\n",
      "provement in results. Different weighting schedules lead\n",
      "to different behaviours, the exponential schedule tends to\n",
      "yield more diverse samples, as indicated by lower FID, SDS\n",
      "and NFSD schedules improve quality and text alignment.\n",
      "While we use the exponential schedule as the default setting\n",
      "in all other ablations, we opt for the NFSD weighting for\n",
      "training our ﬁnal model. Choosing an optimal weighting\n",
      "function presents an opportunity for improvement. Alterna-\n",
      "tively, scheduling the distillation weights over training, as\n",
      "explored in the 3D generative modeling literature [23] could\n",
      "be considered.\n",
      "\n",
      "-----------------------\n",
      "Page 7\n",
      "-----------------------\n",
      "Figure 6. User preference study (multiple steps). We compare the performance of ADD-XL (4-step) against established baselines. Our\n",
      "ADD-XL model outperforms all models, including its teacher SDXL 1.0 (base, no reﬁner) [50], in human preference for both image quality\n",
      "and prompt alignment.\n",
      "\n",
      "-----------------------\n",
      "Method\n",
      "\n",
      "-----------------------\n",
      "#Steps\n",
      "\n",
      "-----------------------\n",
      "Time (s)\n",
      "\n",
      "-----------------------\n",
      "FID ↓\n",
      "\n",
      "-----------------------\n",
      "CLIP ↑\n",
      "\n",
      "-----------------------\n",
      "DPM Solver [37]\n",
      "\n",
      "-----------------------\n",
      "Progressive Distillation [43]\n",
      "\n",
      "-----------------------\n",
      "CFG-Aware Distillation [31]\n",
      "\n",
      "-----------------------\n",
      "InstaFlow-0.9B [36]\n",
      "InstaFlow-1.7B [36]\n",
      "\n",
      "-----------------------\n",
      "UFOGen [71]\n",
      "\n",
      "-----------------------\n",
      "ADD-M\n",
      "\n",
      "-----------------------\n",
      "25\n",
      "8\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "2\n",
      "4\n",
      "\n",
      "-----------------------\n",
      "8\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "0.88\n",
      "0.34\n",
      "\n",
      "-----------------------\n",
      "0.09\n",
      "0.13\n",
      "0.21\n",
      "\n",
      "-----------------------\n",
      "0.34\n",
      "\n",
      "-----------------------\n",
      "0.09\n",
      "0.12\n",
      "\n",
      "-----------------------\n",
      "0.09\n",
      "\n",
      "-----------------------\n",
      "0.09\n",
      "\n",
      "-----------------------\n",
      "20.1\n",
      "31.7\n",
      "\n",
      "-----------------------\n",
      "37.2\n",
      "26.0\n",
      "26.4\n",
      "\n",
      "-----------------------\n",
      "24.2\n",
      "\n",
      "-----------------------\n",
      "23.4\n",
      "22.4\n",
      "\n",
      "-----------------------\n",
      "22.5\n",
      "\n",
      "-----------------------\n",
      "19.7\n",
      "\n",
      "-----------------------\n",
      "0.318\n",
      "0.320\n",
      "\n",
      "-----------------------\n",
      "0.275\n",
      "0.297\n",
      "0.300\n",
      "\n",
      "-----------------------\n",
      "0.300\n",
      "\n",
      "-----------------------\n",
      "0.304\n",
      "0.309\n",
      "\n",
      "-----------------------\n",
      "0.311\n",
      "\n",
      "-----------------------\n",
      "0.326\n",
      "\n",
      "-----------------------\n",
      "↓\n",
      "]\n",
      "s\n",
      "[\n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      "s\n",
      "\n",
      "-----------------------\n",
      "e\n",
      "c\n",
      "n\n",
      "e\n",
      "r\n",
      "e\n",
      "f\n",
      "n\n",
      "I\n",
      "\n",
      "-----------------------\n",
      "12\n",
      "10\n",
      "\n",
      "-----------------------\n",
      "5\n",
      "\n",
      "-----------------------\n",
      "3\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "0\n",
      "\n",
      "-----------------------\n",
      "Table 2. Distillation Comparison We compare ADD to other\n",
      "distillation methods via COCO zero-shot FID5k (FID) and CLIP\n",
      "score (CS). All models are based on SD1.5.\n",
      "\n",
      "-----------------------\n",
      "Teacher type.\n",
      "(Table 1e). Interestingly, a bigger student\n",
      "and teacher does not necessarily result in better FID and\n",
      "CS. Rather, the student adopts the teachers characteristics.\n",
      "SDXL obtains generally higher FID, possibly because of its\n",
      "less diverse output, yet it exhibits higher image quality and\n",
      "text alignment [50].\n",
      "\n",
      "-----------------------\n",
      "Teacher steps.\n",
      "(Table 1f). While our distillation loss\n",
      "formulation allows taking several consecutive steps with the\n",
      "teacher by construction, we ﬁnd that several steps do not\n",
      "conclusively result in better performance.\n",
      "\n",
      "-----------------------\n",
      "4.2. Quantitative Comparison to State of the Art\n",
      "\n",
      "-----------------------\n",
      "For our main comparison with other approaches, we refrain\n",
      "from using automated metrics, as user preference studies\n",
      "are more reliable [50]. In the study, we aim to assess both\n",
      "prompt adherence and the overall image. As a performance\n",
      "measure, we compute win percentages for pairwise compar-\n",
      "isons and ELO scores when comparing several approaches.\n",
      "For the reported ELO scores we calculate the mean scores\n",
      "\n",
      "-----------------------\n",
      "7\n",
      "\n",
      "-----------------------\n",
      "IF-XL\n",
      "(150 steps)\n",
      "\n",
      "-----------------------\n",
      "SDXL\n",
      "(50 steps)\n",
      "\n",
      "-----------------------\n",
      "OpenMUSE\n",
      "(16 steps)\n",
      "\n",
      "-----------------------\n",
      "900\n",
      "\n",
      "-----------------------\n",
      "950\n",
      "\n",
      "-----------------------\n",
      "LCM-XL\n",
      "(4 steps)\n",
      "\n",
      "-----------------------\n",
      "ADD-XL\n",
      "(1 step)\n",
      "1,050\n",
      "\n",
      "-----------------------\n",
      "1,000\n",
      "\n",
      "-----------------------\n",
      "ELO ↑\n",
      "\n",
      "-----------------------\n",
      "ADD-XL\n",
      "(4 steps)\n",
      "\n",
      "-----------------------\n",
      "1,100\n",
      "\n",
      "-----------------------\n",
      "1,150\n",
      "\n",
      "-----------------------\n",
      "1,200\n",
      "\n",
      "-----------------------\n",
      "Figure 7. Performance vs. speed. We visualize the results reported\n",
      "in Fig. 6 in combination with the inference speeds of the respective\n",
      "models. The speeds are calculated for generating a single sample\n",
      "at resolution 512x512 on an A100 in mixed precision.\n",
      "\n",
      "-----------------------\n",
      "between both prompt following and image quality. Details\n",
      "on the ELO score computation and the study parameters are\n",
      "listed in the supplementary material.\n",
      "\n",
      "-----------------------\n",
      "Fig. 5 and Fig. 6 present the study results. The most im-\n",
      "portant results are: First, ADD-XL outperforms LCM-XL (4\n",
      "steps) with a single step. Second, ADD-XL can beat SDXL\n",
      "(50 steps) with four steps in the majority of comparisons.\n",
      "This makes ADD-XL the state-of-the-art in both the single\n",
      "and the multiple steps setting. Fig. 7 visualizes ELO scores\n",
      "relative to inference speed. Lastly, Table 2 compares dif-\n",
      "ferent few-step sampling and distillation methods using the\n",
      "same base model. ADD outperforms all other approaches\n",
      "including the standard DPM solver with eight steps.\n",
      "\n",
      "-----------------------\n",
      "4.3. Qualitative Results\n",
      "\n",
      "-----------------------\n",
      "To complement our quantitative studies above, we present\n",
      "qualitative results in this section. To paint a more complete\n",
      "picture, we provide additional samples and qualitative com-\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 8\n",
      "-----------------------\n",
      "A cinematic shot of a little pig priest wearing sunglasses.\n",
      "\n",
      "-----------------------\n",
      "A photograph of the inside of a subway train. There are frogs\n",
      "sitting on the seats. One of them is reading a newspaper. The\n",
      "window shows the river in the background.\n",
      "\n",
      "-----------------------\n",
      "A photo of an astronaut riding a horse in the forest. There is a\n",
      "river in front of them with water lilies.\n",
      "\n",
      "-----------------------\n",
      "A photo of a cute mouse wearing a crown.\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "D\n",
      "D\n",
      "A\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "e\n",
      "s\n",
      "a\n",
      "B\n",
      "-\n",
      "L\n",
      "X\n",
      "D\n",
      "S\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "0\n",
      "5\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "D\n",
      "D\n",
      "A\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "e\n",
      "s\n",
      "a\n",
      "B\n",
      "-\n",
      "L\n",
      "X\n",
      "D\n",
      "S\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "0\n",
      "5\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "Figure 8. Qualitative comparison to the teacher model. ADD-XL can outperform its teacher model SDXL in the multi-step setting. The\n",
      "adversarial loss boosts realism, particularly enhancing textures (fur, fabric, skin) while reducing oversmoothing, commonly observed in\n",
      "diffusion model samples. ADD-XL’s overall sample diversity tends to be lower.\n",
      "\n",
      "-----------------------\n",
      "parisons in the supplementary material. Fig. 3 compares\n",
      "ADD-XL (1 step) against the best current baselines in the\n",
      "few-steps regime. Fig. 4 illustrates the iterative sampling\n",
      "process of ADD-XL. These results showcase our model’s\n",
      "ability to improve upon an initial sample. Such iterative\n",
      "improvement represents another signiﬁcant beneﬁt over pure\n",
      "GAN approaches like StyleGAN-T++. Lastly, Fig. 8 com-\n",
      "pares ADD-XL directly with its teacher model SDXL-Base.\n",
      "As indicated by the user studies in Section 4.2, ADD-XL\n",
      "outperforms its teacher in both quality and prompt alignment.\n",
      "The enhanced realism comes at the cost of slightly decreased\n",
      "sample diversity.\n",
      "\n",
      "-----------------------\n",
      "5. Discussion\n",
      "\n",
      "-----------------------\n",
      "This work introduces Adversarial Diffusion Distillation, a\n",
      "general method for distilling a pretrained diffusion model\n",
      "into a fast, few-step image generation model. We combine\n",
      "an adversarial and a score distillation objective to distill the\n",
      "public Stable Diffusion [54] and SDXL [50] models, lever-\n",
      "aging both real data through the discriminator and structural\n",
      "understanding through the diffusion teacher. Our approach\n",
      "performs particularly well in the ultra-fast sampling regime\n",
      "of one or two steps, and our analyses demonstrate that it out-\n",
      "performs all concurrent methods in this regime. Furthermore,\n",
      "\n",
      "-----------------------\n",
      "8\n",
      "\n",
      "-----------------------\n",
      "we retain the ability to reﬁne samples using multiple steps.\n",
      "In fact, using four sampling steps, our model outperforms\n",
      "widely used multi-step generators such as SDXL, IF, and\n",
      "OpenMUSE.\n",
      "\n",
      "-----------------------\n",
      "Our model enables the generation of high quality images\n",
      "in a single-step, opening up new possibilities for real-time\n",
      "generation with foundation models.\n",
      "\n",
      "-----------------------\n",
      "Acknowledgements\n",
      "\n",
      "-----------------------\n",
      "We would like to thank Jonas M¨uller for feedback on the\n",
      "draft, the proof, and typesetting; Patrick Esser for feedback\n",
      "on the proof and building an early model demo; Frederic\n",
      "Boesel for generating data and helpful discussions; Minguk\n",
      "Kang and Taesung Park for providing GigaGAN samples;\n",
      "Richard Vencu, Harry Saini, and Sami Kama for maintaining\n",
      "the compute infrastructure; Yara Wald for creative sampling\n",
      "support; and Vanessa Sauer for her general support.\n",
      "\n",
      "-----------------------\n",
      "References\n",
      "\n",
      "-----------------------\n",
      "[1] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep\n",
      "Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben\n",
      "Mann, Nova DasSarma, Nelson Elhage, Zac Hatﬁeld-Dodds,\n",
      "Danny Hernandez, Jackson Kernion, Kamal Ndousse, Cather-\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 9\n",
      "-----------------------\n",
      "ine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam\n",
      "McCandlish, Chris Olah, and Jared Kaplan. A general lan-\n",
      "guage assistant as a laboratory for alignment, 2021. 13\n",
      "[2] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell,\n",
      "Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort,\n",
      "Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\n",
      "davath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nel-\n",
      "son Elhage, Zac Hatﬁeld-Dodds, Danny Hernandez, Tristan\n",
      "Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel\n",
      "Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack\n",
      "Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared\n",
      "Kaplan. Training a helpful and harmless assistant with rein-\n",
      "forcement learning from human feedback, 2022. 13\n",
      "\n",
      "-----------------------\n",
      "[3] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat,\n",
      "Jiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala,\n",
      "Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, and\n",
      "Ming-Yu Liu. ediff-i: Text-to-image diffusion models with an\n",
      "ensemble of expert denoisers. ArXiv, abs/2211.01324, 2022.\n",
      "1, 2\n",
      "\n",
      "-----------------------\n",
      "[4] A. Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn,\n",
      "Seung Wook Kim, Sanja Fidler, and Karsten Kreis. Align your\n",
      "latents: High-resolution video synthesis with latent diffusion\n",
      "models. 2023 IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition (CVPR), pages 22563–22575, 2023.\n",
      "1, 2\n",
      "\n",
      "-----------------------\n",
      "[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou,\n",
      "Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-\n",
      "ing properties in self-supervised vision transformers. In Pro-\n",
      "ceedings of the IEEE/CVF international conference on com-\n",
      "puter vision, pages 9650–9660, 2021. 6\n",
      "\n",
      "-----------------------\n",
      "[6] Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot,\n",
      "Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy,\n",
      "William T Freeman, Michael Rubinstein, et al. Muse: Text-to-\n",
      "image generation via masked generative transformers. Proc.\n",
      "ICML, 2023. 6\n",
      "\n",
      "-----------------------\n",
      "[7] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang\n",
      "Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiao-\n",
      "fang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image\n",
      "generation models using photogenic needles in a haystack.\n",
      "arXiv preprint arXiv:2309.15807, 2023. 4\n",
      "\n",
      "-----------------------\n",
      "[8] Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Genie:\n",
      "Higher-order denoising diffusion solvers. Advances in Neural\n",
      "Information Processing Systems, 35:30150–30166, 2022. 2\n",
      "\n",
      "-----------------------\n",
      "[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\n",
      "Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\n",
      "Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\n",
      "vain Gelly, et al. An image is worth 16x16 words: Trans-\n",
      "arXiv preprint\n",
      "formers for image recognition at scale.\n",
      "arXiv:2010.11929, 2020. 4\n",
      "\n",
      "-----------------------\n",
      "[10] Arpad E. Elo. The Rating of Chessplayers, Past and Present.\n",
      "\n",
      "-----------------------\n",
      "Arco Pub., New York, 1978. 13\n",
      "\n",
      "-----------------------\n",
      "[11] Patrick Esser, Robin Rombach, and Bj¨orn Ommer. Tam-\n",
      "ing transformers for high-resolution image synthesis. 2021\n",
      "IEEE/CVF Conference on Computer Vision and Pattern\n",
      "Recognition (CVPR), pages 12868–12878, 2020. 2\n",
      "\n",
      "-----------------------\n",
      "[12] Patrick Esser, Johnathan Chiu, Parmida Atighehchian,\n",
      "Jonathan Granskog, and Anastasis Germanidis. Structure\n",
      "\n",
      "-----------------------\n",
      "and content-guided video synthesis with diffusion models,\n",
      "2023. 1\n",
      "\n",
      "-----------------------\n",
      "[13] Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos,\n",
      "Thibaut Issenhuth, Emmanuel de B´ezenac, Micka¨el Chen,\n",
      "and Alain Rakotomamonjy. Unifying gans and score-based\n",
      "arXiv preprint\n",
      "diffusion as generative particle models.\n",
      "arXiv:2305.16150, 2023. 3\n",
      "\n",
      "-----------------------\n",
      "[14] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing\n",
      "Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville,\n",
      "and Yoshua Bengio. Generative adversarial networks. Com-\n",
      "munications of the ACM, 63:139 – 144, 2014. 1, 2, 4\n",
      "[15] Timofey Grigoryev, Andrey Voynov, and Artem Babenko.\n",
      "When, why, and which pretrained gans are useful? ICLR,\n",
      "2022. 4\n",
      "\n",
      "-----------------------\n",
      "[16] Amir Hertz, Kﬁr Aberman, and Daniel Cohen-Or. Delta de-\n",
      "noising score. In Proceedings of the IEEE/CVF International\n",
      "Conference on Computer Vision, pages 2328–2337, 2023. 3\n",
      "[17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,\n",
      "and Yejin Choi. CLIPScore: A reference-free evaluation\n",
      "metric for image captioning. In Proc. EMNLP, 2021. 6\n",
      "[18] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bern-\n",
      "hard Nessler, and Sepp Hochreiter. GANs trained by a two\n",
      "time-scale update rule converge to a local Nash equilibrium.\n",
      "NeurIPS, 2017. 6, 12\n",
      "\n",
      "-----------------------\n",
      "[19] Jonathan Ho. Classiﬁer-free diffusion guidance. ArXiv,\n",
      "\n",
      "-----------------------\n",
      "abs/2207.12598, 2022. 2\n",
      "\n",
      "-----------------------\n",
      "[20] Jonathan Ho, Ajay Jain, and P. Abbeel. Denoising diffusion\n",
      "probabilistic models. ArXiv, abs/2006.11239, 2020. 1\n",
      "[21] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang,\n",
      "Ruiqi Gao, Alexey A. Gritsenko, Diederik P. Kingma, Ben\n",
      "Poole, Mohammad Norouzi, David J. Fleet, and Tim Salimans.\n",
      "Imagen video: High deﬁnition video generation with diffusion\n",
      "models. ArXiv, abs/2210.02303, 2022. 1, 2\n",
      "\n",
      "-----------------------\n",
      "[22] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\n",
      "Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank\n",
      "adaptation of large language models. ArXiv, abs/2106.09685,\n",
      "2021. 2\n",
      "\n",
      "-----------------------\n",
      "[23] Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-\n",
      "Jun Zha, and Lei Zhang. Dreamtime: An improved optimiza-\n",
      "tion strategy for text-to-3d content creation. arXiv preprint\n",
      "arXiv:2306.12422, 2023. 6\n",
      "\n",
      "-----------------------\n",
      "[24] Alexia Jolicoeur-Martineau, R´emi Pich´e-Taillefer, R´emi Ta-\n",
      "chet des Combes, and Ioannis Mitliagkas. Adversarial score\n",
      "matching and improved sampling for image generation. arXiv\n",
      "preprint arXiv:2009.05475, 2020. 3\n",
      "\n",
      "-----------------------\n",
      "[25] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli\n",
      "Shechtman, Sylvain Paris, and Taesung Park. Scaling up gans\n",
      "for text-to-image synthesis. In Proceedings of the IEEE/CVF\n",
      "Conference on Computer Vision and Pattern Recognition,\n",
      "pages 10124–10134, 2023. 1, 2, 6, 14\n",
      "\n",
      "-----------------------\n",
      "[26] Tero Karras, Samuli Laine, and Timo Aila. A style-based\n",
      "generator architecture for generative adversarial networks.\n",
      "2019 IEEE/CVF Conference on Computer Vision and Pattern\n",
      "Recognition (CVPR), pages 4396–4405, 2018. 1, 4, 14\n",
      "[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,\n",
      "Jaakko Lehtinen, and Timo Aila. Analyzing and improving\n",
      "the image quality of stylegan. 2020 IEEE/CVF Conference\n",
      "\n",
      "-----------------------\n",
      "9\n",
      "\n",
      "-----------------------\n",
      "Page 10\n",
      "-----------------------\n",
      "on Computer Vision and Pattern Recognition (CVPR), pages\n",
      "8107–8116, 2019. 1, 4\n",
      "\n",
      "-----------------------\n",
      "proach for transferring knowledge from pre-trained diffusion\n",
      "models. arXiv preprint arXiv:2305.18455, 2023. 3\n",
      "\n",
      "-----------------------\n",
      "[28] Oren Katzir, Or Patashnik, Daniel Cohen-Or, and Dani\n",
      "Lischinski. Noise-free score distillation. arXiv preprint\n",
      "arXiv:2310.17590, 2023. 5\n",
      "\n",
      "-----------------------\n",
      "[29] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Mu-\n",
      "rata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki\n",
      "Mitsufuji, and Stefano Ermon. Consistency trajectory models:\n",
      "Learning probability ﬂow ode trajectory of diffusion. arXiv\n",
      "preprint arXiv:2310.02279, 2023. 3\n",
      "\n",
      "-----------------------\n",
      "[30] Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Ma-\n",
      "tiana, Joe Penna, and Omer Levy. Pick-a-pic: An open dataset\n",
      "of user preferences for text-to-image generation, 2023. 12\n",
      "\n",
      "-----------------------\n",
      "[31] Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun\n",
      "Fu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren. Snapfusion:\n",
      "Text-to-image diffusion model on mobile devices within two\n",
      "seconds. arXiv preprint arXiv:2306.00980, 2023. 7\n",
      "\n",
      "-----------------------\n",
      "[32] Jae Hyun Lim and Jong Chul Ye. Geometric gan. arXiv\n",
      "\n",
      "-----------------------\n",
      "preprint arXiv:1705.02894, 2017. 5\n",
      "\n",
      "-----------------------\n",
      "[33] Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Com-\n",
      "mon diffusion noise schedules and sample steps are ﬂawed,\n",
      "2023. 4\n",
      "\n",
      "-----------------------\n",
      "[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bour-\n",
      "dev, Ross Girshick, James Hays, Pietro Perona, Deva Ra-\n",
      "manan, C. Lawrence Zitnick, and Piotr Doll´ar. Microsoft\n",
      "coco: Common objects in context, 2015. 6\n",
      "\n",
      "-----------------------\n",
      "[35] Xingchao Liu, Chengyue Gong, et al. Flow straight and\n",
      "fast: Learning to generate and transfer data with rectiﬁed\n",
      "ﬂow. In The Eleventh International Conference on Learning\n",
      "Representations, 2022. 2\n",
      "\n",
      "-----------------------\n",
      "[36] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, and\n",
      "Qiang Liu. Instaﬂow: One step is enough for high-quality\n",
      "diffusion-based text-to-image generation. arXiv preprint\n",
      "arXiv:2309.06380, 2023. 2, 3, 7, 15\n",
      "\n",
      "-----------------------\n",
      "[37] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan\n",
      "Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion\n",
      "probabilistic model sampling in around 10 steps. Advances in\n",
      "Neural Information Processing Systems, 35:5775–5787, 2022.\n",
      "2, 7\n",
      "\n",
      "-----------------------\n",
      "[38] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and\n",
      "Latent consistency models: Synthesizing\n",
      "Hang Zhao.\n",
      "high-resolution images with few-step inference. ArXiv,\n",
      "abs/2310.04378, 2023. 2, 13\n",
      "\n",
      "-----------------------\n",
      "[39] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang\n",
      "Zhao.\n",
      "Latent consistency models: Synthesizing high-\n",
      "resolution images with few-step inference. arXiv preprint\n",
      "arXiv:2310.04378, 2023. 6\n",
      "\n",
      "-----------------------\n",
      "[40] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\n",
      "Platen, Apolin’ario Passos, Longbo Huang, Jian Li, and Hang\n",
      "Zhao. Lcm-lora: A universal stable-diffusion acceleration\n",
      "module. ArXiv, abs/2311.05556, 2023. 2, 3, 13, 15\n",
      "\n",
      "-----------------------\n",
      "[41] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\n",
      "Platen, Apolin´ario Passos, Longbo Huang, Jian Li, and Hang\n",
      "Zhao. Lcm-lora: A universal stable-diffusion acceleration\n",
      "module. arXiv preprint arXiv:2311.05556, 2023. 6\n",
      "\n",
      "-----------------------\n",
      "[42] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun,\n",
      "Zhenguo Li, and Zhihua Zhang. Diff-instruct: A universal ap-\n",
      "\n",
      "-----------------------\n",
      "[43] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik\n",
      "Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.\n",
      "On distillation of guided diffusion models. In Proceedings of\n",
      "the IEEE/CVF Conference on Computer Vision and Pattern\n",
      "Recognition, pages 14297–14306, 2023. 2, 7\n",
      "\n",
      "-----------------------\n",
      "[44] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.\n",
      "Which training methods for gans do actually converge? In\n",
      "International conference on machine learning, pages 3481–\n",
      "3490. PMLR, 2018. 5\n",
      "\n",
      "-----------------------\n",
      "[45] Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and\n",
      "Daniel Cohen-Or. Latent-nerf for shape-guided generation\n",
      "of 3d shapes and textures. 2023 IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR), pages\n",
      "12663–12673, 2022. 2\n",
      "\n",
      "-----------------------\n",
      "[46] Takeru Miyato and Masanori Koyama. cgans with projection\n",
      "discriminator. arXiv preprint arXiv:1802.05637, 2018. 4\n",
      "[47] Maxime Oquab, Timoth´ee Darcet, Th´eo Moutakanni, Huy Vo,\n",
      "Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel\n",
      "Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2:\n",
      "Learning robust visual features without supervision. arXiv\n",
      "preprint arXiv:2304.07193, 2023. 6\n",
      "\n",
      "-----------------------\n",
      "[48] Suraj Patil, William Berman, and Patrick von Platen. Amused:\n",
      "An open muse model. https://github.com/huggingface/\n",
      "diffusers, 2023. 6, 15\n",
      "\n",
      "-----------------------\n",
      "[49] William Peebles and Saining Xie. Scalable diffusion models\n",
      "with transformers. In Proceedings of the IEEE/CVF Inter-\n",
      "national Conference on Computer Vision, pages 4195–4205,\n",
      "2023. 6\n",
      "\n",
      "-----------------------\n",
      "[50] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann,\n",
      "Tim Dockhorn, Jonas M¨uller, Joe Penna, and Robin Rombach.\n",
      "Sdxl: Improving latent diffusion models for high-resolution\n",
      "image synthesis. arXiv preprint arXiv:2307.01952, 2023. 2,\n",
      "4, 5, 6, 7, 8, 12, 13\n",
      "\n",
      "-----------------------\n",
      "[51] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.\n",
      "Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint\n",
      "arXiv:2209.14988, 2022. 2, 5, 12\n",
      "\n",
      "-----------------------\n",
      "[52] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\n",
      "Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\n",
      "Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning\n",
      "transferable visual models from natural language supervi-\n",
      "sion. In International conference on machine learning, pages\n",
      "8748–8763. PMLR, 2021. 6, 12\n",
      "\n",
      "-----------------------\n",
      "[53] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,\n",
      "and Mark Chen. Hierarchical text-conditional image gener-\n",
      "ation with clip latents. ArXiv, abs/2204.06125, 2022. 1, 2,\n",
      "4\n",
      "\n",
      "-----------------------\n",
      "[54] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick\n",
      "Esser, and Bj¨orn Ommer. High-resolution image synthesis\n",
      "with latent diffusion models. 2022 IEEE/CVF Conference\n",
      "on Computer Vision and Pattern Recognition (CVPR), pages\n",
      "10674–10685, 2021. 1, 2, 5, 6, 8\n",
      "\n",
      "-----------------------\n",
      "[55] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,\n",
      "Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael\n",
      "Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Pho-\n",
      "torealistic text-to-image diffusion models with deep language\n",
      "\n",
      "-----------------------\n",
      "10\n",
      "\n",
      "-----------------------\n",
      "Page 11\n",
      "-----------------------\n",
      "[70] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling\n",
      "the generative learning trilemma with denoising diffusion\n",
      "gans. arXiv preprint arXiv:2112.07804, 2021. 3\n",
      "\n",
      "-----------------------\n",
      "[71] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufo-\n",
      "gen: You forward once large scale text-to-image generation\n",
      "via diffusion gans. arXiv preprint arXiv:2311.09257, 2023. 7\n",
      "[72] Chun-Han Yao, Amit Raj, Wei-Chih Hung, Yuanzhen Li,\n",
      "Michael Rubinstein, Ming-Hsuan Yang, and Varun Jampani.\n",
      "Artic3d: Learning robust articulated 3d shapes from noisy\n",
      "web image collections. arXiv preprint arXiv:2306.04619,\n",
      "2023. 4\n",
      "\n",
      "-----------------------\n",
      "[73] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan\n",
      "Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei\n",
      "Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana\n",
      "Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui\n",
      "Wu. Scaling autoregressive models for content-rich text-to-\n",
      "image generation, 2022. 12\n",
      "\n",
      "-----------------------\n",
      "[74] Qinsheng Zhang and Yongxin Chen. Fast sampling of dif-\n",
      "fusion models with exponential integrator. arXiv preprint\n",
      "arXiv:2204.13902, 2022. 2\n",
      "\n",
      "-----------------------\n",
      "understanding. Advances in Neural Information Processing\n",
      "Systems, 35:36479–36494, 2022. 4, 6\n",
      "\n",
      "-----------------------\n",
      "[56] Tim Salimans and Jonathan Ho. Progressive distillation for\n",
      "fast sampling of diffusion models. CoRR, abs/2202.00512,\n",
      "2022. 2\n",
      "\n",
      "-----------------------\n",
      "[57] Axel Sauer, Kashyap Chitta, Jens M¨uller, and Andreas Geiger.\n",
      "Projected gans converge faster. Advances in Neural Informa-\n",
      "tion Processing Systems, 34:17480–17492, 2021. 5\n",
      "\n",
      "-----------------------\n",
      "[58] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl:\n",
      "Scaling stylegan to large diverse datasets. ACM SIGGRAPH\n",
      "2022 Conference Proceedings, 2022. 1, 4\n",
      "\n",
      "-----------------------\n",
      "[59] Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and\n",
      "Timo Aila. Stylegan-t: Unlocking the power of gans for fast\n",
      "large-scale text-to-image synthesis. Proc. ICML, 2023. 2, 3,\n",
      "4, 5, 6, 14\n",
      "\n",
      "-----------------------\n",
      "[60] Juergen Schmidhuber. Generative adversarial networks are\n",
      "special cases of artiﬁcial curiosity (1990) and also closely\n",
      "related to predictability minimization (1991), 2020. 4\n",
      "[61] Christoph Schuhmann, Romain Beaumont, Richard Vencu,\n",
      "Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes,\n",
      "Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al.\n",
      "LAION-5B: An open large-scale dataset for training next\n",
      "generation image-text models. In NeurIPS, 2022. 6\n",
      "\n",
      "-----------------------\n",
      "[62] Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual,\n",
      "Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea\n",
      "Vedaldi, Devi Parikh, Justin Johnson, et al. Text-to-4d dy-\n",
      "namic scene generation. arXiv preprint arXiv:2301.11280,\n",
      "2023. 3\n",
      "\n",
      "-----------------------\n",
      "[63] Jascha Narain Sohl-Dickstein, Eric A. Weiss, Niru Ma-\n",
      "heswaranathan, and Surya Ganguli. Deep unsupervised\n",
      "learning using nonequilibrium thermodynamics. ArXiv,\n",
      "abs/1503.03585, 2015. 1\n",
      "\n",
      "-----------------------\n",
      "[64] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising\n",
      "diffusion implicit models. In International Conference on\n",
      "Learning Representations, 2021. 2\n",
      "\n",
      "-----------------------\n",
      "[65] Yang Song, Jascha Narain Sohl-Dickstein, Diederik P.\n",
      "Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.\n",
      "Score-based generative modeling through stochastic differen-\n",
      "tial equations. ArXiv, abs/2011.13456, 2020. 1\n",
      "\n",
      "-----------------------\n",
      "[66] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.\n",
      "Consistency models. In International Conference on Machine\n",
      "Learning, 2023. 2\n",
      "\n",
      "-----------------------\n",
      "[67] George Stein, Jesse C Cresswell, Rasa Hosseinzadeh, Yi Sui,\n",
      "Brendan Leigh Ross, Valentin Villecroze, Zhaoyan Liu, An-\n",
      "thony L Caterini, J Eric T Taylor, and Gabriel Loaiza-Ganem.\n",
      "Exposing ﬂaws of generative model evaluation metrics and\n",
      "their unfair treatment of diffusion models. arXiv preprint\n",
      "arXiv:2306.04675, 2023. 6, 14\n",
      "\n",
      "-----------------------\n",
      "[68] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A Yeh,\n",
      "and Greg Shakhnarovich. Score jacobian chaining: Lifting\n",
      "pretrained 2d diffusion models for 3d generation. In Proceed-\n",
      "ings of the IEEE/CVF Conference on Computer Vision and\n",
      "Pattern Recognition, pages 12619–12629, 2023. 2, 5\n",
      "[69] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan\n",
      "Li, Hang Su, and Jun Zhu. Proliﬁcdreamer: High-ﬁdelity and\n",
      "diverse text-to-3d generation with variational score distilla-\n",
      "tion. ArXiv, abs/2305.16213, 2023. 2\n",
      "\n",
      "-----------------------\n",
      "11\n",
      "\n",
      "-----------------------\n",
      "Page 12\n",
      "-----------------------\n",
      "Appendix\n",
      "\n",
      "-----------------------\n",
      "A. SDS As a Special Case of the Distillation Loss\n",
      "\n",
      "-----------------------\n",
      "If we set the weighting function to c(t) = αt\n",
      "and choose d(x, y) = ||x − y||2\n",
      "\n",
      "-----------------------\n",
      "2σt w(t) where w(t) is the scaling factor from the weighted diffusion loss as in [51]\n",
      "\n",
      "-----------------------\n",
      "2, the distillation loss in Eq. (4) is equivalent to the score distillation objective:\n",
      "\n",
      "-----------------------\n",
      "d\n",
      "dθ\n",
      "\n",
      "-----------------------\n",
      "LMSE\n",
      "distill\n",
      "\n",
      "-----------------------\n",
      "(ˆxθ,t − ˆxθ,t) + ˆxθ − ˆxψ(ˆxθ,t; t)]\n",
      "\n",
      "-----------------------\n",
      "dˆxθ\n",
      "dθ i\n",
      "\n",
      "-----------------------\n",
      "(5)\n",
      "\n",
      "-----------------------\n",
      "||ˆxθ − ˆxψ(sg(ˆxθ,t); t)||2\n",
      "2i\n",
      "\n",
      "-----------------------\n",
      "d\n",
      "= Et,ϵ′ hc(t)\n",
      "dθ\n",
      "= Et,ϵ′ h2c(t)[ˆxθ − ˆxψ(ˆxθ,t; t)]\n",
      "= Et,ϵ′ h\n",
      "\n",
      "-----------------------\n",
      "w(t)[\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "αt\n",
      "\n",
      "-----------------------\n",
      "dˆxθ\n",
      "dθ i\n",
      "\n",
      "-----------------------\n",
      "αt\n",
      "σt\n",
      "1\n",
      "σt\n",
      "w(t)\n",
      "σt\n",
      "\n",
      "-----------------------\n",
      "= Et,ϵ′ h\n",
      "\n",
      "-----------------------\n",
      "= Et,ϵ′ h\n",
      "d\n",
      "dθ\n",
      "\n",
      "-----------------------\n",
      "=\n",
      "\n",
      "-----------------------\n",
      "LSDS\n",
      "\n",
      "-----------------------\n",
      "w(t)[(αt ˆxθ − ˆxθ,t) − (αt ˆxψ(ˆxθ,t; t) − ˆxθ,t)]\n",
      "\n",
      "-----------------------\n",
      "dˆxθ\n",
      "dθ i\n",
      "\n",
      "-----------------------\n",
      "[−σtϵ′ + σtˆϵθ(ˆxθ,t; t)]\n",
      "\n",
      "-----------------------\n",
      "dˆxθ\n",
      "dθ i\n",
      "\n",
      "-----------------------\n",
      "B. Details on Human Preference Assessment\n",
      "\n",
      "-----------------------\n",
      "For the evaluation results presented in Figures 5 to 7, we employ human evaluation and do not rely on commonly used\n",
      "metrics for quality assessment of generative models such as FID [18] and CLIP-score [52], since these have been shown to\n",
      "capture more ﬁne grained aspects like aesthetics and scene composition only insufﬁciently [30, 50]. However these categories\n",
      "in particular have become more and more important when comparing current state-of-the-art text-to-image models. We\n",
      "evaluate all models based on 100 selected prompts from the PartiPrompts benchmark [73] with the most relevant categories\n",
      "(excluding prompts from the category basic). More details on how the study was conducted Appendix B.1 and the rankings\n",
      "computed Appendix B.2 are listed below.\n",
      "\n",
      "-----------------------\n",
      "Figure 9. User preference study (single step). We compare the performance of ADD-M (1-step) against established baselines.\n",
      "\n",
      "-----------------------\n",
      "12\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 13\n",
      "-----------------------\n",
      "Figure 10. User preference study (multiple steps). We compare the performance of ADD-XL (4-step) against established baselines.\n",
      "\n",
      "-----------------------\n",
      "B.1. Experimental Setup\n",
      "\n",
      "-----------------------\n",
      "Given all models for one particular study (e.g. ADD-XL, OpenMUSE6, IF-XL7, SDXL [50] and LCM-XL8 [38, 40] in\n",
      "Figure 7) we compare each prompt for each pair of models (1v1). For every comparison, we collect an average of four votes\n",
      "per task from different annotators, for both visual quality and prompt following. Human evaluators, recruited from the platform\n",
      "Proliﬁc9 with English as their ﬁrst language, are shown two images from different models based on the same text prompt. To\n",
      "prevent biases, evaluators are restricted from participating in more than one of our studies. For the prompt following task,\n",
      "we display the text prompt above the two images and ask, “Which image looks more representative of the text shown above\n",
      "and faithfully follows it?” For the visual quality assessment, we do not show the prompt and instead ask, “Which image is of\n",
      "higher quality and aesthetically more pleasing?”. Performing a complete assessment between all pair-wise comparisons gives\n",
      "us robust and reliable signals on model performance trends and the effect of varying thresholds. The order of prompts and the\n",
      "order between models are fully randomized. Frequent attention checks are in place to ensure data quality.\n",
      "\n",
      "-----------------------\n",
      "B.2. ELO Score Calculation\n",
      "\n",
      "-----------------------\n",
      "To calculate rankings when comparing more than two models based on 1v1 comparisons we use ELO Scores (higher-is-\n",
      "better) [10] which were originally proposed as a scoring method for chess players but have more recently also been applied to\n",
      "compare instruction-tuned generative LLMs [1, 2]. For a set of competing players with initial ratings Rinit participating in a\n",
      "series of zero-sum games the ELO rating system updates the ratings of the two players involved in a particular game based on\n",
      "the expected and and actual outcome of that game. Before the game with two players with ratings R1 and R2, the expected\n",
      "outcome for the two players are calculated as\n",
      "\n",
      "-----------------------\n",
      "E1 =\n",
      "\n",
      "-----------------------\n",
      "E2 =\n",
      "\n",
      "-----------------------\n",
      "1\n",
      "R2−R1\n",
      "400\n",
      "\n",
      "-----------------------\n",
      "1 + 10\n",
      "1\n",
      "R1−R2\n",
      "400\n",
      "\n",
      "-----------------------\n",
      "1 + 10\n",
      "\n",
      "-----------------------\n",
      ",\n",
      "\n",
      "-----------------------\n",
      ".\n",
      "\n",
      "-----------------------\n",
      "After observing the result of the game, the ratings Ri are updated via the rule\n",
      "\n",
      "-----------------------\n",
      "′\n",
      "\n",
      "-----------------------\n",
      "i = Ri + K · (Si − Ei) ,\n",
      "\n",
      "-----------------------\n",
      "R\n",
      "\n",
      "-----------------------\n",
      "i ∈ {1, 2}\n",
      "\n",
      "-----------------------\n",
      "(6)\n",
      "\n",
      "-----------------------\n",
      "(7)\n",
      "\n",
      "-----------------------\n",
      "(8)\n",
      "\n",
      "-----------------------\n",
      "where Si indicates the outcome of the match for player i. In our case we have Si = 1 if player i wins and Si = 0 if player\n",
      "i looses. The constant K can be see as weight putting emphasis on more recent games. We choose K = 1 and bootstrap\n",
      "the ﬁnal ELO ranking for a given series of comparisons based on 1000 individual ELO ranking calculations with randomly\n",
      "shufﬂed order. Before comparing the models we choose the start rating for every model as Rinit = 1000.\n",
      "\n",
      "-----------------------\n",
      "6https://huggingface.co/openMUSE\n",
      "7https://github.com/deep-ﬂoyd/IF\n",
      "8https://huggingface.co/latent-consistency/lcm-lora-sdxl\n",
      "9https://app.proliﬁc.com\n",
      "\n",
      "-----------------------\n",
      "13\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 14\n",
      "-----------------------\n",
      "C. GAN Baselines Comparison\n",
      "\n",
      "-----------------------\n",
      "For training our state-of-the-art GAN baseline StyleGAN-T++, we follow the training procedure outlined in [59]. The main\n",
      "differences are extended training (∼2M iterations with a batch size of 2048, which is comparable to GigaGAN’s schedule [25]),\n",
      "the improved discriminator architecture proposed in Section 3.2, and R1 penalty applied at each discriminator head.\n",
      "\n",
      "-----------------------\n",
      "Fig. 11 shows that StyleGAN-T++ outperforms the previous best GANs by achieving a comparable zero-shot FID to\n",
      "GigaGAN at a signiﬁcantly higher CLIP score. Here, we do not compare to DMs, as comparisons between model classes via\n",
      "automatic metrics tend to be less informative [67]. As an example, GigaGAN achieves FID and CLIP scores comparable to\n",
      "SD1.5, but its sample quality is still inferior, as noted by the authors.\n",
      "\n",
      "-----------------------\n",
      "k\n",
      "5\n",
      "\n",
      "-----------------------\n",
      "D\n",
      "I\n",
      "F\n",
      "t\n",
      "o\n",
      "h\n",
      "s\n",
      "-\n",
      "o\n",
      "r\n",
      "e\n",
      "Z\n",
      "\n",
      "-----------------------\n",
      "26\n",
      "24\n",
      "22\n",
      "20\n",
      "18\n",
      "16\n",
      "14\n",
      "\n",
      "-----------------------\n",
      "0.29\n",
      "\n",
      "-----------------------\n",
      "0.3\n",
      "\n",
      "-----------------------\n",
      "GigaGAN\n",
      "StyleGAN-T\n",
      "StyleGAN-T++\n",
      "\n",
      "-----------------------\n",
      "0.34\n",
      "\n",
      "-----------------------\n",
      "0.35\n",
      "\n",
      "-----------------------\n",
      "0.36\n",
      "\n",
      "-----------------------\n",
      "0.31\n",
      "\n",
      "-----------------------\n",
      "0.32\n",
      "CLIP score (ViT-g-14)\n",
      "\n",
      "-----------------------\n",
      "0.33\n",
      "\n",
      "-----------------------\n",
      "Figure 11. Comparing text alignment tradeoffs at 256 × 256 pixels. We compare FID–CLIP score curves of StyleGAN-T, StyleGAN-T++,\n",
      "and GigaGAN. For increasing CLIP score, all methods use via decreasing truncation [26] for values ψ = {1.0, 0.9, . . . , 0.3}.\n",
      "\n",
      "-----------------------\n",
      "Figure 12. Additional single step 5122 images generated with ADD-XL. All samples are generated with a single U-Net evaluation trained\n",
      "with adversarial diffusion distillation (ADD).\n",
      "\n",
      "-----------------------\n",
      "14\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 15\n",
      "-----------------------\n",
      "D. Additional Samples\n",
      "\n",
      "-----------------------\n",
      "We show additional one-step samples as in Figure 1 in Figure 12. An additional qualitative comparison as in Figure 4 which\n",
      "demonstrates that our model can further reﬁne quality by using more than one sampling step is provided in Figure 14, where\n",
      "we show that, while sampling quality with a single step is already high, more steps can give higher diversity and better spelling\n",
      "capabilities. Lastly, we provide an additional qualitative comparison of ADD-XL to other state-of-the-art one and few-step\n",
      "models in Figure 13.\n",
      "\n",
      "-----------------------\n",
      "A cinematic shot of robot with colorful feathers.\n",
      "\n",
      "-----------------------\n",
      "Teddy bears working on new AI research on the moon in the\n",
      "1980s.\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "D\n",
      "D\n",
      "A\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "M\n",
      "C\n",
      "L\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "D\n",
      "D\n",
      "A\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "2\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "M\n",
      "C\n",
      "L\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "2\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "D\n",
      "D\n",
      "A\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "-\n",
      "\n",
      "-----------------------\n",
      "L\n",
      "X\n",
      "M\n",
      "C\n",
      "L\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "w\n",
      "o\n",
      "l\n",
      "\n",
      "-----------------------\n",
      "F\n",
      "a\n",
      "t\n",
      "s\n",
      "n\n",
      "I\n",
      "\n",
      "-----------------------\n",
      "E\n",
      "S\n",
      "U\n",
      "M\n",
      "n\n",
      "e\n",
      "p\n",
      "O\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      ")\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "6\n",
      "1\n",
      "(\n",
      "\n",
      "-----------------------\n",
      "Figure 13. Additional qualitative comparisons to state of the art fast samplers. Few step samples from our ADD-XL and LCM-XL [40],\n",
      "InstaFlow [36], and OpenMuse [48].\n",
      "\n",
      "-----------------------\n",
      "15\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page 16\n",
      "-----------------------\n",
      "“a robot is playing the guitar at a rock concert in front of a large\n",
      "crowd.”\n",
      "\n",
      "-----------------------\n",
      "“A portrait photo of a kangaroo wearing an orange hoodie and\n",
      "blue sunglasses standing on the grass in front of the Sydney\n",
      "Opera House holding a sign on the chest that says Welcome\n",
      "Friends!”\n",
      "\n",
      "-----------------------\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "1\n",
      "\n",
      "-----------------------\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "2\n",
      "\n",
      "-----------------------\n",
      "s\n",
      "p\n",
      "e\n",
      "t\n",
      "s\n",
      "4\n",
      "\n",
      "-----------------------\n",
      "Figure 14. Additional results on the qualitative effect of sampling steps. Similar to Figure 4, we show qualitative examples when\n",
      "sampling ADD-XL with 1, 2, and 4 steps. Single-step samples are often already of high quality, but increasing the number of steps can\n",
      "further improve the diversity (left) and spelling capabilities (right). The seeds are constant within columns and we see that the general layout\n",
      "is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\n",
      "\n",
      "-----------------------\n",
      "16\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "Page: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\n",
      "-----------------------\n",
      "[('Adversarial Diffusion Distillation\\n', 14), ('Axel Sauer\\nDominik Lorenz\\nAndreas Blattmann\\nRobin Rombach\\n', 11), ('Code: https://github.com/Stability-AI/generative-models Model weights: https://huggingface.co/stabilityai/\\n', 8), ('Stability AI\\n', 11), ('Figure 1. Generating high-ﬁdelity 5122 images in a single step. All samples are generated with a single U-Net evaluation trained with\\nadversarial diffusion distillation (ADD).\\n', 8), ('Abstract\\n1. Introduction\\n', 11), ('We introduce Adversarial Diffusion Distillation (ADD), a\\nnovel training approach that efﬁciently samples large-scale\\nfoundational image diffusion models in just 1–4 steps while\\nmaintaining high image quality. We use score distillation\\nto leverage large-scale off-the-shelf image diffusion models\\nas a teacher signal in combination with an adversarial loss\\nto ensure high image ﬁdelity even in the low-step regime\\nof one or two sampling steps. Our analyses show that our\\nmodel clearly outperforms existing few-step methods (GANs,\\nLatent Consistency Models) in a single step and reaches the\\nperformance of state-of-the-art diffusion models (SDXL) in\\nonly four steps. ADD is the ﬁrst method to unlock single-step,\\nreal-time image synthesis with foundation models.\\nDiffusion models (DMs) [20, 63, 65] have taken a central\\nrole in the ﬁeld of generative modeling and have recently en-\\nabled remarkable advances in high-quality image- [3, 53, 54]\\nand video- [4, 12, 21] synthesis. One of the key strengths of\\nDMs is their scalability and iterative nature, which allows\\nthem to handle complex tasks such as image synthesis from\\nfree-form text prompts. However, the iterative inference\\nprocess in DMs requires a signiﬁcant number of sampling\\nsteps, which currently hinders their real-time application.\\nGenerative Adversarial Networks (GANs) [14, 26, 27], on\\nthe other hand, are characterized by their single-step for-\\nmulation and inherent speed. But despite attempts to scale\\nto large datasets[25, 58], GANs often fall short of DMs in\\nterms of sample quality. The aim of this work is to combine\\nthe superior sample quality of DMs with the inherent speed\\nof GANs.\\n1\\nOur approach is conceptually simple: We propose Ad-\\nversarial Diffusion Distillation (ADD), a general approach\\nthat reduces the number of inference steps of a pre-trained\\ndiffusion model to 1–4 sampling steps while maintaining\\nhigh sampling ﬁdelity and potentially further improving the\\noverall performance of the model. To this end, we intro-\\nduce a combination of two training objectives: (i) an ad-\\nversarial loss and (ii) a distillation loss that corresponds\\nto score distillation sampling (SDS) [51]. The adversar-\\nial loss forces the model to directly generate samples that\\nlie on the manifold of real images at each forward pass,\\navoiding blurriness and other artifacts typically observed in\\nother distillation methods [43]. The distillation loss uses\\nanother pretrained (and ﬁxed) DM as a teacher to effectively\\nutilize the extensive knowledge of the pretrained DM and\\npreserve the strong compositionality observed in large DMs.\\nDuring inference, our approach does not use classiﬁer-free\\nguidance [19], further reducing memory requirements. We\\nretain the model’s ability to improve results through iterative\\nreﬁnement, which is an advantage over previous one-step\\nGAN-based approaches [59].\\nOur contributions can be summarized as follows:\\n• We introduce ADD, a method for turning pretrained diffu-\\nsion models into high-ﬁdelity, real-time image generators\\nusing only 1–4 sampling steps.\\n• Our method uses a novel combination of adversarial train-\\ning and score distillation, for which we carefully ablate\\nseveral design choices.\\n• ADD signiﬁcantly outperforms strong baselines such as\\nLCM, LCM-XL [38] and single-step GANs [59], and is\\nable to handle complex image compositions while main-\\ntaining high image realism at only a single inference step.\\n• Using four sampling steps, ADD-XL outperforms its\\nteacher model SDXL-Base at a resolution of 5122 px.\\n', 9), ('2. Background\\n', 11), ('While diffusion models achieve remarkable performance in\\nsynthesizing and editing high-resolution images [3, 53, 54]\\nand videos [4, 21], their iterative nature hinders real-time ap-\\nplication. Latent diffusion models [54] attempt to solve this\\nproblem by representing images in a more computationally\\nfeasible latent space [11], but they still rely on the iterative\\napplication of large models with billions of parameters. In\\naddition to utilizing faster samplers for diffusion models\\n[8, 37, 64, 74], there is a growing body of research on model\\ndistillation such as progressive distillation [56] and guidance\\ndistillation [43]. These approaches reduce the number of\\niterative sampling steps to 4-8, but may signiﬁcantly lower\\nthe original performance. Furthermore, they require an it-\\nerative training process. Consistency models [66] address\\nthe latter issue by enforcing a consistency regularization on\\nthe ODE trajectory and demonstrate strong performance for\\npixel-based models in the few-shot setting. LCMs [38] focus\\n', 9), ('Figure 2. Adversarial Diffusion Distillation. The ADD-student\\nis trained as a denoiser that receives diffused input images xs\\nand outputs samples ˆxθ(xs, s) and optimizes two objectives: a)\\nadversarial loss: the model aims to fool a discriminator which is\\ntrained to distinguish the generated samples ˆxθ from real images\\nx0. b) distillation loss: the model is trained to match the denoised\\ntargets ˆxψ of a frozen DM teacher.\\n', 8), ('on distilling latent diffusion models and achieve impressive\\nperformance at 4 sampling steps. Recently, LCM-LoRA [40]\\nintroduced a low-rank adaptation [22] training for efﬁciently\\nlearning LCM modules, which can be plugged into differ-\\nent checkpoints for SD and SDXL [50, 54]. InstaFlow [36]\\npropose to use Rectiﬁed Flows [35] to facilitate a better\\ndistillation process.\\nAll of these methods share common ﬂaws: samples syn-\\nthesized in four steps often look blurry and exhibit noticeable\\nartifacts. At fewer sampling steps, this problem is further am-\\npliﬁed. GANs [14] can also be trained as standalone single-\\nstep models for text-to-image synthesis [25, 59]. Their sam-\\npling speed is impressive, yet the performance lags behind\\ndiffusion-based models. In part, this can be attributed to the\\nﬁnely balanced GAN-speciﬁc architectures necessary for sta-\\nble training of the adversarial objective. Scaling these mod-\\nels and integrating advances in neural network architectures\\nwithout disturbing the balance is notoriously challenging.\\nAdditionally, current state-of-the-art text-to-image GANs\\ndo not have a method like classiﬁer-free guidance available\\nwhich is crucial for DMs at scale.\\nScore Distillation Sampling [51] also known as Score\\nJacobian Chaining [68] is a recently proposed method that\\nhas been developed to distill the knowledge of foundational\\nT2I Models into 3D synthesis models. While the majority of\\nSDS-based works [45, 51, 68, 69] use SDS in the context of\\n2\\n', 9), ('A cinematic shot of a professor sloth wearing a tuxedo at a\\nBBQ party.\\nA high-quality photo of a confused bear in calculus class. The\\nbear is wearing a party hat and steampunk armor.\\n', 8), ('-\\n', 2), ('L\\nX\\nD\\nD\\nA\\n', 5), (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2), ('L\\nX\\nM\\nC\\nL\\n', 5), (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2), ('L\\nX\\nM\\nC\\nL\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n2\\n(\\n-\\n', 2), ('L\\nX\\nM\\nC\\nL\\n+\\n+\\nT\\n-\\nN\\nA\\nG\\ne\\nl\\ny\\nt\\nS\\n', 5), ('w\\no\\nl\\nF\\na\\nt\\ns\\nn\\nI\\n', 6), ('E\\nS\\nU\\nM\\nn\\ne\\np\\nO\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n)\\np\\ne\\nt\\ns\\n1\\n(\\n)\\np\\ne\\nt\\ns\\n1\\n(\\n)\\ns\\np\\ne\\nt\\ns\\n6\\n1\\n(\\n', 2), ('Figure 3. Qualitative comparison to state-of-the-art fast samplers. Single step samples from our ADD-XL (top) and LCM-XL [40], our\\ncustom StyleGAN-T [59] baseline, InstaFlow [36] and MUSE. For MUSE, we use the OpenMUSE implementation and default inference\\nsettings with 16 sampling steps. For LCM-XL, we sample with 1, 2 and 4 steps. Our model outperforms all other few-step samplers in a\\nsingle step.\\n', 8), ('per-scene optimization for 3D objects, the approach has also\\nbeen applied to text-to-3D-video-synthesis [62] and in the\\ncontext of image editing [16].\\nRecently, the authors of [13] have shown a strong relation-\\nship between score-based models and GANs and propose\\nScore GANs, which are trained using score-based diffusion\\nﬂows from a DM instead of a discriminator. Similarly, Diff-\\nInstruct [42], a method which generalizes SDS, enables to\\ndistill a pretrained diffusion model into a generator without\\ndiscriminator.\\nfaster sampling, Denoising Diffusion GANs [70] are intro-\\nduced as a method to enable sampling with few steps. To\\nimprove quality, a discriminator loss is added to the score\\nmatching objective in Adversarial Score Matching [24] and\\nthe consistency objective of CTM [29].\\nOur method combines adversarial training and score dis-\\ntillation in a hybrid objective to address the issues in current\\ntop performing few-step generative models.\\n', 9), ('3. Method\\n', 11), ('Conversely, there are also approaches which aim to im-\\nprove the diffusion process using adversarial training. For\\nOur goal is to generate high-ﬁdelity samples in as few sam-\\npling steps as possible, while matching the quality of state-\\n3\\n', 9), ('“A brain riding a rocketship heading\\ntowards the moon.”\\n“A bald eagle made of chocolate powder,\\nmango, and whipped cream”\\n“A blue colored dog.”\\n', 8), ('p\\ne\\nt\\ns\\n1\\n', 4), ('s\\np\\ne\\nt\\ns\\n2\\ns\\np\\ne\\nt\\ns\\n4\\n', 3), ('Figure 4. Qualitative effect of sampling steps. We show qualitative examples when sampling ADD-XL with 1, 2, and 4 steps. Single-step\\nsamples are often already of high quality, but increasing the number of steps can further improve the consistency (e.g. second prompt, ﬁrst\\ncolumn) and attention to detail (e.g. second prompt, second column). The seeds are constant within columns and we see that the general\\nlayout is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\\n', 8), ('of-the-art models [7, 50, 53, 55]. The adversarial objec-\\ntive [14, 60] naturally lends itself to fast generation as it\\ntrains a model that outputs samples on the image manifold in\\na single forward step. However, attempts at scaling GANs to\\nlarge datasets [58, 59] observed that is critical to not solely\\nrely on the discriminator, but also employ a pretrained clas-\\nsiﬁer or CLIP network for improving text alignment. As\\nremarked in [59], overly utilizing discriminative networks\\nintroduces artifacts and image quality suffers. Instead, we\\nutilize the gradient of a pretrained diffusion model via a score\\ndistillation objective to improve text alignment and sample\\nquality. Furthermore, instead of training from scratch, we\\ninitialize our model with pretrained diffusion model weights;\\npretraining the generator network is known to signiﬁcantly\\nimprove training with an adversarial loss [15]. Lastly, in-\\nstead of utilizing a decoder-only architecture used for GAN\\ntraining [26, 27], we adapt a standard diffusion model frame-\\nwork. This setup naturally enables iterative reﬁnement.\\n', 9), ('3.1. Training Procedure\\n', 10), ('Our training procedure is outlined in Fig. 2 and involves three\\nnetworks: The ADD-student is initialized from a pretrained\\nUNet-DM with weights θ, a discriminator with trainable\\nweights ϕ, and a DM teacher with frozen weights ψ. Dur-\\ning training, the ADD-student generates samples ˆxθ(xs, s)\\nfrom noisy data xs. The noised data points are produced\\nfrom a dataset of real images x0 via a forward diffusion\\nprocess xs = αsx0 + σsϵ. In our experiments, we use the\\nsame coefﬁcients αs and σs as the student DM and sam-\\nple s uniformly from a set Tstudent = {τ1, ..., τn} of N\\nchosen student timesteps. In practice, we choose N = 4.\\nImportantly, we set τn = 1000 and enforce zero-terminal\\nSNR [33] during training, as the model needs to start from\\npure noise during inference.\\nFor the adversarial objective, the generated samples ˆxθ\\nand real images x0 are passed to the discriminator which\\naims to distinguish between them. The design of the dis-\\ncriminator and the adversarial loss are described in detail in\\nSec. 3.2. To distill knowledge from the DM teacher, we dif-\\nfuse student samples ˆxθ with the teacher’s forward process to\\nˆxθ,t, and use the teacher’s denoising prediction ˆxψ(ˆxθ,t, t)\\nas a reconstruction target for the distillation loss Ldistill,\\nsee Section 3.3. Thus, the overall objective is\\nL = LG\\n', 9), ('adv(ˆxθ(xs, s), ϕ) + λLdistill(ˆxθ(xs, s), ψ)\\n', 6), ('(1)\\nWhile we formulate our method in pixel space, it is\\nstraightforward to adapt it to LDMs operating in latent space.\\nWhen using LDMs with a shared latent space for teacher\\nand student, the distillation loss can be computed in pixel or\\nlatent space. We compute the distillation loss in pixel space\\nas this yields more stable gradients when distilling latent\\ndiffusion model [72].\\n', 9), ('3.2. Adversarial Loss\\n', 10), ('For the discriminator, we follow the proposed design and\\ntraining procedure in [59] which we brieﬂy summarize; for\\ndetails, we refer the reader to the original work. We use a\\nfrozen pretrained feature network F and a set of trainable\\nlightweight discriminator heads Dϕ,k. For the feature net-\\nwork F , Sauer et al. [59] ﬁnd vision transformers (ViTs) [9]\\nto work well, and we ablate different choice for the ViTs\\nobjective and model size in Section 4. The trainable discrim-\\ninator heads are applied on features Fk at different layers of\\nthe feature network.\\nTo improve performance, the discriminator can be condi-\\ntioned on additional information via projection [46]. Com-\\n4\\n', 9), ('Figure 5. User preference study (single step). We compare the performance of ADD-XL (1-step) against established baselines. ADD-XL\\nmodel outperforms all models, except SDXL in human preference for both image quality and prompt alignment. Using more sampling steps\\nfurther improves our model (bottom row).\\n', 8), ('monly, a text embedding ctext is used in the text-to-image\\nsetting. But, in contrast to standard GAN training, our train-\\ning conﬁguration also allows to condition on a given image.\\nFor τ < 1000, the ADD-student receives some signal from\\nthe input image x0. Therefore, for a given generated sample\\nˆxθ(xs, s), we can condition the discriminator on information\\nfrom x0. This encourages the ADD-student to utilize the\\ninput effectively. In practice, we use an additional feature\\nnetwork to extract an image embedding cimg.\\nFollowing [57, 59], we use the hinge loss [32] as the\\nadversarial objective function. Thus the ADD-student’s ad-\\nversarial objective Ladv(ˆxθ(xs, s), ϕ) amounts to\\nLG\\n', 9), ('adv(ˆxθ(xs, s), ϕ)\\n', 6), ('= −Es,ϵ,x0 h X\\n', 9), ('k\\n', 6), ('Dϕ,k(Fk(ˆxθ(xs, s)))i ,\\n(2)\\nwhereas the discriminator is trained to minimize\\nLD\\nadv(ˆxθ(xs, s), ϕ)\\n= Ex0 h X\\n', 9), ('k\\n', 6), ('max(0, 1 − Dϕ,k(Fk(x0))) + γR1(ϕ)i\\n+ Eˆxθ h X\\n', 9), ('k\\n', 6), ('max(0, 1 + Dϕ,k(Fk(ˆxθ)))i ,\\nwhere sg denotes the stop-gradient operation. Intuitively,\\nthe loss uses a distance metric d to measure the mis-\\nmatch between generated samples xθ by the ADD-student\\nand the DM-teacher’s outputs ˆxψ(ˆxθ,t, t) = (ˆxθ,t −\\nσtˆϵψ(ˆxθ,t, t))/αt averaged over timesteps t and noise ϵ′.\\nNotably, the teacher is not directly applied on generations\\nˆxθ of the ADD-student but instead on diffused outputs\\nˆxθ,t = αt ˆxθ + σtϵ′, as non-diffused inputs would be out-of-\\ndistribution for the teacher model [68].\\nIn the following, we deﬁne the distance function\\nd(x, y) := ||x − y||2\\n2. Regarding the weighting function\\nc(t), we consider two options: exponential weighting, where\\nc(t) = αt (higher noise levels contribute less), and score dis-\\ntillation sampling (SDS) weighting [51]. In the supplemen-\\ntary material, we demonstrate that with d(x, y) = ||x − y||2\\n2\\nand a speciﬁc choice for c(t), our distillation loss becomes\\nequivalent to the SDS objective LSDS, as proposed in [51].\\nThe advantage of our formulation is its ability to enable\\ndirect visualization of the reconstruction targets and that\\nit naturally facilitates the execution of several consecutive\\ndenoising steps. Lastly, we also evaluate noise-free score\\ndistillation (NFSD) objective, a recently proposed variant of\\nSDS [28].\\n(3)\\n', 9), ('4. Experiments\\n', 11), ('where R1 denotes the R1 gradient penalty [44]. Rather\\nthan computing the gradient penalty with respect to the pixel\\nvalues, we compute it on the input of each discriminator head\\nDϕ,k. We ﬁnd that the R1 penalty is particularly beneﬁcial\\nwhen training at output resolutions larger than 1282 px.\\n', 9), ('3.3. Score Distillation Loss\\n', 10), ('The distillation loss in Eq. (1) is formulated as\\nFor our experiments, we train two models of different ca-\\npacities, ADD-M (860M parameters) and ADD-XL (3.1B\\nparameters). For ablating ADD-M, we use a Stable Dif-\\nfusion (SD) 2.1 backbone [54], and for fair comparisons\\nwith other baselines, we use SD1.5. ADD-XL utilizes a\\nSDXL [50] backbone. All experiments are conducted at\\na standardized resolution of 512x512 pixels; outputs from\\nmodels generating higher resolutions are down-sampled to\\nthis size.\\nLdistill(ˆxθ(xs, s), ψ)\\n= Et,ϵ′\\n(cid:2)\\nc(t)d(ˆxθ, ˆxψ(sg(ˆxθ,t); t))\\n,\\n(cid:3)\\n(4)\\nWe employ a distillation weighting factor of λ = 2.5\\nacross all experiments. Additionally, the R1 penalty strength\\n5\\n', 9), ('Arch\\nViT-S\\nViT-S\\nViT-L\\nViT-L\\nObjective FID ↓\\n21.5\\nDINOv1\\n20.6\\nDINOv2\\n24.0\\nDINOv2\\n23.3\\nCLIP\\nCS ↑\\n0.312\\n0.319\\n0.302\\n0.308\\nctext\\n✗\\n✓\\n✗\\n✓\\ncimg\\n✗\\n✗\\n✓\\n✓\\nFID ↓\\n21.2\\n21.2\\n21.1\\n20.6\\nCS ↑\\n0.302\\n0.307\\n0.316\\n0.319\\nInitialization\\nRandom\\nPretrained\\nFID ↓ CS ↑\\n293.6 0.065\\n0.319\\n20.6\\n(a) Discriminator feature networks. Small,\\nmodern DINO networks perform best.\\n(b) Discriminator conditioning. Combining\\nimage and text conditioning is most effective.\\n(c) Student pretraining. A randomly initial-\\nized student network collapses.\\nLoss\\nLadv\\nLdistill\\nLadv + λLdistill,exp\\nLadv + λLdistill,sds\\nLadv +λLdistill,nfsd\\nFID ↓\\n20.8\\n315.6\\n20.6\\n22.3\\n21.8\\nCS ↑\\n0.315\\n0.076\\n0.319\\n0.325\\n0.327\\nStudent\\nSD2.1\\nSD2.1\\nSDXL\\nSDXL\\nTeacher\\nSD2.1\\nSDXL\\nSD2.1\\nSDXL\\nFID ↓\\n20.6\\n21.3\\n29.3\\n28.41\\nCS ↑\\n0.319\\n0.321\\n0.314\\n0.325\\nSteps\\n1\\n2\\n4\\nFID ↓\\n20.6\\n20.8\\n20.3\\nCS ↑\\n0.319\\n0.321\\n0.317\\n(d) Loss terms. Both losses are needed and\\nexponential weighting of Ldistill is beneﬁcial.\\n(e) Teacher type. The student adopts the\\nteacher’s traits (SDXL has higher FID & CS).\\n(f) Teacher steps. A single teacher step is sufﬁ-\\ncient.\\n', 7), ('Table 1. ADD ablation study. We report COCO zero-shot FID5k (FID) and CLIP score (CS). The results are calculated for a single student\\nstep. The default training settings are: DINOv2 ViT-S as the feature network, text and image conditioning for the discriminator, pretrained\\nstudent weights, a small teacher and student model, and a single teacher step. The training length is 4000 iterations with a batch size of 128.\\nDefault settings are marked in gray .\\n', 8), ('γ is set to 10−5. For discriminator conditioning, we use\\na pretrained CLIP-ViT-g-14 text encoder [52] to compute\\ntext embeddings ctext and the CLS embedding of a DINOv2\\nViT-L encoder [47] for image embeddings cimg. For the\\nbaselines, we use the best publicly available models: La-\\ntent diffusion models [50, 54] (SD1.51, SDXL2) cascaded\\npixel diffusion models [55] (IF-XL3), distilled diffusion mod-\\nels [39, 41] (LCM-1.5, LCM-1.5-XL4), and OpenMUSE\\n5 [48], a reimplementation of MUSE [6], a transformer\\nmodel speciﬁcally developed for fast inference. Note that\\nwe compare to the SDXL-Base-1.0 model without its addi-\\ntional reﬁner model; this is to ensure a fair comparison. As\\nthere are no public state-of-the-art GAN models, we retrain\\nStyleGAN-T [59] with our improved discriminator. This\\nbaseline (StyleGAN-T++) signiﬁcantly outperforms the pre-\\nvious best GANs in FID and CS, see supplementary. We\\nquantify sample quality via FID [18] and text alignment via\\nCLIP score [17]. For CLIP score, we use ViT-g-14 model\\ntrained on LAION-2B [61]. Both metrics are evaluated on\\n5k samples from COCO2017 [34].\\n', 9), ('4.1. Ablation Study\\n', 10), ('Our training setup opens up a number of design spaces re-\\ngarding the adversarial loss, distillation loss, initialization,\\nand loss interplay. We conduct an ablation study on several\\nchoices in Table 1; key insights are highlighted below each\\ntable. We will discuss each experiment in the following.\\nDiscriminator feature networks.\\n(Table 1a). Recent\\ninsights by Stein et al. [67] suggest that ViTs trained with the\\nCLIP [52] or DINO [5, 47] objectives are particularly well-\\n', 9), ('1https://github.com/CompVis/stable-diffusion\\n2https://github.com/Stability-AI/generative-models\\n3https://github.com/deep-ﬂoyd/IF\\n4https://huggingface.co/latent-consistency/lcm-lora-sdxl\\n5https://huggingface.co/openMUSE\\n', 5), ('6\\nsuited for evaluating the performance of generative models.\\nSimilarly, these models also seem effective as discriminator\\nfeature networks, with DINOv2 emerging as the best choice.\\nDiscriminator conditioning. (Table 1b). Similar to prior\\nstudies, we observe that text conditioning of the discrimi-\\nnator enhances results. Notably, image conditioning outper-\\nforms text conditioning, and the combination of both ctext\\nand cimg yields the best results.\\nStudent pretraining. (Table 1c). Our experiments demon-\\nstrate the importance of pretraining the ADD-student. Being\\nable to use pretrained generators is a signiﬁcant advantage\\nover pure GAN approaches. A problem of GANs is the lack\\nof scalability; both Sauer et al. [59] and Kang et al. [25]\\nobserve a saturation of performance after a certain network\\ncapacity is reached. This observation contrasts the generally\\nsmooth scaling laws of DMs [49]. However, ADD can ef-\\nfectively leverage larger pretrained DMs (see Table 1c) and\\nbeneﬁt from stable DM pretraining.\\nLoss terms. (Table 1d). We ﬁnd that both losses are essen-\\ntial. The distillation loss on its own is not effective, but when\\ncombined with the adversarial loss, there is a noticeable im-\\nprovement in results. Different weighting schedules lead\\nto different behaviours, the exponential schedule tends to\\nyield more diverse samples, as indicated by lower FID, SDS\\nand NFSD schedules improve quality and text alignment.\\nWhile we use the exponential schedule as the default setting\\nin all other ablations, we opt for the NFSD weighting for\\ntraining our ﬁnal model. Choosing an optimal weighting\\nfunction presents an opportunity for improvement. Alterna-\\ntively, scheduling the distillation weights over training, as\\nexplored in the 3D generative modeling literature [23] could\\nbe considered.\\n', 9), ('Figure 6. User preference study (multiple steps). We compare the performance of ADD-XL (4-step) against established baselines. Our\\nADD-XL model outperforms all models, including its teacher SDXL 1.0 (base, no reﬁner) [50], in human preference for both image quality\\nand prompt alignment.\\n', 8), ('Method\\n#Steps\\nTime (s)\\nFID ↓\\nCLIP ↑\\nDPM Solver [37]\\nProgressive Distillation [43]\\nCFG-Aware Distillation [31]\\nInstaFlow-0.9B [36]\\nInstaFlow-1.7B [36]\\nUFOGen [71]\\nADD-M\\n25\\n8\\n1\\n2\\n4\\n8\\n1\\n1\\n1\\n1\\n0.88\\n0.34\\n0.09\\n0.13\\n0.21\\n0.34\\n0.09\\n0.12\\n0.09\\n0.09\\n20.1\\n31.7\\n37.2\\n26.0\\n26.4\\n24.2\\n23.4\\n22.4\\n22.5\\n19.7\\n0.318\\n0.320\\n0.275\\n0.297\\n0.300\\n0.300\\n0.304\\n0.309\\n0.311\\n0.326\\n', 6), ('↓\\n]\\ns\\n[\\nd\\ne\\ne\\np\\ns\\n', 4), ('e\\nc\\nn\\ne\\nr\\ne\\nf\\nn\\nI\\n', 3), ('12\\n10\\n5\\n3\\n1\\n0\\nTable 2. Distillation Comparison We compare ADD to other\\ndistillation methods via COCO zero-shot FID5k (FID) and CLIP\\nscore (CS). All models are based on SD1.5.\\n', 8), ('Teacher type.\\n(Table 1e). Interestingly, a bigger student\\nand teacher does not necessarily result in better FID and\\nCS. Rather, the student adopts the teachers characteristics.\\nSDXL obtains generally higher FID, possibly because of its\\nless diverse output, yet it exhibits higher image quality and\\ntext alignment [50].\\nTeacher steps.\\n(Table 1f). While our distillation loss\\nformulation allows taking several consecutive steps with the\\nteacher by construction, we ﬁnd that several steps do not\\nconclusively result in better performance.\\n', 9), ('4.2. Quantitative Comparison to State of the Art\\n', 10), ('For our main comparison with other approaches, we refrain\\nfrom using automated metrics, as user preference studies\\nare more reliable [50]. In the study, we aim to assess both\\nprompt adherence and the overall image. As a performance\\nmeasure, we compute win percentages for pairwise compar-\\nisons and ELO scores when comparing several approaches.\\nFor the reported ELO scores we calculate the mean scores\\n7\\n', 9), ('IF-XL\\n(150 steps)\\nSDXL\\n(50 steps)\\nOpenMUSE\\n(16 steps)\\n900\\n950\\nLCM-XL\\n(4 steps)\\nADD-XL\\n(1 step)\\n1,050\\n1,000\\nELO ↑\\nADD-XL\\n(4 steps)\\n1,100\\n1,150\\n1,200\\nFigure 7. Performance vs. speed. We visualize the results reported\\nin Fig. 6 in combination with the inference speeds of the respective\\nmodels. The speeds are calculated for generating a single sample\\nat resolution 512x512 on an A100 in mixed precision.\\n', 8), ('between both prompt following and image quality. Details\\non the ELO score computation and the study parameters are\\nlisted in the supplementary material.\\nFig. 5 and Fig. 6 present the study results. The most im-\\nportant results are: First, ADD-XL outperforms LCM-XL (4\\nsteps) with a single step. Second, ADD-XL can beat SDXL\\n(50 steps) with four steps in the majority of comparisons.\\nThis makes ADD-XL the state-of-the-art in both the single\\nand the multiple steps setting. Fig. 7 visualizes ELO scores\\nrelative to inference speed. Lastly, Table 2 compares dif-\\nferent few-step sampling and distillation methods using the\\nsame base model. ADD outperforms all other approaches\\nincluding the standard DPM solver with eight steps.\\n', 9), ('4.3. Qualitative Results\\n', 10), ('To complement our quantitative studies above, we present\\nqualitative results in this section. To paint a more complete\\npicture, we provide additional samples and qualitative com-\\n', 9), ('A cinematic shot of a little pig priest wearing sunglasses.\\nA photograph of the inside of a subway train. There are frogs\\nsitting on the seats. One of them is reading a newspaper. The\\nwindow shows the river in the background.\\nA photo of an astronaut riding a horse in the forest. There is a\\nriver in front of them with water lilies.\\nA photo of a cute mouse wearing a crown.\\n', 8), ('-\\n', 2), ('L\\nX\\nD\\nD\\nA\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n', 2), ('e\\ns\\na\\nB\\n-\\nL\\nX\\nD\\nS\\n', 3), (')\\ns\\np\\ne\\nt\\ns\\n0\\n5\\n(\\n-\\n', 2), ('L\\nX\\nD\\nD\\nA\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n', 2), ('e\\ns\\na\\nB\\n-\\nL\\nX\\nD\\nS\\n', 3), (')\\ns\\np\\ne\\nt\\ns\\n0\\n5\\n(\\n', 2), ('Figure 8. Qualitative comparison to the teacher model. ADD-XL can outperform its teacher model SDXL in the multi-step setting. The\\nadversarial loss boosts realism, particularly enhancing textures (fur, fabric, skin) while reducing oversmoothing, commonly observed in\\ndiffusion model samples. ADD-XL’s overall sample diversity tends to be lower.\\n', 8), ('parisons in the supplementary material. Fig. 3 compares\\nADD-XL (1 step) against the best current baselines in the\\nfew-steps regime. Fig. 4 illustrates the iterative sampling\\nprocess of ADD-XL. These results showcase our model’s\\nability to improve upon an initial sample. Such iterative\\nimprovement represents another signiﬁcant beneﬁt over pure\\nGAN approaches like StyleGAN-T++. Lastly, Fig. 8 com-\\npares ADD-XL directly with its teacher model SDXL-Base.\\nAs indicated by the user studies in Section 4.2, ADD-XL\\noutperforms its teacher in both quality and prompt alignment.\\nThe enhanced realism comes at the cost of slightly decreased\\nsample diversity.\\n', 9), ('5. Discussion\\n', 11), ('This work introduces Adversarial Diffusion Distillation, a\\ngeneral method for distilling a pretrained diffusion model\\ninto a fast, few-step image generation model. We combine\\nan adversarial and a score distillation objective to distill the\\npublic Stable Diffusion [54] and SDXL [50] models, lever-\\naging both real data through the discriminator and structural\\nunderstanding through the diffusion teacher. Our approach\\nperforms particularly well in the ultra-fast sampling regime\\nof one or two steps, and our analyses demonstrate that it out-\\nperforms all concurrent methods in this regime. Furthermore,\\n8\\nwe retain the ability to reﬁne samples using multiple steps.\\nIn fact, using four sampling steps, our model outperforms\\nwidely used multi-step generators such as SDXL, IF, and\\nOpenMUSE.\\nOur model enables the generation of high quality images\\nin a single-step, opening up new possibilities for real-time\\ngeneration with foundation models.\\n', 9), ('Acknowledgements\\n', 11), ('We would like to thank Jonas M¨uller for feedback on the\\ndraft, the proof, and typesetting; Patrick Esser for feedback\\non the proof and building an early model demo; Frederic\\nBoesel for generating data and helpful discussions; Minguk\\nKang and Taesung Park for providing GigaGAN samples;\\nRichard Vencu, Harry Saini, and Sami Kama for maintaining\\nthe compute infrastructure; Yara Wald for creative sampling\\nsupport; and Vanessa Sauer for her general support.\\n', 9), ('References\\n', 11), ('[1] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep\\nGanguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben\\nMann, Nova DasSarma, Nelson Elhage, Zac Hatﬁeld-Dodds,\\nDanny Hernandez, Jackson Kernion, Kamal Ndousse, Cather-\\nine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam\\nMcCandlish, Chris Olah, and Jared Kaplan. A general lan-\\nguage assistant as a laboratory for alignment, 2021. 13\\n[2] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell,\\nAnna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort,\\nDeep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\\ndavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nel-\\nson Elhage, Zac Hatﬁeld-Dodds, Danny Hernandez, Tristan\\nHume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel\\nNanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack\\nClark, Sam McCandlish, Chris Olah, Ben Mann, and Jared\\nKaplan. Training a helpful and harmless assistant with rein-\\nforcement learning from human feedback, 2022. 13\\n[3] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat,\\nJiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala,\\nTimo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, and\\nMing-Yu Liu. ediff-i: Text-to-image diffusion models with an\\nensemble of expert denoisers. ArXiv, abs/2211.01324, 2022.\\n1, 2\\n[4] A. Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn,\\nSeung Wook Kim, Sanja Fidler, and Karsten Kreis. Align your\\nlatents: High-resolution video synthesis with latent diffusion\\nmodels. 2023 IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR), pages 22563–22575, 2023.\\n1, 2\\n[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou,\\nJulien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-\\ning properties in self-supervised vision transformers. In Pro-\\nceedings of the IEEE/CVF international conference on com-\\nputer vision, pages 9650–9660, 2021. 6\\n[6] Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot,\\nJose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy,\\nWilliam T Freeman, Michael Rubinstein, et al. Muse: Text-to-\\nimage generation via masked generative transformers. Proc.\\nICML, 2023. 6\\n[7] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang\\nWang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiao-\\nfang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image\\ngeneration models using photogenic needles in a haystack.\\narXiv preprint arXiv:2309.15807, 2023. 4\\n[8] Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Genie:\\nHigher-order denoising diffusion solvers. Advances in Neural\\nInformation Processing Systems, 35:30150–30166, 2022. 2\\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\\nDirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\\nMostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\\nvain Gelly, et al. An image is worth 16x16 words: Trans-\\narXiv preprint\\nformers for image recognition at scale.\\narXiv:2010.11929, 2020. 4\\n[10] Arpad E. Elo. The Rating of Chessplayers, Past and Present.\\nArco Pub., New York, 1978. 13\\n[11] Patrick Esser, Robin Rombach, and Bj¨orn Ommer. Tam-\\ning transformers for high-resolution image synthesis. 2021\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR), pages 12868–12878, 2020. 2\\n[12] Patrick Esser, Johnathan Chiu, Parmida Atighehchian,\\nJonathan Granskog, and Anastasis Germanidis. Structure\\nand content-guided video synthesis with diffusion models,\\n2023. 1\\n[13] Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos,\\nThibaut Issenhuth, Emmanuel de B´ezenac, Micka¨el Chen,\\nand Alain Rakotomamonjy. Unifying gans and score-based\\narXiv preprint\\ndiffusion as generative particle models.\\narXiv:2305.16150, 2023. 3\\n[14] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing\\nXu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville,\\nand Yoshua Bengio. Generative adversarial networks. Com-\\nmunications of the ACM, 63:139 – 144, 2014. 1, 2, 4\\n[15] Timofey Grigoryev, Andrey Voynov, and Artem Babenko.\\nWhen, why, and which pretrained gans are useful? ICLR,\\n2022. 4\\n[16] Amir Hertz, Kﬁr Aberman, and Daniel Cohen-Or. Delta de-\\nnoising score. In Proceedings of the IEEE/CVF International\\nConference on Computer Vision, pages 2328–2337, 2023. 3\\n[17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,\\nand Yejin Choi. CLIPScore: A reference-free evaluation\\nmetric for image captioning. In Proc. EMNLP, 2021. 6\\n[18] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bern-\\nhard Nessler, and Sepp Hochreiter. GANs trained by a two\\ntime-scale update rule converge to a local Nash equilibrium.\\nNeurIPS, 2017. 6, 12\\n[19] Jonathan Ho. Classiﬁer-free diffusion guidance. ArXiv,\\nabs/2207.12598, 2022. 2\\n[20] Jonathan Ho, Ajay Jain, and P. Abbeel. Denoising diffusion\\nprobabilistic models. ArXiv, abs/2006.11239, 2020. 1\\n[21] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang,\\nRuiqi Gao, Alexey A. Gritsenko, Diederik P. Kingma, Ben\\nPoole, Mohammad Norouzi, David J. Fleet, and Tim Salimans.\\nImagen video: High deﬁnition video generation with diffusion\\nmodels. ArXiv, abs/2210.02303, 2022. 1, 2\\n[22] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\\nYuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank\\nadaptation of large language models. ArXiv, abs/2106.09685,\\n2021. 2\\n[23] Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-\\nJun Zha, and Lei Zhang. Dreamtime: An improved optimiza-\\ntion strategy for text-to-3d content creation. arXiv preprint\\narXiv:2306.12422, 2023. 6\\n[24] Alexia Jolicoeur-Martineau, R´emi Pich´e-Taillefer, R´emi Ta-\\nchet des Combes, and Ioannis Mitliagkas. Adversarial score\\nmatching and improved sampling for image generation. arXiv\\npreprint arXiv:2009.05475, 2020. 3\\n[25] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli\\nShechtman, Sylvain Paris, and Taesung Park. Scaling up gans\\nfor text-to-image synthesis. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition,\\npages 10124–10134, 2023. 1, 2, 6, 14\\n[26] Tero Karras, Samuli Laine, and Timo Aila. A style-based\\ngenerator architecture for generative adversarial networks.\\n2019 IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR), pages 4396–4405, 2018. 1, 4, 14\\n[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,\\nJaakko Lehtinen, and Timo Aila. Analyzing and improving\\nthe image quality of stylegan. 2020 IEEE/CVF Conference\\n', 8), ('9\\n', 9), ('on Computer Vision and Pattern Recognition (CVPR), pages\\n8107–8116, 2019. 1, 4\\nproach for transferring knowledge from pre-trained diffusion\\nmodels. arXiv preprint arXiv:2305.18455, 2023. 3\\n[28] Oren Katzir, Or Patashnik, Daniel Cohen-Or, and Dani\\nLischinski. Noise-free score distillation. arXiv preprint\\narXiv:2310.17590, 2023. 5\\n[29] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Mu-\\nrata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki\\nMitsufuji, and Stefano Ermon. Consistency trajectory models:\\nLearning probability ﬂow ode trajectory of diffusion. arXiv\\npreprint arXiv:2310.02279, 2023. 3\\n[30] Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Ma-\\ntiana, Joe Penna, and Omer Levy. Pick-a-pic: An open dataset\\nof user preferences for text-to-image generation, 2023. 12\\n[31] Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun\\nFu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren. Snapfusion:\\nText-to-image diffusion model on mobile devices within two\\nseconds. arXiv preprint arXiv:2306.00980, 2023. 7\\n[32] Jae Hyun Lim and Jong Chul Ye. Geometric gan. arXiv\\npreprint arXiv:1705.02894, 2017. 5\\n[33] Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Com-\\nmon diffusion noise schedules and sample steps are ﬂawed,\\n2023. 4\\n[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bour-\\ndev, Ross Girshick, James Hays, Pietro Perona, Deva Ra-\\nmanan, C. Lawrence Zitnick, and Piotr Doll´ar. Microsoft\\ncoco: Common objects in context, 2015. 6\\n[35] Xingchao Liu, Chengyue Gong, et al. Flow straight and\\nfast: Learning to generate and transfer data with rectiﬁed\\nﬂow. In The Eleventh International Conference on Learning\\nRepresentations, 2022. 2\\n[36] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, and\\nQiang Liu. Instaﬂow: One step is enough for high-quality\\ndiffusion-based text-to-image generation. arXiv preprint\\narXiv:2309.06380, 2023. 2, 3, 7, 15\\n[37] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan\\nLi, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion\\nprobabilistic model sampling in around 10 steps. Advances in\\nNeural Information Processing Systems, 35:5775–5787, 2022.\\n2, 7\\n[38] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and\\nLatent consistency models: Synthesizing\\nHang Zhao.\\nhigh-resolution images with few-step inference. ArXiv,\\nabs/2310.04378, 2023. 2, 13\\n[39] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang\\nZhao.\\nLatent consistency models: Synthesizing high-\\nresolution images with few-step inference. arXiv preprint\\narXiv:2310.04378, 2023. 6\\n[40] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\\nPlaten, Apolin’ario Passos, Longbo Huang, Jian Li, and Hang\\nZhao. Lcm-lora: A universal stable-diffusion acceleration\\nmodule. ArXiv, abs/2311.05556, 2023. 2, 3, 13, 15\\n[41] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\\nPlaten, Apolin´ario Passos, Longbo Huang, Jian Li, and Hang\\nZhao. Lcm-lora: A universal stable-diffusion acceleration\\nmodule. arXiv preprint arXiv:2311.05556, 2023. 6\\n[42] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun,\\nZhenguo Li, and Zhihua Zhang. Diff-instruct: A universal ap-\\n[43] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik\\nKingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.\\nOn distillation of guided diffusion models. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 14297–14306, 2023. 2, 7\\n[44] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.\\nWhich training methods for gans do actually converge? In\\nInternational conference on machine learning, pages 3481–\\n3490. PMLR, 2018. 5\\n[45] Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and\\nDaniel Cohen-Or. Latent-nerf for shape-guided generation\\nof 3d shapes and textures. 2023 IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR), pages\\n12663–12673, 2022. 2\\n[46] Takeru Miyato and Masanori Koyama. cgans with projection\\ndiscriminator. arXiv preprint arXiv:1802.05637, 2018. 4\\n[47] Maxime Oquab, Timoth´ee Darcet, Th´eo Moutakanni, Huy Vo,\\nMarc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel\\nHaziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2:\\nLearning robust visual features without supervision. arXiv\\npreprint arXiv:2304.07193, 2023. 6\\n[48] Suraj Patil, William Berman, and Patrick von Platen. Amused:\\nAn open muse model. https://github.com/huggingface/\\ndiffusers, 2023. 6, 15\\n[49] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. In Proceedings of the IEEE/CVF Inter-\\nnational Conference on Computer Vision, pages 4195–4205,\\n2023. 6\\n[50] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann,\\nTim Dockhorn, Jonas M¨uller, Joe Penna, and Robin Rombach.\\nSdxl: Improving latent diffusion models for high-resolution\\nimage synthesis. arXiv preprint arXiv:2307.01952, 2023. 2,\\n4, 5, 6, 7, 8, 12, 13\\n[51] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.\\nDreamfusion: Text-to-3d using 2d diffusion. arXiv preprint\\narXiv:2209.14988, 2022. 2, 5, 12\\n[52] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\\nAmanda Askell, Pamela Mishkin, Jack Clark, et al. Learning\\ntransferable visual models from natural language supervi-\\nsion. In International conference on machine learning, pages\\n8748–8763. PMLR, 2021. 6, 12\\n[53] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,\\nand Mark Chen. Hierarchical text-conditional image gener-\\nation with clip latents. ArXiv, abs/2204.06125, 2022. 1, 2,\\n4\\n[54] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick\\nEsser, and Bj¨orn Ommer. High-resolution image synthesis\\nwith latent diffusion models. 2022 IEEE/CVF Conference\\non Computer Vision and Pattern Recognition (CVPR), pages\\n10674–10685, 2021. 1, 2, 5, 6, 8\\n[55] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,\\nJay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael\\nGontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Pho-\\ntorealistic text-to-image diffusion models with deep language\\n', 8), ('10\\n', 9), ('[70] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling\\nthe generative learning trilemma with denoising diffusion\\ngans. arXiv preprint arXiv:2112.07804, 2021. 3\\n[71] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufo-\\ngen: You forward once large scale text-to-image generation\\nvia diffusion gans. arXiv preprint arXiv:2311.09257, 2023. 7\\n[72] Chun-Han Yao, Amit Raj, Wei-Chih Hung, Yuanzhen Li,\\nMichael Rubinstein, Ming-Hsuan Yang, and Varun Jampani.\\nArtic3d: Learning robust articulated 3d shapes from noisy\\nweb image collections. arXiv preprint arXiv:2306.04619,\\n2023. 4\\n[73] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan\\nBaid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei\\nYang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana\\nParekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui\\nWu. Scaling autoregressive models for content-rich text-to-\\nimage generation, 2022. 12\\n[74] Qinsheng Zhang and Yongxin Chen. Fast sampling of dif-\\nfusion models with exponential integrator. arXiv preprint\\narXiv:2204.13902, 2022. 2\\nunderstanding. Advances in Neural Information Processing\\nSystems, 35:36479–36494, 2022. 4, 6\\n[56] Tim Salimans and Jonathan Ho. Progressive distillation for\\nfast sampling of diffusion models. CoRR, abs/2202.00512,\\n2022. 2\\n[57] Axel Sauer, Kashyap Chitta, Jens M¨uller, and Andreas Geiger.\\nProjected gans converge faster. Advances in Neural Informa-\\ntion Processing Systems, 34:17480–17492, 2021. 5\\n[58] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl:\\nScaling stylegan to large diverse datasets. ACM SIGGRAPH\\n2022 Conference Proceedings, 2022. 1, 4\\n[59] Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and\\nTimo Aila. Stylegan-t: Unlocking the power of gans for fast\\nlarge-scale text-to-image synthesis. Proc. ICML, 2023. 2, 3,\\n4, 5, 6, 14\\n[60] Juergen Schmidhuber. Generative adversarial networks are\\nspecial cases of artiﬁcial curiosity (1990) and also closely\\nrelated to predictability minimization (1991), 2020. 4\\n[61] Christoph Schuhmann, Romain Beaumont, Richard Vencu,\\nCade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes,\\nAarush Katta, Clayton Mullis, Mitchell Wortsman, et al.\\nLAION-5B: An open large-scale dataset for training next\\ngeneration image-text models. In NeurIPS, 2022. 6\\n[62] Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual,\\nIurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea\\nVedaldi, Devi Parikh, Justin Johnson, et al. Text-to-4d dy-\\nnamic scene generation. arXiv preprint arXiv:2301.11280,\\n2023. 3\\n[63] Jascha Narain Sohl-Dickstein, Eric A. Weiss, Niru Ma-\\nheswaranathan, and Surya Ganguli. Deep unsupervised\\nlearning using nonequilibrium thermodynamics. ArXiv,\\nabs/1503.03585, 2015. 1\\n[64] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising\\ndiffusion implicit models. In International Conference on\\nLearning Representations, 2021. 2\\n[65] Yang Song, Jascha Narain Sohl-Dickstein, Diederik P.\\nKingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.\\nScore-based generative modeling through stochastic differen-\\ntial equations. ArXiv, abs/2011.13456, 2020. 1\\n[66] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.\\nConsistency models. In International Conference on Machine\\nLearning, 2023. 2\\n[67] George Stein, Jesse C Cresswell, Rasa Hosseinzadeh, Yi Sui,\\nBrendan Leigh Ross, Valentin Villecroze, Zhaoyan Liu, An-\\nthony L Caterini, J Eric T Taylor, and Gabriel Loaiza-Ganem.\\nExposing ﬂaws of generative model evaluation metrics and\\ntheir unfair treatment of diffusion models. arXiv preprint\\narXiv:2306.04675, 2023. 6, 14\\n[68] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A Yeh,\\nand Greg Shakhnarovich. Score jacobian chaining: Lifting\\npretrained 2d diffusion models for 3d generation. In Proceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 12619–12629, 2023. 2, 5\\n[69] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan\\nLi, Hang Su, and Jun Zhu. Proliﬁcdreamer: High-ﬁdelity and\\ndiverse text-to-3d generation with variational score distilla-\\ntion. ArXiv, abs/2305.16213, 2023. 2\\n', 8), ('11\\n', 9), ('Appendix\\nA. SDS As a Special Case of the Distillation Loss\\n', 11), ('If we set the weighting function to c(t) = αt\\nand choose d(x, y) = ||x − y||2\\n', 9), ('2σt w(t) where w(t) is the scaling factor from the weighted diffusion loss as in [51]\\n2, the distillation loss in Eq. (4) is equivalent to the score distillation objective:\\n', 6), ('d\\ndθ\\nLMSE\\ndistill\\n(ˆxθ,t − ˆxθ,t) + ˆxθ − ˆxψ(ˆxθ,t; t)]\\ndˆxθ\\ndθ i\\n(5)\\n||ˆxθ − ˆxψ(sg(ˆxθ,t); t)||2\\n2i\\nd\\n= Et,ϵ′ hc(t)\\ndθ\\n= Et,ϵ′ h2c(t)[ˆxθ − ˆxψ(ˆxθ,t; t)]\\n= Et,ϵ′ h\\nw(t)[\\n1\\nαt\\ndˆxθ\\ndθ i\\nαt\\nσt\\n1\\nσt\\nw(t)\\nσt\\n= Et,ϵ′ h\\n= Et,ϵ′ h\\nd\\ndθ\\n=\\nLSDS\\nw(t)[(αt ˆxθ − ˆxθ,t) − (αt ˆxψ(ˆxθ,t; t) − ˆxθ,t)]\\ndˆxθ\\ndθ i\\n[−σtϵ′ + σtˆϵθ(ˆxθ,t; t)]\\ndˆxθ\\ndθ i\\n', 9), ('B. Details on Human Preference Assessment\\n', 11), ('For the evaluation results presented in Figures 5 to 7, we employ human evaluation and do not rely on commonly used\\nmetrics for quality assessment of generative models such as FID [18] and CLIP-score [52], since these have been shown to\\ncapture more ﬁne grained aspects like aesthetics and scene composition only insufﬁciently [30, 50]. However these categories\\nin particular have become more and more important when comparing current state-of-the-art text-to-image models. We\\nevaluate all models based on 100 selected prompts from the PartiPrompts benchmark [73] with the most relevant categories\\n(excluding prompts from the category basic). More details on how the study was conducted Appendix B.1 and the rankings\\ncomputed Appendix B.2 are listed below.\\n', 9), ('Figure 9. User preference study (single step). We compare the performance of ADD-M (1-step) against established baselines.\\n', 8), ('12\\n', 9), ('Figure 10. User preference study (multiple steps). We compare the performance of ADD-XL (4-step) against established baselines.\\n', 8), ('B.1. Experimental Setup\\n', 10), ('Given all models for one particular study (e.g. ADD-XL, OpenMUSE6, IF-XL7, SDXL [50] and LCM-XL8 [38, 40] in\\nFigure 7) we compare each prompt for each pair of models (1v1). For every comparison, we collect an average of four votes\\nper task from different annotators, for both visual quality and prompt following. Human evaluators, recruited from the platform\\nProliﬁc9 with English as their ﬁrst language, are shown two images from different models based on the same text prompt. To\\nprevent biases, evaluators are restricted from participating in more than one of our studies. For the prompt following task,\\nwe display the text prompt above the two images and ask, “Which image looks more representative of the text shown above\\nand faithfully follows it?” For the visual quality assessment, we do not show the prompt and instead ask, “Which image is of\\nhigher quality and aesthetically more pleasing?”. Performing a complete assessment between all pair-wise comparisons gives\\nus robust and reliable signals on model performance trends and the effect of varying thresholds. The order of prompts and the\\norder between models are fully randomized. Frequent attention checks are in place to ensure data quality.\\n', 9), ('B.2. ELO Score Calculation\\n', 10), ('To calculate rankings when comparing more than two models based on 1v1 comparisons we use ELO Scores (higher-is-\\nbetter) [10] which were originally proposed as a scoring method for chess players but have more recently also been applied to\\ncompare instruction-tuned generative LLMs [1, 2]. For a set of competing players with initial ratings Rinit participating in a\\nseries of zero-sum games the ELO rating system updates the ratings of the two players involved in a particular game based on\\nthe expected and and actual outcome of that game. Before the game with two players with ratings R1 and R2, the expected\\noutcome for the two players are calculated as\\nE1 =\\nE2 =\\n1\\nR2−R1\\n400\\n1 + 10\\n1\\nR1−R2\\n400\\n1 + 10\\n,\\n.\\nAfter observing the result of the game, the ratings Ri are updated via the rule\\n', 9), ('′\\n', 4), ('i = Ri + K · (Si − Ei) ,\\n', 6), ('R\\ni ∈ {1, 2}\\n(6)\\n(7)\\n(8)\\nwhere Si indicates the outcome of the match for player i. In our case we have Si = 1 if player i wins and Si = 0 if player\\ni looses. The constant K can be see as weight putting emphasis on more recent games. We choose K = 1 and bootstrap\\nthe ﬁnal ELO ranking for a given series of comparisons based on 1000 individual ELO ranking calculations with randomly\\nshufﬂed order. Before comparing the models we choose the start rating for every model as Rinit = 1000.\\n', 9), ('6https://huggingface.co/openMUSE\\n7https://github.com/deep-ﬂoyd/IF\\n8https://huggingface.co/latent-consistency/lcm-lora-sdxl\\n9https://app.proliﬁc.com\\n', 5), ('13\\n', 9), ('C. GAN Baselines Comparison\\n', 11), ('For training our state-of-the-art GAN baseline StyleGAN-T++, we follow the training procedure outlined in [59]. The main\\ndifferences are extended training (∼2M iterations with a batch size of 2048, which is comparable to GigaGAN’s schedule [25]),\\nthe improved discriminator architecture proposed in Section 3.2, and R1 penalty applied at each discriminator head.\\nFig. 11 shows that StyleGAN-T++ outperforms the previous best GANs by achieving a comparable zero-shot FID to\\nGigaGAN at a signiﬁcantly higher CLIP score. Here, we do not compare to DMs, as comparisons between model classes via\\nautomatic metrics tend to be less informative [67]. As an example, GigaGAN achieves FID and CLIP scores comparable to\\nSD1.5, but its sample quality is still inferior, as noted by the authors.\\n', 9), ('k\\n5\\n', 6), ('D\\nI\\nF\\nt\\no\\nh\\ns\\n-\\no\\nr\\ne\\nZ\\n', 12), ('26\\n24\\n22\\n20\\n18\\n16\\n14\\n0.29\\n0.3\\n', 17), ('GigaGAN\\nStyleGAN-T\\nStyleGAN-T++\\n', 8), ('0.34\\n0.35\\n0.36\\n0.31\\n0.32\\nCLIP score (ViT-g-14)\\n0.33\\n', 17), ('Figure 11. Comparing text alignment tradeoffs at 256 × 256 pixels. We compare FID–CLIP score curves of StyleGAN-T, StyleGAN-T++,\\nand GigaGAN. For increasing CLIP score, all methods use via decreasing truncation [26] for values ψ = {1.0, 0.9, . . . , 0.3}.\\nFigure 12. Additional single step 5122 images generated with ADD-XL. All samples are generated with a single U-Net evaluation trained\\nwith adversarial diffusion distillation (ADD).\\n', 8), ('14\\n', 9), ('D. Additional Samples\\n', 11), ('We show additional one-step samples as in Figure 1 in Figure 12. An additional qualitative comparison as in Figure 4 which\\ndemonstrates that our model can further reﬁne quality by using more than one sampling step is provided in Figure 14, where\\nwe show that, while sampling quality with a single step is already high, more steps can give higher diversity and better spelling\\ncapabilities. Lastly, we provide an additional qualitative comparison of ADD-XL to other state-of-the-art one and few-step\\nmodels in Figure 13.\\n', 9), ('A cinematic shot of robot with colorful feathers.\\nTeddy bears working on new AI research on the moon in the\\n1980s.\\n', 8), ('-\\n', 2), ('L\\nX\\nD\\nD\\nA\\n', 5), (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2), ('L\\nX\\nM\\nC\\nL\\n', 5), (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2), ('L\\nX\\nD\\nD\\nA\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n2\\n(\\n-\\n', 2), ('L\\nX\\nM\\nC\\nL\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n2\\n(\\n-\\n', 2), ('L\\nX\\nD\\nD\\nA\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n-\\n', 2), ('L\\nX\\nM\\nC\\nL\\n', 5), (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n', 2), ('w\\no\\nl\\n', 6), ('F\\na\\nt\\ns\\nn\\nI\\n', 4), ('E\\nS\\nU\\nM\\nn\\ne\\np\\nO\\n', 5), (')\\np\\ne\\nt\\ns\\n1\\n(\\n)\\ns\\np\\ne\\nt\\ns\\n6\\n1\\n(\\n', 2), ('Figure 13. Additional qualitative comparisons to state of the art fast samplers. Few step samples from our ADD-XL and LCM-XL [40],\\nInstaFlow [36], and OpenMuse [48].\\n', 8), ('15\\n', 9), ('“a robot is playing the guitar at a rock concert in front of a large\\ncrowd.”\\n“A portrait photo of a kangaroo wearing an orange hoodie and\\nblue sunglasses standing on the grass in front of the Sydney\\nOpera House holding a sign on the chest that says Welcome\\nFriends!”\\n', 8), ('p\\ne\\nt\\ns\\n1\\n', 4), ('s\\np\\ne\\nt\\ns\\n2\\ns\\np\\ne\\nt\\ns\\n4\\n', 3), ('Figure 14. Additional results on the qualitative effect of sampling steps. Similar to Figure 4, we show qualitative examples when\\nsampling ADD-XL with 1, 2, and 4 steps. Single-step samples are often already of high quality, but increasing the number of steps can\\nfurther improve the diversity (left) and spelling capabilities (right). The seeds are constant within columns and we see that the general layout\\nis preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\\n', 8), ('16\\n', 9)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "cur_fs = None\n",
    "cur_text = ''\n",
    "snippets = []   # first collect all snippets that have the same font size\n",
    "for c in content:\n",
    "    sp = c.find('span')\n",
    "    if not sp:\n",
    "        continue\n",
    "    st = sp.get('style')\n",
    "    if not st:\n",
    "        continue\n",
    "    fs = re.findall('font-size:(\\d+)px',st)\n",
    "    if not fs:\n",
    "        continue\n",
    "    fs = int(fs[0])\n",
    "    if not cur_fs:\n",
    "        cur_fs = fs\n",
    "    if fs == cur_fs:\n",
    "        cur_text += c.text\n",
    "    else:\n",
    "        snippets.append((cur_text,cur_fs))\n",
    "        cur_fs = fs\n",
    "        cur_text = c.text\n",
    "snippets.append((cur_text,cur_fs))\n",
    "\n",
    "print(snippets)\n",
    "# Note: The above logic is very straightforward. One can also add more strategies such as removing duplicate snippets (as\n",
    "# headers/footers in a PDF appear on multiple pages so if we find duplicates it's safe to assume that it is redundant info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev Size: 14\n",
      "second if: ('Axel Sauer\\nDominik Lorenz\\nAndreas Blattmann\\nRobin Rombach\\n', 11)\n",
      "second if: ('Code: https://github.com/Stability-AI/generative-models Model weights: https://huggingface.co/stabilityai/\\n', 8)\n",
      "second if: ('Stability AI\\n', 11)\n",
      "second if: ('Figure 1. Generating high-ﬁdelity 5122 images in a single step. All samples are generated with a single U-Net evaluation trained with\\nadversarial diffusion distillation (ADD).\\n', 8)\n",
      "second if: ('Abstract\\n1. Introduction\\n', 11)\n",
      "second if: ('We introduce Adversarial Diffusion Distillation (ADD), a\\nnovel training approach that efﬁciently samples large-scale\\nfoundational image diffusion models in just 1–4 steps while\\nmaintaining high image quality. We use score distillation\\nto leverage large-scale off-the-shelf image diffusion models\\nas a teacher signal in combination with an adversarial loss\\nto ensure high image ﬁdelity even in the low-step regime\\nof one or two sampling steps. Our analyses show that our\\nmodel clearly outperforms existing few-step methods (GANs,\\nLatent Consistency Models) in a single step and reaches the\\nperformance of state-of-the-art diffusion models (SDXL) in\\nonly four steps. ADD is the ﬁrst method to unlock single-step,\\nreal-time image synthesis with foundation models.\\nDiffusion models (DMs) [20, 63, 65] have taken a central\\nrole in the ﬁeld of generative modeling and have recently en-\\nabled remarkable advances in high-quality image- [3, 53, 54]\\nand video- [4, 12, 21] synthesis. One of the key strengths of\\nDMs is their scalability and iterative nature, which allows\\nthem to handle complex tasks such as image synthesis from\\nfree-form text prompts. However, the iterative inference\\nprocess in DMs requires a signiﬁcant number of sampling\\nsteps, which currently hinders their real-time application.\\nGenerative Adversarial Networks (GANs) [14, 26, 27], on\\nthe other hand, are characterized by their single-step for-\\nmulation and inherent speed. But despite attempts to scale\\nto large datasets[25, 58], GANs often fall short of DMs in\\nterms of sample quality. The aim of this work is to combine\\nthe superior sample quality of DMs with the inherent speed\\nof GANs.\\n1\\nOur approach is conceptually simple: We propose Ad-\\nversarial Diffusion Distillation (ADD), a general approach\\nthat reduces the number of inference steps of a pre-trained\\ndiffusion model to 1–4 sampling steps while maintaining\\nhigh sampling ﬁdelity and potentially further improving the\\noverall performance of the model. To this end, we intro-\\nduce a combination of two training objectives: (i) an ad-\\nversarial loss and (ii) a distillation loss that corresponds\\nto score distillation sampling (SDS) [51]. The adversar-\\nial loss forces the model to directly generate samples that\\nlie on the manifold of real images at each forward pass,\\navoiding blurriness and other artifacts typically observed in\\nother distillation methods [43]. The distillation loss uses\\nanother pretrained (and ﬁxed) DM as a teacher to effectively\\nutilize the extensive knowledge of the pretrained DM and\\npreserve the strong compositionality observed in large DMs.\\nDuring inference, our approach does not use classiﬁer-free\\nguidance [19], further reducing memory requirements. We\\nretain the model’s ability to improve results through iterative\\nreﬁnement, which is an advantage over previous one-step\\nGAN-based approaches [59].\\nOur contributions can be summarized as follows:\\n• We introduce ADD, a method for turning pretrained diffu-\\nsion models into high-ﬁdelity, real-time image generators\\nusing only 1–4 sampling steps.\\n• Our method uses a novel combination of adversarial train-\\ning and score distillation, for which we carefully ablate\\nseveral design choices.\\n• ADD signiﬁcantly outperforms strong baselines such as\\nLCM, LCM-XL [38] and single-step GANs [59], and is\\nable to handle complex image compositions while main-\\ntaining high image realism at only a single inference step.\\n• Using four sampling steps, ADD-XL outperforms its\\nteacher model SDXL-Base at a resolution of 5122 px.\\n', 9)\n",
      "second if: ('2. Background\\n', 11)\n",
      "second if: ('While diffusion models achieve remarkable performance in\\nsynthesizing and editing high-resolution images [3, 53, 54]\\nand videos [4, 21], their iterative nature hinders real-time ap-\\nplication. Latent diffusion models [54] attempt to solve this\\nproblem by representing images in a more computationally\\nfeasible latent space [11], but they still rely on the iterative\\napplication of large models with billions of parameters. In\\naddition to utilizing faster samplers for diffusion models\\n[8, 37, 64, 74], there is a growing body of research on model\\ndistillation such as progressive distillation [56] and guidance\\ndistillation [43]. These approaches reduce the number of\\niterative sampling steps to 4-8, but may signiﬁcantly lower\\nthe original performance. Furthermore, they require an it-\\nerative training process. Consistency models [66] address\\nthe latter issue by enforcing a consistency regularization on\\nthe ODE trajectory and demonstrate strong performance for\\npixel-based models in the few-shot setting. LCMs [38] focus\\n', 9)\n",
      "second if: ('Figure 2. Adversarial Diffusion Distillation. The ADD-student\\nis trained as a denoiser that receives diffused input images xs\\nand outputs samples ˆxθ(xs, s) and optimizes two objectives: a)\\nadversarial loss: the model aims to fool a discriminator which is\\ntrained to distinguish the generated samples ˆxθ from real images\\nx0. b) distillation loss: the model is trained to match the denoised\\ntargets ˆxψ of a frozen DM teacher.\\n', 8)\n",
      "second if: ('on distilling latent diffusion models and achieve impressive\\nperformance at 4 sampling steps. Recently, LCM-LoRA [40]\\nintroduced a low-rank adaptation [22] training for efﬁciently\\nlearning LCM modules, which can be plugged into differ-\\nent checkpoints for SD and SDXL [50, 54]. InstaFlow [36]\\npropose to use Rectiﬁed Flows [35] to facilitate a better\\ndistillation process.\\nAll of these methods share common ﬂaws: samples syn-\\nthesized in four steps often look blurry and exhibit noticeable\\nartifacts. At fewer sampling steps, this problem is further am-\\npliﬁed. GANs [14] can also be trained as standalone single-\\nstep models for text-to-image synthesis [25, 59]. Their sam-\\npling speed is impressive, yet the performance lags behind\\ndiffusion-based models. In part, this can be attributed to the\\nﬁnely balanced GAN-speciﬁc architectures necessary for sta-\\nble training of the adversarial objective. Scaling these mod-\\nels and integrating advances in neural network architectures\\nwithout disturbing the balance is notoriously challenging.\\nAdditionally, current state-of-the-art text-to-image GANs\\ndo not have a method like classiﬁer-free guidance available\\nwhich is crucial for DMs at scale.\\nScore Distillation Sampling [51] also known as Score\\nJacobian Chaining [68] is a recently proposed method that\\nhas been developed to distill the knowledge of foundational\\nT2I Models into 3D synthesis models. While the majority of\\nSDS-based works [45, 51, 68, 69] use SDS in the context of\\n2\\n', 9)\n",
      "second if: ('A cinematic shot of a professor sloth wearing a tuxedo at a\\nBBQ party.\\nA high-quality photo of a confused bear in calculus class. The\\nbear is wearing a party hat and steampunk armor.\\n', 8)\n",
      "second if: ('-\\n', 2)\n",
      "second if: ('L\\nX\\nD\\nD\\nA\\n', 5)\n",
      "second if: (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nM\\nC\\nL\\n', 5)\n",
      "second if: (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nM\\nC\\nL\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n2\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nM\\nC\\nL\\n+\\n+\\nT\\n-\\nN\\nA\\nG\\ne\\nl\\ny\\nt\\nS\\n', 5)\n",
      "second if: ('w\\no\\nl\\nF\\na\\nt\\ns\\nn\\nI\\n', 6)\n",
      "second if: ('E\\nS\\nU\\nM\\nn\\ne\\np\\nO\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n)\\np\\ne\\nt\\ns\\n1\\n(\\n)\\np\\ne\\nt\\ns\\n1\\n(\\n)\\ns\\np\\ne\\nt\\ns\\n6\\n1\\n(\\n', 2)\n",
      "second if: ('Figure 3. Qualitative comparison to state-of-the-art fast samplers. Single step samples from our ADD-XL (top) and LCM-XL [40], our\\ncustom StyleGAN-T [59] baseline, InstaFlow [36] and MUSE. For MUSE, we use the OpenMUSE implementation and default inference\\nsettings with 16 sampling steps. For LCM-XL, we sample with 1, 2 and 4 steps. Our model outperforms all other few-step samplers in a\\nsingle step.\\n', 8)\n",
      "second if: ('per-scene optimization for 3D objects, the approach has also\\nbeen applied to text-to-3D-video-synthesis [62] and in the\\ncontext of image editing [16].\\nRecently, the authors of [13] have shown a strong relation-\\nship between score-based models and GANs and propose\\nScore GANs, which are trained using score-based diffusion\\nﬂows from a DM instead of a discriminator. Similarly, Diff-\\nInstruct [42], a method which generalizes SDS, enables to\\ndistill a pretrained diffusion model into a generator without\\ndiscriminator.\\nfaster sampling, Denoising Diffusion GANs [70] are intro-\\nduced as a method to enable sampling with few steps. To\\nimprove quality, a discriminator loss is added to the score\\nmatching objective in Adversarial Score Matching [24] and\\nthe consistency objective of CTM [29].\\nOur method combines adversarial training and score dis-\\ntillation in a hybrid objective to address the issues in current\\ntop performing few-step generative models.\\n', 9)\n",
      "second if: ('3. Method\\n', 11)\n",
      "second if: ('Conversely, there are also approaches which aim to im-\\nprove the diffusion process using adversarial training. For\\nOur goal is to generate high-ﬁdelity samples in as few sam-\\npling steps as possible, while matching the quality of state-\\n3\\n', 9)\n",
      "second if: ('“A brain riding a rocketship heading\\ntowards the moon.”\\n“A bald eagle made of chocolate powder,\\nmango, and whipped cream”\\n“A blue colored dog.”\\n', 8)\n",
      "second if: ('p\\ne\\nt\\ns\\n1\\n', 4)\n",
      "second if: ('s\\np\\ne\\nt\\ns\\n2\\ns\\np\\ne\\nt\\ns\\n4\\n', 3)\n",
      "second if: ('Figure 4. Qualitative effect of sampling steps. We show qualitative examples when sampling ADD-XL with 1, 2, and 4 steps. Single-step\\nsamples are often already of high quality, but increasing the number of steps can further improve the consistency (e.g. second prompt, ﬁrst\\ncolumn) and attention to detail (e.g. second prompt, second column). The seeds are constant within columns and we see that the general\\nlayout is preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\\n', 8)\n",
      "second if: ('of-the-art models [7, 50, 53, 55]. The adversarial objec-\\ntive [14, 60] naturally lends itself to fast generation as it\\ntrains a model that outputs samples on the image manifold in\\na single forward step. However, attempts at scaling GANs to\\nlarge datasets [58, 59] observed that is critical to not solely\\nrely on the discriminator, but also employ a pretrained clas-\\nsiﬁer or CLIP network for improving text alignment. As\\nremarked in [59], overly utilizing discriminative networks\\nintroduces artifacts and image quality suffers. Instead, we\\nutilize the gradient of a pretrained diffusion model via a score\\ndistillation objective to improve text alignment and sample\\nquality. Furthermore, instead of training from scratch, we\\ninitialize our model with pretrained diffusion model weights;\\npretraining the generator network is known to signiﬁcantly\\nimprove training with an adversarial loss [15]. Lastly, in-\\nstead of utilizing a decoder-only architecture used for GAN\\ntraining [26, 27], we adapt a standard diffusion model frame-\\nwork. This setup naturally enables iterative reﬁnement.\\n', 9)\n",
      "second if: ('3.1. Training Procedure\\n', 10)\n",
      "second if: ('Our training procedure is outlined in Fig. 2 and involves three\\nnetworks: The ADD-student is initialized from a pretrained\\nUNet-DM with weights θ, a discriminator with trainable\\nweights ϕ, and a DM teacher with frozen weights ψ. Dur-\\ning training, the ADD-student generates samples ˆxθ(xs, s)\\nfrom noisy data xs. The noised data points are produced\\nfrom a dataset of real images x0 via a forward diffusion\\nprocess xs = αsx0 + σsϵ. In our experiments, we use the\\nsame coefﬁcients αs and σs as the student DM and sam-\\nple s uniformly from a set Tstudent = {τ1, ..., τn} of N\\nchosen student timesteps. In practice, we choose N = 4.\\nImportantly, we set τn = 1000 and enforce zero-terminal\\nSNR [33] during training, as the model needs to start from\\npure noise during inference.\\nFor the adversarial objective, the generated samples ˆxθ\\nand real images x0 are passed to the discriminator which\\naims to distinguish between them. The design of the dis-\\ncriminator and the adversarial loss are described in detail in\\nSec. 3.2. To distill knowledge from the DM teacher, we dif-\\nfuse student samples ˆxθ with the teacher’s forward process to\\nˆxθ,t, and use the teacher’s denoising prediction ˆxψ(ˆxθ,t, t)\\nas a reconstruction target for the distillation loss Ldistill,\\nsee Section 3.3. Thus, the overall objective is\\nL = LG\\n', 9)\n",
      "second if: ('adv(ˆxθ(xs, s), ϕ) + λLdistill(ˆxθ(xs, s), ψ)\\n', 6)\n",
      "second if: ('(1)\\nWhile we formulate our method in pixel space, it is\\nstraightforward to adapt it to LDMs operating in latent space.\\nWhen using LDMs with a shared latent space for teacher\\nand student, the distillation loss can be computed in pixel or\\nlatent space. We compute the distillation loss in pixel space\\nas this yields more stable gradients when distilling latent\\ndiffusion model [72].\\n', 9)\n",
      "second if: ('3.2. Adversarial Loss\\n', 10)\n",
      "second if: ('For the discriminator, we follow the proposed design and\\ntraining procedure in [59] which we brieﬂy summarize; for\\ndetails, we refer the reader to the original work. We use a\\nfrozen pretrained feature network F and a set of trainable\\nlightweight discriminator heads Dϕ,k. For the feature net-\\nwork F , Sauer et al. [59] ﬁnd vision transformers (ViTs) [9]\\nto work well, and we ablate different choice for the ViTs\\nobjective and model size in Section 4. The trainable discrim-\\ninator heads are applied on features Fk at different layers of\\nthe feature network.\\nTo improve performance, the discriminator can be condi-\\ntioned on additional information via projection [46]. Com-\\n4\\n', 9)\n",
      "second if: ('Figure 5. User preference study (single step). We compare the performance of ADD-XL (1-step) against established baselines. ADD-XL\\nmodel outperforms all models, except SDXL in human preference for both image quality and prompt alignment. Using more sampling steps\\nfurther improves our model (bottom row).\\n', 8)\n",
      "second if: ('monly, a text embedding ctext is used in the text-to-image\\nsetting. But, in contrast to standard GAN training, our train-\\ning conﬁguration also allows to condition on a given image.\\nFor τ < 1000, the ADD-student receives some signal from\\nthe input image x0. Therefore, for a given generated sample\\nˆxθ(xs, s), we can condition the discriminator on information\\nfrom x0. This encourages the ADD-student to utilize the\\ninput effectively. In practice, we use an additional feature\\nnetwork to extract an image embedding cimg.\\nFollowing [57, 59], we use the hinge loss [32] as the\\nadversarial objective function. Thus the ADD-student’s ad-\\nversarial objective Ladv(ˆxθ(xs, s), ϕ) amounts to\\nLG\\n', 9)\n",
      "second if: ('adv(ˆxθ(xs, s), ϕ)\\n', 6)\n",
      "second if: ('= −Es,ϵ,x0 h X\\n', 9)\n",
      "second if: ('k\\n', 6)\n",
      "second if: ('Dϕ,k(Fk(ˆxθ(xs, s)))i ,\\n(2)\\nwhereas the discriminator is trained to minimize\\nLD\\nadv(ˆxθ(xs, s), ϕ)\\n= Ex0 h X\\n', 9)\n",
      "second if: ('k\\n', 6)\n",
      "second if: ('max(0, 1 − Dϕ,k(Fk(x0))) + γR1(ϕ)i\\n+ Eˆxθ h X\\n', 9)\n",
      "second if: ('k\\n', 6)\n",
      "second if: ('max(0, 1 + Dϕ,k(Fk(ˆxθ)))i ,\\nwhere sg denotes the stop-gradient operation. Intuitively,\\nthe loss uses a distance metric d to measure the mis-\\nmatch between generated samples xθ by the ADD-student\\nand the DM-teacher’s outputs ˆxψ(ˆxθ,t, t) = (ˆxθ,t −\\nσtˆϵψ(ˆxθ,t, t))/αt averaged over timesteps t and noise ϵ′.\\nNotably, the teacher is not directly applied on generations\\nˆxθ of the ADD-student but instead on diffused outputs\\nˆxθ,t = αt ˆxθ + σtϵ′, as non-diffused inputs would be out-of-\\ndistribution for the teacher model [68].\\nIn the following, we deﬁne the distance function\\nd(x, y) := ||x − y||2\\n2. Regarding the weighting function\\nc(t), we consider two options: exponential weighting, where\\nc(t) = αt (higher noise levels contribute less), and score dis-\\ntillation sampling (SDS) weighting [51]. In the supplemen-\\ntary material, we demonstrate that with d(x, y) = ||x − y||2\\n2\\nand a speciﬁc choice for c(t), our distillation loss becomes\\nequivalent to the SDS objective LSDS, as proposed in [51].\\nThe advantage of our formulation is its ability to enable\\ndirect visualization of the reconstruction targets and that\\nit naturally facilitates the execution of several consecutive\\ndenoising steps. Lastly, we also evaluate noise-free score\\ndistillation (NFSD) objective, a recently proposed variant of\\nSDS [28].\\n(3)\\n', 9)\n",
      "second if: ('4. Experiments\\n', 11)\n",
      "second if: ('where R1 denotes the R1 gradient penalty [44]. Rather\\nthan computing the gradient penalty with respect to the pixel\\nvalues, we compute it on the input of each discriminator head\\nDϕ,k. We ﬁnd that the R1 penalty is particularly beneﬁcial\\nwhen training at output resolutions larger than 1282 px.\\n', 9)\n",
      "second if: ('3.3. Score Distillation Loss\\n', 10)\n",
      "second if: ('The distillation loss in Eq. (1) is formulated as\\nFor our experiments, we train two models of different ca-\\npacities, ADD-M (860M parameters) and ADD-XL (3.1B\\nparameters). For ablating ADD-M, we use a Stable Dif-\\nfusion (SD) 2.1 backbone [54], and for fair comparisons\\nwith other baselines, we use SD1.5. ADD-XL utilizes a\\nSDXL [50] backbone. All experiments are conducted at\\na standardized resolution of 512x512 pixels; outputs from\\nmodels generating higher resolutions are down-sampled to\\nthis size.\\nLdistill(ˆxθ(xs, s), ψ)\\n= Et,ϵ′\\n(cid:2)\\nc(t)d(ˆxθ, ˆxψ(sg(ˆxθ,t); t))\\n,\\n(cid:3)\\n(4)\\nWe employ a distillation weighting factor of λ = 2.5\\nacross all experiments. Additionally, the R1 penalty strength\\n5\\n', 9)\n",
      "second if: ('Arch\\nViT-S\\nViT-S\\nViT-L\\nViT-L\\nObjective FID ↓\\n21.5\\nDINOv1\\n20.6\\nDINOv2\\n24.0\\nDINOv2\\n23.3\\nCLIP\\nCS ↑\\n0.312\\n0.319\\n0.302\\n0.308\\nctext\\n✗\\n✓\\n✗\\n✓\\ncimg\\n✗\\n✗\\n✓\\n✓\\nFID ↓\\n21.2\\n21.2\\n21.1\\n20.6\\nCS ↑\\n0.302\\n0.307\\n0.316\\n0.319\\nInitialization\\nRandom\\nPretrained\\nFID ↓ CS ↑\\n293.6 0.065\\n0.319\\n20.6\\n(a) Discriminator feature networks. Small,\\nmodern DINO networks perform best.\\n(b) Discriminator conditioning. Combining\\nimage and text conditioning is most effective.\\n(c) Student pretraining. A randomly initial-\\nized student network collapses.\\nLoss\\nLadv\\nLdistill\\nLadv + λLdistill,exp\\nLadv + λLdistill,sds\\nLadv +λLdistill,nfsd\\nFID ↓\\n20.8\\n315.6\\n20.6\\n22.3\\n21.8\\nCS ↑\\n0.315\\n0.076\\n0.319\\n0.325\\n0.327\\nStudent\\nSD2.1\\nSD2.1\\nSDXL\\nSDXL\\nTeacher\\nSD2.1\\nSDXL\\nSD2.1\\nSDXL\\nFID ↓\\n20.6\\n21.3\\n29.3\\n28.41\\nCS ↑\\n0.319\\n0.321\\n0.314\\n0.325\\nSteps\\n1\\n2\\n4\\nFID ↓\\n20.6\\n20.8\\n20.3\\nCS ↑\\n0.319\\n0.321\\n0.317\\n(d) Loss terms. Both losses are needed and\\nexponential weighting of Ldistill is beneﬁcial.\\n(e) Teacher type. The student adopts the\\nteacher’s traits (SDXL has higher FID & CS).\\n(f) Teacher steps. A single teacher step is sufﬁ-\\ncient.\\n', 7)\n",
      "second if: ('Table 1. ADD ablation study. We report COCO zero-shot FID5k (FID) and CLIP score (CS). The results are calculated for a single student\\nstep. The default training settings are: DINOv2 ViT-S as the feature network, text and image conditioning for the discriminator, pretrained\\nstudent weights, a small teacher and student model, and a single teacher step. The training length is 4000 iterations with a batch size of 128.\\nDefault settings are marked in gray .\\n', 8)\n",
      "second if: ('γ is set to 10−5. For discriminator conditioning, we use\\na pretrained CLIP-ViT-g-14 text encoder [52] to compute\\ntext embeddings ctext and the CLS embedding of a DINOv2\\nViT-L encoder [47] for image embeddings cimg. For the\\nbaselines, we use the best publicly available models: La-\\ntent diffusion models [50, 54] (SD1.51, SDXL2) cascaded\\npixel diffusion models [55] (IF-XL3), distilled diffusion mod-\\nels [39, 41] (LCM-1.5, LCM-1.5-XL4), and OpenMUSE\\n5 [48], a reimplementation of MUSE [6], a transformer\\nmodel speciﬁcally developed for fast inference. Note that\\nwe compare to the SDXL-Base-1.0 model without its addi-\\ntional reﬁner model; this is to ensure a fair comparison. As\\nthere are no public state-of-the-art GAN models, we retrain\\nStyleGAN-T [59] with our improved discriminator. This\\nbaseline (StyleGAN-T++) signiﬁcantly outperforms the pre-\\nvious best GANs in FID and CS, see supplementary. We\\nquantify sample quality via FID [18] and text alignment via\\nCLIP score [17]. For CLIP score, we use ViT-g-14 model\\ntrained on LAION-2B [61]. Both metrics are evaluated on\\n5k samples from COCO2017 [34].\\n', 9)\n",
      "second if: ('4.1. Ablation Study\\n', 10)\n",
      "second if: ('Our training setup opens up a number of design spaces re-\\ngarding the adversarial loss, distillation loss, initialization,\\nand loss interplay. We conduct an ablation study on several\\nchoices in Table 1; key insights are highlighted below each\\ntable. We will discuss each experiment in the following.\\nDiscriminator feature networks.\\n(Table 1a). Recent\\ninsights by Stein et al. [67] suggest that ViTs trained with the\\nCLIP [52] or DINO [5, 47] objectives are particularly well-\\n', 9)\n",
      "second if: ('1https://github.com/CompVis/stable-diffusion\\n2https://github.com/Stability-AI/generative-models\\n3https://github.com/deep-ﬂoyd/IF\\n4https://huggingface.co/latent-consistency/lcm-lora-sdxl\\n5https://huggingface.co/openMUSE\\n', 5)\n",
      "second if: ('6\\nsuited for evaluating the performance of generative models.\\nSimilarly, these models also seem effective as discriminator\\nfeature networks, with DINOv2 emerging as the best choice.\\nDiscriminator conditioning. (Table 1b). Similar to prior\\nstudies, we observe that text conditioning of the discrimi-\\nnator enhances results. Notably, image conditioning outper-\\nforms text conditioning, and the combination of both ctext\\nand cimg yields the best results.\\nStudent pretraining. (Table 1c). Our experiments demon-\\nstrate the importance of pretraining the ADD-student. Being\\nable to use pretrained generators is a signiﬁcant advantage\\nover pure GAN approaches. A problem of GANs is the lack\\nof scalability; both Sauer et al. [59] and Kang et al. [25]\\nobserve a saturation of performance after a certain network\\ncapacity is reached. This observation contrasts the generally\\nsmooth scaling laws of DMs [49]. However, ADD can ef-\\nfectively leverage larger pretrained DMs (see Table 1c) and\\nbeneﬁt from stable DM pretraining.\\nLoss terms. (Table 1d). We ﬁnd that both losses are essen-\\ntial. The distillation loss on its own is not effective, but when\\ncombined with the adversarial loss, there is a noticeable im-\\nprovement in results. Different weighting schedules lead\\nto different behaviours, the exponential schedule tends to\\nyield more diverse samples, as indicated by lower FID, SDS\\nand NFSD schedules improve quality and text alignment.\\nWhile we use the exponential schedule as the default setting\\nin all other ablations, we opt for the NFSD weighting for\\ntraining our ﬁnal model. Choosing an optimal weighting\\nfunction presents an opportunity for improvement. Alterna-\\ntively, scheduling the distillation weights over training, as\\nexplored in the 3D generative modeling literature [23] could\\nbe considered.\\n', 9)\n",
      "second if: ('Figure 6. User preference study (multiple steps). We compare the performance of ADD-XL (4-step) against established baselines. Our\\nADD-XL model outperforms all models, including its teacher SDXL 1.0 (base, no reﬁner) [50], in human preference for both image quality\\nand prompt alignment.\\n', 8)\n",
      "second if: ('Method\\n#Steps\\nTime (s)\\nFID ↓\\nCLIP ↑\\nDPM Solver [37]\\nProgressive Distillation [43]\\nCFG-Aware Distillation [31]\\nInstaFlow-0.9B [36]\\nInstaFlow-1.7B [36]\\nUFOGen [71]\\nADD-M\\n25\\n8\\n1\\n2\\n4\\n8\\n1\\n1\\n1\\n1\\n0.88\\n0.34\\n0.09\\n0.13\\n0.21\\n0.34\\n0.09\\n0.12\\n0.09\\n0.09\\n20.1\\n31.7\\n37.2\\n26.0\\n26.4\\n24.2\\n23.4\\n22.4\\n22.5\\n19.7\\n0.318\\n0.320\\n0.275\\n0.297\\n0.300\\n0.300\\n0.304\\n0.309\\n0.311\\n0.326\\n', 6)\n",
      "second if: ('↓\\n]\\ns\\n[\\nd\\ne\\ne\\np\\ns\\n', 4)\n",
      "second if: ('e\\nc\\nn\\ne\\nr\\ne\\nf\\nn\\nI\\n', 3)\n",
      "second if: ('12\\n10\\n5\\n3\\n1\\n0\\nTable 2. Distillation Comparison We compare ADD to other\\ndistillation methods via COCO zero-shot FID5k (FID) and CLIP\\nscore (CS). All models are based on SD1.5.\\n', 8)\n",
      "second if: ('Teacher type.\\n(Table 1e). Interestingly, a bigger student\\nand teacher does not necessarily result in better FID and\\nCS. Rather, the student adopts the teachers characteristics.\\nSDXL obtains generally higher FID, possibly because of its\\nless diverse output, yet it exhibits higher image quality and\\ntext alignment [50].\\nTeacher steps.\\n(Table 1f). While our distillation loss\\nformulation allows taking several consecutive steps with the\\nteacher by construction, we ﬁnd that several steps do not\\nconclusively result in better performance.\\n', 9)\n",
      "second if: ('4.2. Quantitative Comparison to State of the Art\\n', 10)\n",
      "second if: ('For our main comparison with other approaches, we refrain\\nfrom using automated metrics, as user preference studies\\nare more reliable [50]. In the study, we aim to assess both\\nprompt adherence and the overall image. As a performance\\nmeasure, we compute win percentages for pairwise compar-\\nisons and ELO scores when comparing several approaches.\\nFor the reported ELO scores we calculate the mean scores\\n7\\n', 9)\n",
      "second if: ('IF-XL\\n(150 steps)\\nSDXL\\n(50 steps)\\nOpenMUSE\\n(16 steps)\\n900\\n950\\nLCM-XL\\n(4 steps)\\nADD-XL\\n(1 step)\\n1,050\\n1,000\\nELO ↑\\nADD-XL\\n(4 steps)\\n1,100\\n1,150\\n1,200\\nFigure 7. Performance vs. speed. We visualize the results reported\\nin Fig. 6 in combination with the inference speeds of the respective\\nmodels. The speeds are calculated for generating a single sample\\nat resolution 512x512 on an A100 in mixed precision.\\n', 8)\n",
      "second if: ('between both prompt following and image quality. Details\\non the ELO score computation and the study parameters are\\nlisted in the supplementary material.\\nFig. 5 and Fig. 6 present the study results. The most im-\\nportant results are: First, ADD-XL outperforms LCM-XL (4\\nsteps) with a single step. Second, ADD-XL can beat SDXL\\n(50 steps) with four steps in the majority of comparisons.\\nThis makes ADD-XL the state-of-the-art in both the single\\nand the multiple steps setting. Fig. 7 visualizes ELO scores\\nrelative to inference speed. Lastly, Table 2 compares dif-\\nferent few-step sampling and distillation methods using the\\nsame base model. ADD outperforms all other approaches\\nincluding the standard DPM solver with eight steps.\\n', 9)\n",
      "second if: ('4.3. Qualitative Results\\n', 10)\n",
      "second if: ('To complement our quantitative studies above, we present\\nqualitative results in this section. To paint a more complete\\npicture, we provide additional samples and qualitative com-\\n', 9)\n",
      "second if: ('A cinematic shot of a little pig priest wearing sunglasses.\\nA photograph of the inside of a subway train. There are frogs\\nsitting on the seats. One of them is reading a newspaper. The\\nwindow shows the river in the background.\\nA photo of an astronaut riding a horse in the forest. There is a\\nriver in front of them with water lilies.\\nA photo of a cute mouse wearing a crown.\\n', 8)\n",
      "second if: ('-\\n', 2)\n",
      "second if: ('L\\nX\\nD\\nD\\nA\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n', 2)\n",
      "second if: ('e\\ns\\na\\nB\\n-\\nL\\nX\\nD\\nS\\n', 3)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n0\\n5\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nD\\nD\\nA\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n', 2)\n",
      "second if: ('e\\ns\\na\\nB\\n-\\nL\\nX\\nD\\nS\\n', 3)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n0\\n5\\n(\\n', 2)\n",
      "second if: ('Figure 8. Qualitative comparison to the teacher model. ADD-XL can outperform its teacher model SDXL in the multi-step setting. The\\nadversarial loss boosts realism, particularly enhancing textures (fur, fabric, skin) while reducing oversmoothing, commonly observed in\\ndiffusion model samples. ADD-XL’s overall sample diversity tends to be lower.\\n', 8)\n",
      "second if: ('parisons in the supplementary material. Fig. 3 compares\\nADD-XL (1 step) against the best current baselines in the\\nfew-steps regime. Fig. 4 illustrates the iterative sampling\\nprocess of ADD-XL. These results showcase our model’s\\nability to improve upon an initial sample. Such iterative\\nimprovement represents another signiﬁcant beneﬁt over pure\\nGAN approaches like StyleGAN-T++. Lastly, Fig. 8 com-\\npares ADD-XL directly with its teacher model SDXL-Base.\\nAs indicated by the user studies in Section 4.2, ADD-XL\\noutperforms its teacher in both quality and prompt alignment.\\nThe enhanced realism comes at the cost of slightly decreased\\nsample diversity.\\n', 9)\n",
      "second if: ('5. Discussion\\n', 11)\n",
      "second if: ('This work introduces Adversarial Diffusion Distillation, a\\ngeneral method for distilling a pretrained diffusion model\\ninto a fast, few-step image generation model. We combine\\nan adversarial and a score distillation objective to distill the\\npublic Stable Diffusion [54] and SDXL [50] models, lever-\\naging both real data through the discriminator and structural\\nunderstanding through the diffusion teacher. Our approach\\nperforms particularly well in the ultra-fast sampling regime\\nof one or two steps, and our analyses demonstrate that it out-\\nperforms all concurrent methods in this regime. Furthermore,\\n8\\nwe retain the ability to reﬁne samples using multiple steps.\\nIn fact, using four sampling steps, our model outperforms\\nwidely used multi-step generators such as SDXL, IF, and\\nOpenMUSE.\\nOur model enables the generation of high quality images\\nin a single-step, opening up new possibilities for real-time\\ngeneration with foundation models.\\n', 9)\n",
      "second if: ('Acknowledgements\\n', 11)\n",
      "second if: ('We would like to thank Jonas M¨uller for feedback on the\\ndraft, the proof, and typesetting; Patrick Esser for feedback\\non the proof and building an early model demo; Frederic\\nBoesel for generating data and helpful discussions; Minguk\\nKang and Taesung Park for providing GigaGAN samples;\\nRichard Vencu, Harry Saini, and Sami Kama for maintaining\\nthe compute infrastructure; Yara Wald for creative sampling\\nsupport; and Vanessa Sauer for her general support.\\n', 9)\n",
      "second if: ('References\\n', 11)\n",
      "second if: ('[1] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep\\nGanguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben\\nMann, Nova DasSarma, Nelson Elhage, Zac Hatﬁeld-Dodds,\\nDanny Hernandez, Jackson Kernion, Kamal Ndousse, Cather-\\nine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam\\nMcCandlish, Chris Olah, and Jared Kaplan. A general lan-\\nguage assistant as a laboratory for alignment, 2021. 13\\n[2] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell,\\nAnna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort,\\nDeep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\\ndavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nel-\\nson Elhage, Zac Hatﬁeld-Dodds, Danny Hernandez, Tristan\\nHume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel\\nNanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack\\nClark, Sam McCandlish, Chris Olah, Ben Mann, and Jared\\nKaplan. Training a helpful and harmless assistant with rein-\\nforcement learning from human feedback, 2022. 13\\n[3] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat,\\nJiaming Song, Qinsheng Zhang, Karsten Kreis, Miika Aittala,\\nTimo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, and\\nMing-Yu Liu. ediff-i: Text-to-image diffusion models with an\\nensemble of expert denoisers. ArXiv, abs/2211.01324, 2022.\\n1, 2\\n[4] A. Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn,\\nSeung Wook Kim, Sanja Fidler, and Karsten Kreis. Align your\\nlatents: High-resolution video synthesis with latent diffusion\\nmodels. 2023 IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR), pages 22563–22575, 2023.\\n1, 2\\n[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou,\\nJulien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-\\ning properties in self-supervised vision transformers. In Pro-\\nceedings of the IEEE/CVF international conference on com-\\nputer vision, pages 9650–9660, 2021. 6\\n[6] Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot,\\nJose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy,\\nWilliam T Freeman, Michael Rubinstein, et al. Muse: Text-to-\\nimage generation via masked generative transformers. Proc.\\nICML, 2023. 6\\n[7] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang\\nWang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiao-\\nfang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image\\ngeneration models using photogenic needles in a haystack.\\narXiv preprint arXiv:2309.15807, 2023. 4\\n[8] Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Genie:\\nHigher-order denoising diffusion solvers. Advances in Neural\\nInformation Processing Systems, 35:30150–30166, 2022. 2\\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\\nDirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\\nMostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\\nvain Gelly, et al. An image is worth 16x16 words: Trans-\\narXiv preprint\\nformers for image recognition at scale.\\narXiv:2010.11929, 2020. 4\\n[10] Arpad E. Elo. The Rating of Chessplayers, Past and Present.\\nArco Pub., New York, 1978. 13\\n[11] Patrick Esser, Robin Rombach, and Bj¨orn Ommer. Tam-\\ning transformers for high-resolution image synthesis. 2021\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR), pages 12868–12878, 2020. 2\\n[12] Patrick Esser, Johnathan Chiu, Parmida Atighehchian,\\nJonathan Granskog, and Anastasis Germanidis. Structure\\nand content-guided video synthesis with diffusion models,\\n2023. 1\\n[13] Jean-Yves Franceschi, Mike Gartrell, Ludovic Dos Santos,\\nThibaut Issenhuth, Emmanuel de B´ezenac, Micka¨el Chen,\\nand Alain Rakotomamonjy. Unifying gans and score-based\\narXiv preprint\\ndiffusion as generative particle models.\\narXiv:2305.16150, 2023. 3\\n[14] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing\\nXu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville,\\nand Yoshua Bengio. Generative adversarial networks. Com-\\nmunications of the ACM, 63:139 – 144, 2014. 1, 2, 4\\n[15] Timofey Grigoryev, Andrey Voynov, and Artem Babenko.\\nWhen, why, and which pretrained gans are useful? ICLR,\\n2022. 4\\n[16] Amir Hertz, Kﬁr Aberman, and Daniel Cohen-Or. Delta de-\\nnoising score. In Proceedings of the IEEE/CVF International\\nConference on Computer Vision, pages 2328–2337, 2023. 3\\n[17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,\\nand Yejin Choi. CLIPScore: A reference-free evaluation\\nmetric for image captioning. In Proc. EMNLP, 2021. 6\\n[18] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bern-\\nhard Nessler, and Sepp Hochreiter. GANs trained by a two\\ntime-scale update rule converge to a local Nash equilibrium.\\nNeurIPS, 2017. 6, 12\\n[19] Jonathan Ho. Classiﬁer-free diffusion guidance. ArXiv,\\nabs/2207.12598, 2022. 2\\n[20] Jonathan Ho, Ajay Jain, and P. Abbeel. Denoising diffusion\\nprobabilistic models. ArXiv, abs/2006.11239, 2020. 1\\n[21] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang,\\nRuiqi Gao, Alexey A. Gritsenko, Diederik P. Kingma, Ben\\nPoole, Mohammad Norouzi, David J. Fleet, and Tim Salimans.\\nImagen video: High deﬁnition video generation with diffusion\\nmodels. ArXiv, abs/2210.02303, 2022. 1, 2\\n[22] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\\nYuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank\\nadaptation of large language models. ArXiv, abs/2106.09685,\\n2021. 2\\n[23] Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-\\nJun Zha, and Lei Zhang. Dreamtime: An improved optimiza-\\ntion strategy for text-to-3d content creation. arXiv preprint\\narXiv:2306.12422, 2023. 6\\n[24] Alexia Jolicoeur-Martineau, R´emi Pich´e-Taillefer, R´emi Ta-\\nchet des Combes, and Ioannis Mitliagkas. Adversarial score\\nmatching and improved sampling for image generation. arXiv\\npreprint arXiv:2009.05475, 2020. 3\\n[25] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli\\nShechtman, Sylvain Paris, and Taesung Park. Scaling up gans\\nfor text-to-image synthesis. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition,\\npages 10124–10134, 2023. 1, 2, 6, 14\\n[26] Tero Karras, Samuli Laine, and Timo Aila. A style-based\\ngenerator architecture for generative adversarial networks.\\n2019 IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR), pages 4396–4405, 2018. 1, 4, 14\\n[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,\\nJaakko Lehtinen, and Timo Aila. Analyzing and improving\\nthe image quality of stylegan. 2020 IEEE/CVF Conference\\n', 8)\n",
      "second if: ('9\\n', 9)\n",
      "second if: ('on Computer Vision and Pattern Recognition (CVPR), pages\\n8107–8116, 2019. 1, 4\\nproach for transferring knowledge from pre-trained diffusion\\nmodels. arXiv preprint arXiv:2305.18455, 2023. 3\\n[28] Oren Katzir, Or Patashnik, Daniel Cohen-Or, and Dani\\nLischinski. Noise-free score distillation. arXiv preprint\\narXiv:2310.17590, 2023. 5\\n[29] Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Mu-\\nrata, Yuhta Takida, Toshimitsu Uesaka, Yutong He, Yuki\\nMitsufuji, and Stefano Ermon. Consistency trajectory models:\\nLearning probability ﬂow ode trajectory of diffusion. arXiv\\npreprint arXiv:2310.02279, 2023. 3\\n[30] Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Ma-\\ntiana, Joe Penna, and Omer Levy. Pick-a-pic: An open dataset\\nof user preferences for text-to-image generation, 2023. 12\\n[31] Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun\\nFu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren. Snapfusion:\\nText-to-image diffusion model on mobile devices within two\\nseconds. arXiv preprint arXiv:2306.00980, 2023. 7\\n[32] Jae Hyun Lim and Jong Chul Ye. Geometric gan. arXiv\\npreprint arXiv:1705.02894, 2017. 5\\n[33] Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Com-\\nmon diffusion noise schedules and sample steps are ﬂawed,\\n2023. 4\\n[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bour-\\ndev, Ross Girshick, James Hays, Pietro Perona, Deva Ra-\\nmanan, C. Lawrence Zitnick, and Piotr Doll´ar. Microsoft\\ncoco: Common objects in context, 2015. 6\\n[35] Xingchao Liu, Chengyue Gong, et al. Flow straight and\\nfast: Learning to generate and transfer data with rectiﬁed\\nﬂow. In The Eleventh International Conference on Learning\\nRepresentations, 2022. 2\\n[36] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, and\\nQiang Liu. Instaﬂow: One step is enough for high-quality\\ndiffusion-based text-to-image generation. arXiv preprint\\narXiv:2309.06380, 2023. 2, 3, 7, 15\\n[37] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan\\nLi, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion\\nprobabilistic model sampling in around 10 steps. Advances in\\nNeural Information Processing Systems, 35:5775–5787, 2022.\\n2, 7\\n[38] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and\\nLatent consistency models: Synthesizing\\nHang Zhao.\\nhigh-resolution images with few-step inference. ArXiv,\\nabs/2310.04378, 2023. 2, 13\\n[39] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang\\nZhao.\\nLatent consistency models: Synthesizing high-\\nresolution images with few-step inference. arXiv preprint\\narXiv:2310.04378, 2023. 6\\n[40] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\\nPlaten, Apolin’ario Passos, Longbo Huang, Jian Li, and Hang\\nZhao. Lcm-lora: A universal stable-diffusion acceleration\\nmodule. ArXiv, abs/2311.05556, 2023. 2, 3, 13, 15\\n[41] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von\\nPlaten, Apolin´ario Passos, Longbo Huang, Jian Li, and Hang\\nZhao. Lcm-lora: A universal stable-diffusion acceleration\\nmodule. arXiv preprint arXiv:2311.05556, 2023. 6\\n[42] Weijian Luo, Tianyang Hu, Shifeng Zhang, Jiacheng Sun,\\nZhenguo Li, and Zhihua Zhang. Diff-instruct: A universal ap-\\n[43] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik\\nKingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.\\nOn distillation of guided diffusion models. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 14297–14306, 2023. 2, 7\\n[44] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.\\nWhich training methods for gans do actually converge? In\\nInternational conference on machine learning, pages 3481–\\n3490. PMLR, 2018. 5\\n[45] Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and\\nDaniel Cohen-Or. Latent-nerf for shape-guided generation\\nof 3d shapes and textures. 2023 IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR), pages\\n12663–12673, 2022. 2\\n[46] Takeru Miyato and Masanori Koyama. cgans with projection\\ndiscriminator. arXiv preprint arXiv:1802.05637, 2018. 4\\n[47] Maxime Oquab, Timoth´ee Darcet, Th´eo Moutakanni, Huy Vo,\\nMarc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel\\nHaziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2:\\nLearning robust visual features without supervision. arXiv\\npreprint arXiv:2304.07193, 2023. 6\\n[48] Suraj Patil, William Berman, and Patrick von Platen. Amused:\\nAn open muse model. https://github.com/huggingface/\\ndiffusers, 2023. 6, 15\\n[49] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. In Proceedings of the IEEE/CVF Inter-\\nnational Conference on Computer Vision, pages 4195–4205,\\n2023. 6\\n[50] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann,\\nTim Dockhorn, Jonas M¨uller, Joe Penna, and Robin Rombach.\\nSdxl: Improving latent diffusion models for high-resolution\\nimage synthesis. arXiv preprint arXiv:2307.01952, 2023. 2,\\n4, 5, 6, 7, 8, 12, 13\\n[51] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.\\nDreamfusion: Text-to-3d using 2d diffusion. arXiv preprint\\narXiv:2209.14988, 2022. 2, 5, 12\\n[52] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\\nAmanda Askell, Pamela Mishkin, Jack Clark, et al. Learning\\ntransferable visual models from natural language supervi-\\nsion. In International conference on machine learning, pages\\n8748–8763. PMLR, 2021. 6, 12\\n[53] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,\\nand Mark Chen. Hierarchical text-conditional image gener-\\nation with clip latents. ArXiv, abs/2204.06125, 2022. 1, 2,\\n4\\n[54] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick\\nEsser, and Bj¨orn Ommer. High-resolution image synthesis\\nwith latent diffusion models. 2022 IEEE/CVF Conference\\non Computer Vision and Pattern Recognition (CVPR), pages\\n10674–10685, 2021. 1, 2, 5, 6, 8\\n[55] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,\\nJay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael\\nGontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Pho-\\ntorealistic text-to-image diffusion models with deep language\\n', 8)\n",
      "second if: ('10\\n', 9)\n",
      "second if: ('[70] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling\\nthe generative learning trilemma with denoising diffusion\\ngans. arXiv preprint arXiv:2112.07804, 2021. 3\\n[71] Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou. Ufo-\\ngen: You forward once large scale text-to-image generation\\nvia diffusion gans. arXiv preprint arXiv:2311.09257, 2023. 7\\n[72] Chun-Han Yao, Amit Raj, Wei-Chih Hung, Yuanzhen Li,\\nMichael Rubinstein, Ming-Hsuan Yang, and Varun Jampani.\\nArtic3d: Learning robust articulated 3d shapes from noisy\\nweb image collections. arXiv preprint arXiv:2306.04619,\\n2023. 4\\n[73] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan\\nBaid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei\\nYang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana\\nParekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui\\nWu. Scaling autoregressive models for content-rich text-to-\\nimage generation, 2022. 12\\n[74] Qinsheng Zhang and Yongxin Chen. Fast sampling of dif-\\nfusion models with exponential integrator. arXiv preprint\\narXiv:2204.13902, 2022. 2\\nunderstanding. Advances in Neural Information Processing\\nSystems, 35:36479–36494, 2022. 4, 6\\n[56] Tim Salimans and Jonathan Ho. Progressive distillation for\\nfast sampling of diffusion models. CoRR, abs/2202.00512,\\n2022. 2\\n[57] Axel Sauer, Kashyap Chitta, Jens M¨uller, and Andreas Geiger.\\nProjected gans converge faster. Advances in Neural Informa-\\ntion Processing Systems, 34:17480–17492, 2021. 5\\n[58] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl:\\nScaling stylegan to large diverse datasets. ACM SIGGRAPH\\n2022 Conference Proceedings, 2022. 1, 4\\n[59] Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and\\nTimo Aila. Stylegan-t: Unlocking the power of gans for fast\\nlarge-scale text-to-image synthesis. Proc. ICML, 2023. 2, 3,\\n4, 5, 6, 14\\n[60] Juergen Schmidhuber. Generative adversarial networks are\\nspecial cases of artiﬁcial curiosity (1990) and also closely\\nrelated to predictability minimization (1991), 2020. 4\\n[61] Christoph Schuhmann, Romain Beaumont, Richard Vencu,\\nCade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes,\\nAarush Katta, Clayton Mullis, Mitchell Wortsman, et al.\\nLAION-5B: An open large-scale dataset for training next\\ngeneration image-text models. In NeurIPS, 2022. 6\\n[62] Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual,\\nIurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea\\nVedaldi, Devi Parikh, Justin Johnson, et al. Text-to-4d dy-\\nnamic scene generation. arXiv preprint arXiv:2301.11280,\\n2023. 3\\n[63] Jascha Narain Sohl-Dickstein, Eric A. Weiss, Niru Ma-\\nheswaranathan, and Surya Ganguli. Deep unsupervised\\nlearning using nonequilibrium thermodynamics. ArXiv,\\nabs/1503.03585, 2015. 1\\n[64] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising\\ndiffusion implicit models. In International Conference on\\nLearning Representations, 2021. 2\\n[65] Yang Song, Jascha Narain Sohl-Dickstein, Diederik P.\\nKingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.\\nScore-based generative modeling through stochastic differen-\\ntial equations. ArXiv, abs/2011.13456, 2020. 1\\n[66] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.\\nConsistency models. In International Conference on Machine\\nLearning, 2023. 2\\n[67] George Stein, Jesse C Cresswell, Rasa Hosseinzadeh, Yi Sui,\\nBrendan Leigh Ross, Valentin Villecroze, Zhaoyan Liu, An-\\nthony L Caterini, J Eric T Taylor, and Gabriel Loaiza-Ganem.\\nExposing ﬂaws of generative model evaluation metrics and\\ntheir unfair treatment of diffusion models. arXiv preprint\\narXiv:2306.04675, 2023. 6, 14\\n[68] Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A Yeh,\\nand Greg Shakhnarovich. Score jacobian chaining: Lifting\\npretrained 2d diffusion models for 3d generation. In Proceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 12619–12629, 2023. 2, 5\\n[69] Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan\\nLi, Hang Su, and Jun Zhu. Proliﬁcdreamer: High-ﬁdelity and\\ndiverse text-to-3d generation with variational score distilla-\\ntion. ArXiv, abs/2305.16213, 2023. 2\\n', 8)\n",
      "second if: ('11\\n', 9)\n",
      "second if: ('Appendix\\nA. SDS As a Special Case of the Distillation Loss\\n', 11)\n",
      "second if: ('If we set the weighting function to c(t) = αt\\nand choose d(x, y) = ||x − y||2\\n', 9)\n",
      "second if: ('2σt w(t) where w(t) is the scaling factor from the weighted diffusion loss as in [51]\\n2, the distillation loss in Eq. (4) is equivalent to the score distillation objective:\\n', 6)\n",
      "second if: ('d\\ndθ\\nLMSE\\ndistill\\n(ˆxθ,t − ˆxθ,t) + ˆxθ − ˆxψ(ˆxθ,t; t)]\\ndˆxθ\\ndθ i\\n(5)\\n||ˆxθ − ˆxψ(sg(ˆxθ,t); t)||2\\n2i\\nd\\n= Et,ϵ′ hc(t)\\ndθ\\n= Et,ϵ′ h2c(t)[ˆxθ − ˆxψ(ˆxθ,t; t)]\\n= Et,ϵ′ h\\nw(t)[\\n1\\nαt\\ndˆxθ\\ndθ i\\nαt\\nσt\\n1\\nσt\\nw(t)\\nσt\\n= Et,ϵ′ h\\n= Et,ϵ′ h\\nd\\ndθ\\n=\\nLSDS\\nw(t)[(αt ˆxθ − ˆxθ,t) − (αt ˆxψ(ˆxθ,t; t) − ˆxθ,t)]\\ndˆxθ\\ndθ i\\n[−σtϵ′ + σtˆϵθ(ˆxθ,t; t)]\\ndˆxθ\\ndθ i\\n', 9)\n",
      "second if: ('B. Details on Human Preference Assessment\\n', 11)\n",
      "second if: ('For the evaluation results presented in Figures 5 to 7, we employ human evaluation and do not rely on commonly used\\nmetrics for quality assessment of generative models such as FID [18] and CLIP-score [52], since these have been shown to\\ncapture more ﬁne grained aspects like aesthetics and scene composition only insufﬁciently [30, 50]. However these categories\\nin particular have become more and more important when comparing current state-of-the-art text-to-image models. We\\nevaluate all models based on 100 selected prompts from the PartiPrompts benchmark [73] with the most relevant categories\\n(excluding prompts from the category basic). More details on how the study was conducted Appendix B.1 and the rankings\\ncomputed Appendix B.2 are listed below.\\n', 9)\n",
      "second if: ('Figure 9. User preference study (single step). We compare the performance of ADD-M (1-step) against established baselines.\\n', 8)\n",
      "second if: ('12\\n', 9)\n",
      "second if: ('Figure 10. User preference study (multiple steps). We compare the performance of ADD-XL (4-step) against established baselines.\\n', 8)\n",
      "second if: ('B.1. Experimental Setup\\n', 10)\n",
      "second if: ('Given all models for one particular study (e.g. ADD-XL, OpenMUSE6, IF-XL7, SDXL [50] and LCM-XL8 [38, 40] in\\nFigure 7) we compare each prompt for each pair of models (1v1). For every comparison, we collect an average of four votes\\nper task from different annotators, for both visual quality and prompt following. Human evaluators, recruited from the platform\\nProliﬁc9 with English as their ﬁrst language, are shown two images from different models based on the same text prompt. To\\nprevent biases, evaluators are restricted from participating in more than one of our studies. For the prompt following task,\\nwe display the text prompt above the two images and ask, “Which image looks more representative of the text shown above\\nand faithfully follows it?” For the visual quality assessment, we do not show the prompt and instead ask, “Which image is of\\nhigher quality and aesthetically more pleasing?”. Performing a complete assessment between all pair-wise comparisons gives\\nus robust and reliable signals on model performance trends and the effect of varying thresholds. The order of prompts and the\\norder between models are fully randomized. Frequent attention checks are in place to ensure data quality.\\n', 9)\n",
      "second if: ('B.2. ELO Score Calculation\\n', 10)\n",
      "second if: ('To calculate rankings when comparing more than two models based on 1v1 comparisons we use ELO Scores (higher-is-\\nbetter) [10] which were originally proposed as a scoring method for chess players but have more recently also been applied to\\ncompare instruction-tuned generative LLMs [1, 2]. For a set of competing players with initial ratings Rinit participating in a\\nseries of zero-sum games the ELO rating system updates the ratings of the two players involved in a particular game based on\\nthe expected and and actual outcome of that game. Before the game with two players with ratings R1 and R2, the expected\\noutcome for the two players are calculated as\\nE1 =\\nE2 =\\n1\\nR2−R1\\n400\\n1 + 10\\n1\\nR1−R2\\n400\\n1 + 10\\n,\\n.\\nAfter observing the result of the game, the ratings Ri are updated via the rule\\n', 9)\n",
      "second if: ('′\\n', 4)\n",
      "second if: ('i = Ri + K · (Si − Ei) ,\\n', 6)\n",
      "second if: ('R\\ni ∈ {1, 2}\\n(6)\\n(7)\\n(8)\\nwhere Si indicates the outcome of the match for player i. In our case we have Si = 1 if player i wins and Si = 0 if player\\ni looses. The constant K can be see as weight putting emphasis on more recent games. We choose K = 1 and bootstrap\\nthe ﬁnal ELO ranking for a given series of comparisons based on 1000 individual ELO ranking calculations with randomly\\nshufﬂed order. Before comparing the models we choose the start rating for every model as Rinit = 1000.\\n', 9)\n",
      "second if: ('6https://huggingface.co/openMUSE\\n7https://github.com/deep-ﬂoyd/IF\\n8https://huggingface.co/latent-consistency/lcm-lora-sdxl\\n9https://app.proliﬁc.com\\n', 5)\n",
      "second if: ('13\\n', 9)\n",
      "second if: ('C. GAN Baselines Comparison\\n', 11)\n",
      "second if: ('For training our state-of-the-art GAN baseline StyleGAN-T++, we follow the training procedure outlined in [59]. The main\\ndifferences are extended training (∼2M iterations with a batch size of 2048, which is comparable to GigaGAN’s schedule [25]),\\nthe improved discriminator architecture proposed in Section 3.2, and R1 penalty applied at each discriminator head.\\nFig. 11 shows that StyleGAN-T++ outperforms the previous best GANs by achieving a comparable zero-shot FID to\\nGigaGAN at a signiﬁcantly higher CLIP score. Here, we do not compare to DMs, as comparisons between model classes via\\nautomatic metrics tend to be less informative [67]. As an example, GigaGAN achieves FID and CLIP scores comparable to\\nSD1.5, but its sample quality is still inferior, as noted by the authors.\\n', 9)\n",
      "second if: ('k\\n5\\n', 6)\n",
      "Prev Size: 17, Cur Size: 12\n",
      "second if: ('GigaGAN\\nStyleGAN-T\\nStyleGAN-T++\\n', 8)\n",
      "second if: ('Figure 11. Comparing text alignment tradeoffs at 256 × 256 pixels. We compare FID–CLIP score curves of StyleGAN-T, StyleGAN-T++,\\nand GigaGAN. For increasing CLIP score, all methods use via decreasing truncation [26] for values ψ = {1.0, 0.9, . . . , 0.3}.\\nFigure 12. Additional single step 5122 images generated with ADD-XL. All samples are generated with a single U-Net evaluation trained\\nwith adversarial diffusion distillation (ADD).\\n', 8)\n",
      "Prev Size: 11, Cur Size: 9\n",
      "second if: ('We show additional one-step samples as in Figure 1 in Figure 12. An additional qualitative comparison as in Figure 4 which\\ndemonstrates that our model can further reﬁne quality by using more than one sampling step is provided in Figure 14, where\\nwe show that, while sampling quality with a single step is already high, more steps can give higher diversity and better spelling\\ncapabilities. Lastly, we provide an additional qualitative comparison of ADD-XL to other state-of-the-art one and few-step\\nmodels in Figure 13.\\n', 9)\n",
      "second if: ('A cinematic shot of robot with colorful feathers.\\nTeddy bears working on new AI research on the moon in the\\n1980s.\\n', 8)\n",
      "second if: ('-\\n', 2)\n",
      "second if: ('L\\nX\\nD\\nD\\nA\\n', 5)\n",
      "second if: (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nM\\nC\\nL\\n', 5)\n",
      "second if: (')\\np\\ne\\nt\\ns\\n1\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nD\\nD\\nA\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n2\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nM\\nC\\nL\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n2\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nD\\nD\\nA\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n-\\n', 2)\n",
      "second if: ('L\\nX\\nM\\nC\\nL\\n', 5)\n",
      "second if: (')\\ns\\np\\ne\\nt\\ns\\n4\\n(\\n', 2)\n",
      "second if: ('w\\no\\nl\\n', 6)\n",
      "second if: ('F\\na\\nt\\ns\\nn\\nI\\n', 4)\n",
      "second if: ('E\\nS\\nU\\nM\\nn\\ne\\np\\nO\\n', 5)\n",
      "second if: (')\\np\\ne\\nt\\ns\\n1\\n(\\n)\\ns\\np\\ne\\nt\\ns\\n6\\n1\\n(\\n', 2)\n",
      "second if: ('Figure 13. Additional qualitative comparisons to state of the art fast samplers. Few step samples from our ADD-XL and LCM-XL [40],\\nInstaFlow [36], and OpenMuse [48].\\n', 8)\n",
      "second if: ('15\\n', 9)\n",
      "second if: ('“a robot is playing the guitar at a rock concert in front of a large\\ncrowd.”\\n“A portrait photo of a kangaroo wearing an orange hoodie and\\nblue sunglasses standing on the grass in front of the Sydney\\nOpera House holding a sign on the chest that says Welcome\\nFriends!”\\n', 8)\n",
      "second if: ('p\\ne\\nt\\ns\\n1\\n', 4)\n",
      "second if: ('s\\np\\ne\\nt\\ns\\n2\\ns\\np\\ne\\nt\\ns\\n4\\n', 3)\n",
      "second if: ('Figure 14. Additional results on the qualitative effect of sampling steps. Similar to Figure 4, we show qualitative examples when\\nsampling ADD-XL with 1, 2, and 4 steps. Single-step samples are often already of high quality, but increasing the number of steps can\\nfurther improve the diversity (left) and spelling capabilities (right). The seeds are constant within columns and we see that the general layout\\nis preserved across sampling steps, allowing for fast exploration of outputs while retaining the possibility to reﬁne.\\n', 8)\n",
      "second if: ('16\\n', 9)\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "cur_idx = -1\n",
    "semantic_snippets = []\n",
    "# Assumption: headings have higher font size than their respective content\n",
    "for s in snippets:\n",
    "    if s[0].lower == 'references': continue\n",
    "    # if current snippet's font size > previous section's heading => it is a new heading\n",
    "    if not semantic_snippets or s[1] > semantic_snippets[cur_idx].metadata['heading_font']:\n",
    "        metadata={'heading':s[0], 'content_font': 0, 'heading_font': s[1]}\n",
    "        metadata.update(data.metadata)\n",
    "        semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "        cur_idx += 1\n",
    "        continue\n",
    "\n",
    "    # if current snippet's font size <= previous section's content => content belongs to the same section (one can also create\n",
    "    # a tree like structure for sub sections if needed but that may require some more thinking and may be data specific)\n",
    "    if not semantic_snippets[cur_idx].metadata['content_font'] or s[1] <= semantic_snippets[cur_idx].metadata['content_font']:\n",
    "        print(f\"second if: {s}\")\n",
    "        semantic_snippets[cur_idx].page_content += s[0]\n",
    "        semantic_snippets[cur_idx].metadata['content_font'] = max(s[1], semantic_snippets[cur_idx].metadata['content_font'])\n",
    "        continue\n",
    "\n",
    "    # if current snippet's font size > previous section's content but less than previous section's heading than also make a new\n",
    "    # section (e.g. title of a PDF will have the highest font size but we don't want it to subsume all sections)\n",
    "    metadata={'heading':s[0], 'content_font': 0, 'heading_font': s[1]}\n",
    "    metadata.update(data.metadata)\n",
    "    semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "    cur_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "49366\n",
      "0\n",
      "32\n",
      "437\n",
      "0\n",
      "1866\n"
     ]
    }
   ],
   "source": [
    "print(len(semantic_snippets))\n",
    "for i in semantic_snippets:\n",
    "    print(len(i.page_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
